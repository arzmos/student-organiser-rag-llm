{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fb23dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.4 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 13:38:37) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b18a4186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.1.0\n",
      "  Downloading langchain-0.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting openai==1.7.2\n",
      "  Downloading openai-1.7.2-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting langchain-openai==0.0.2\n",
      "  Downloading langchain_openai-0.0.2-py3-none-any.whl.metadata (570 bytes)\n",
      "Collecting langchain-community==0.0.12\n",
      "  Downloading langchain_community-0.0.12-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting langchainhub==0.1.14\n",
      "  Downloading langchainhub-0.1.14-py3-none-any.whl.metadata (478 bytes)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain==0.1.0) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain==0.1.0) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain==0.1.0) (3.8.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain==0.1.0) (0.6.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain==0.1.0) (1.33)\n",
      "Collecting langchain-core<0.2,>=0.1.7 (from langchain==0.1.0)\n",
      "  Downloading langchain_core-0.1.53-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.77 (from langchain==0.1.0)\n",
      "  Downloading langsmith-0.0.92-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain==0.1.0) (1.24.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain==0.1.0) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain==0.1.0) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain==0.1.0) (8.2.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from openai==1.7.2) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from openai==1.7.2) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from openai==1.7.2) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from openai==1.7.2) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from openai==1.7.2) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from openai==1.7.2) (4.12.2)\n",
      "Collecting tiktoken<0.6.0,>=0.5.2 (from langchain-openai==0.0.2)\n",
      "  Downloading tiktoken-0.5.2-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub==0.1.14)\n",
      "  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.0) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai==1.7.2) (3.7)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.0) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.0) (0.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.7.2) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.7.2) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.7.2) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.0) (2.1)\n",
      "INFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-core<0.2,>=0.1.7 (from langchain==0.1.0)\n",
      "  Downloading langchain_core-0.1.52-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.51-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.50-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.49-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.48-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.47-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.46-py3-none-any.whl.metadata (5.9 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langchain_core-0.1.45-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.44-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.43-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.42-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.41-py3-none-any.whl.metadata (5.9 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading langchain_core-0.1.40-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.39-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.38-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.37-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.36-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.35-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.34-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.33-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.32-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.31-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.30-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.29-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.28-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.27-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.26-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.25-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.24-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.23-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.77 (from langchain==0.1.0)\n",
      "  Downloading langsmith-0.0.87-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2,>=0.1.7->langchain==0.1.0)\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.0) (2.20.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain==0.1.0) (1.26.16)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.0) (2.0.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from tiktoken<0.6.0,>=0.5.2->langchain-openai==0.0.2) (2022.7.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from tqdm>4->openai==1.7.2) (0.4.6)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain==0.1.0)\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.0) (0.4.3)\n",
      "Downloading langchain-0.1.0-py3-none-any.whl (797 kB)\n",
      "   ---------------------------------------- 0.0/798.0 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 235.5/798.0 kB 7.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 542.7/798.0 kB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  788.5/798.0 kB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 798.0/798.0 kB 5.6 MB/s eta 0:00:00\n",
      "Downloading openai-1.7.2-py3-none-any.whl (212 kB)\n",
      "   ---------------------------------------- 0.0/212.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 212.1/212.1 kB 6.5 MB/s eta 0:00:00\n",
      "Downloading langchain_openai-0.0.2-py3-none-any.whl (28 kB)\n",
      "Downloading langchain_community-0.0.12-py3-none-any.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.3/1.6 MB 9.6 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.6/1.6 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 0.9/1.6 MB 7.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.1/1.6 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.4/1.6 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.6 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 6.2 MB/s eta 0:00:00\n",
      "Downloading langchainhub-0.1.14-py3-none-any.whl (3.4 kB)\n",
      "Downloading langchain_core-0.1.23-py3-none-any.whl (241 kB)\n",
      "   ---------------------------------------- 0.0/241.2 kB ? eta -:--:--\n",
      "   ---------------------------------------  235.5/241.2 kB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 241.2/241.2 kB 3.7 MB/s eta 0:00:00\n",
      "Downloading langsmith-0.0.87-py3-none-any.whl (55 kB)\n",
      "   ---------------------------------------- 0.0/55.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 55.4/55.4 kB 2.8 MB/s eta 0:00:00\n",
      "Downloading tiktoken-0.5.2-cp311-cp311-win_amd64.whl (786 kB)\n",
      "   ---------------------------------------- 0.0/786.4 kB ? eta -:--:--\n",
      "   --------------- ----------------------- 317.4/786.4 kB 20.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 655.4/786.4 kB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 786.4/786.4 kB 7.1 MB/s eta 0:00:00\n",
      "Downloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n",
      "Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "   ---------------------------------------- 0.0/53.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 53.0/53.0 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "   ---------------------------------------- 0.0/126.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 126.3/126.3 kB 3.6 MB/s eta 0:00:00\n",
      "Installing collected packages: urllib3, packaging, types-requests, tiktoken, openai, langsmith, langchainhub, langchain-core, langchain-openai, langchain-community, langchain\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.16\n",
      "    Uninstalling urllib3-1.26.16:\n",
      "      Successfully uninstalled urllib3-1.26.16\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.1\n",
      "    Uninstalling packaging-24.1:\n",
      "      Successfully uninstalled packaging-24.1\n",
      "  Attempting uninstall: tiktoken\n",
      "    Found existing installation: tiktoken 0.7.0\n",
      "    Uninstalling tiktoken-0.7.0:\n",
      "      Successfully uninstalled tiktoken-0.7.0\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.28.0\n",
      "    Uninstalling openai-0.28.0:\n",
      "      Successfully uninstalled openai-0.28.0\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.1.88\n",
      "    Uninstalling langsmith-0.1.88:\n",
      "      Successfully uninstalled langsmith-0.1.88\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.2.28\n",
      "    Uninstalling langchain-core-0.2.28:\n",
      "      Successfully uninstalled langchain-core-0.2.28\n",
      "  Attempting uninstall: langchain-openai\n",
      "    Found existing installation: langchain-openai 0.1.20\n",
      "    Uninstalling langchain-openai-0.1.20:\n",
      "      Successfully uninstalled langchain-openai-0.1.20\n",
      "  Attempting uninstall: langchain-community\n",
      "    Found existing installation: langchain-community 0.2.7\n",
      "    Uninstalling langchain-community-0.2.7:\n",
      "      Successfully uninstalled langchain-community-0.2.7\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.2.9\n",
      "    Uninstalling langchain-0.2.9:\n",
      "      Successfully uninstalled langchain-0.2.9\n",
      "Successfully installed langchain-0.1.0 langchain-community-0.0.12 langchain-core-0.1.23 langchain-openai-0.0.2 langchainhub-0.1.14 langsmith-0.0.87 openai-1.7.2 packaging-23.2 tiktoken-0.5.2 types-requests-2.32.0.20241016 urllib3-2.2.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "botocore 1.27.59 requires urllib3<1.27,>=1.25.4, but you have urllib3 2.2.3 which is incompatible.\n",
      "google-auth 2.22.0 requires urllib3<2.0, but you have urllib3 2.2.3 which is incompatible.\n",
      "langchain-text-splitters 0.2.2 requires langchain-core<0.3.0,>=0.2.10, but you have langchain-core 0.1.23 which is incompatible.\n",
      "python-lsp-black 1.2.1 requires black>=22.3.0, but you have black 0.0 which is incompatible.\n",
      "spacy-transformers 1.3.5 requires transformers<4.42.0,>=3.4.0, but you have transformers 4.43.0.dev0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain==0.1.0 openai==1.7.2 langchain-openai==0.0.2 langchain-community==0.0.12 langchainhub==0.1.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3ea1754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\omidm\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03476392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Collecting neo4j\n",
      "  Downloading neo4j-5.26.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: langchain in c:\\users\\omidm\\anaconda3\\lib\\site-packages (0.1.0)\n",
      "Requirement already satisfied: openai in c:\\users\\omidm\\anaconda3\\lib\\site-packages (1.7.2)\n",
      "Collecting google-generativeai\n",
      "  Downloading google_generativeai-0.8.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: pytz in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from neo4j) (2022.7)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain) (3.8.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain) (0.6.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.9 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain) (0.0.12)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.7 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain) (0.1.23)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.77 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain) (0.0.87)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from openai) (4.12.2)\n",
      "Collecting google-ai-generativelanguage==0.6.10 (from google-generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.10-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Downloading google_api_core-2.23.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-api-python-client (from google-generativeai)\n",
      "  Downloading google_api_python_client-2.154.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from google-generativeai) (2.22.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from google-generativeai) (4.25.3)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.10->google-generativeai)\n",
      "  Downloading proto_plus-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (1.63.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (1.16.0)\n",
      "Collecting urllib3<2.0 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
      "     ---------------------------------------- 0.0/50.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 50.1/50.1 kB ? eta 0:00:00\n",
      "Requirement already satisfied: certifi in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.7->langchain) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.57.0)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai)\n",
      "  Downloading grpcio_status-1.68.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.4.8)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (0.4.3)\n",
      "Collecting protobuf (from google-generativeai)\n",
      "  Downloading protobuf-5.28.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai)\n",
      "  Downloading grpcio-1.68.0-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
      "Downloading neo4j-5.26.0-py3-none-any.whl (302 kB)\n",
      "   ---------------------------------------- 0.0/302.0 kB ? eta -:--:--\n",
      "   ---------------------------------------  297.0/302.0 kB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 302.0/302.0 kB 6.2 MB/s eta 0:00:00\n",
      "Downloading google_generativeai-0.8.3-py3-none-any.whl (160 kB)\n",
      "   ---------------------------------------- 0.0/160.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 160.8/160.8 kB 9.4 MB/s eta 0:00:00\n",
      "Downloading google_ai_generativelanguage-0.6.10-py3-none-any.whl (760 kB)\n",
      "   ---------------------------------------- 0.0/760.0 kB ? eta -:--:--\n",
      "   --------------- ------------------------ 297.0/760.0 kB 9.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 604.2/760.0 kB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 760.0/760.0 kB 6.9 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.23.0-py3-none-any.whl (156 kB)\n",
      "   ---------------------------------------- 0.0/156.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 156.6/156.6 kB 4.7 MB/s eta 0:00:00\n",
      "Downloading google_api_python_client-2.154.0-py2.py3-none-any.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/12.6 MB 9.9 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.6/12.6 MB 7.0 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.8/12.6 MB 7.1 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.2/12.6 MB 6.2 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.4/12.6 MB 6.1 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.7/12.6 MB 6.2 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.2/12.6 MB 6.2 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.5/12.6 MB 6.3 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.7/12.6 MB 6.3 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.0/12.6 MB 6.2 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.3/12.6 MB 6.2 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.6/12.6 MB 6.3 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 4.0/12.6 MB 6.3 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 4.3/12.6 MB 6.4 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.6/12.6 MB 6.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.9/12.6 MB 6.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 5.2/12.6 MB 6.5 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.5/12.6 MB 6.5 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.8/12.6 MB 6.5 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.1/12.6 MB 6.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.4/12.6 MB 6.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.8/12.6 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 7.1/12.6 MB 6.5 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.4/12.6 MB 6.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.7/12.6 MB 6.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 8.0/12.6 MB 6.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.3/12.6 MB 6.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.6/12.6 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.9/12.6 MB 6.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.2/12.6 MB 6.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.5/12.6 MB 6.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.9/12.6 MB 6.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.2/12.6 MB 6.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.5/12.6 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.8/12.6 MB 6.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.1/12.6 MB 6.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.3/12.6 MB 6.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.5/12.6 MB 6.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.8/12.6 MB 6.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.1/12.6 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.5/12.6 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.6 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 6.2 MB/s eta 0:00:00\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading proto_plus-1.25.0-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.1/50.1 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
      "   ---------------------------------------- 0.0/144.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 144.2/144.2 kB 8.9 MB/s eta 0:00:00\n",
      "Downloading grpcio_status-1.68.0-py3-none-any.whl (14 kB)\n",
      "Downloading protobuf-5.28.3-cp310-abi3-win_amd64.whl (431 kB)\n",
      "   ---------------------------------------- 0.0/431.5 kB ? eta -:--:--\n",
      "   ------------------------------- -------- 337.9/431.5 kB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 431.5/431.5 kB 6.7 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.68.0-cp311-cp311-win_amd64.whl (4.4 MB)\n",
      "   ---------------------------------------- 0.0/4.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/4.4 MB 6.5 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.6/4.4 MB 6.5 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.9/4.4 MB 6.5 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 1.2/4.4 MB 7.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.6/4.4 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.8/4.4 MB 6.9 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 2.2/4.4 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 2.5/4.4 MB 6.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 2.8/4.4 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 3.1/4.4 MB 6.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 3.4/4.4 MB 6.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 3.7/4.4 MB 6.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 4.0/4.4 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.3/4.4 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.4/4.4 MB 6.5 MB/s eta 0:00:00\n",
      "Installing collected packages: urllib3, uritemplate, protobuf, neo4j, grpcio, proto-plus, grpcio-status, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.3\n",
      "    Uninstalling urllib3-2.2.3:\n",
      "      Successfully uninstalled urllib3-2.2.3\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.3\n",
      "    Uninstalling protobuf-4.25.3:\n",
      "      Successfully uninstalled protobuf-4.25.3\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.57.0\n",
      "    Uninstalling grpcio-1.57.0:\n",
      "      Successfully uninstalled grpcio-1.57.0\n",
      "Successfully installed google-ai-generativelanguage-0.6.10 google-api-core-2.23.0 google-api-python-client-2.154.0 google-auth-httplib2-0.2.0 google-generativeai-0.8.3 grpcio-1.68.0 grpcio-status-1.68.0 neo4j-5.26.0 proto-plus-1.25.0 protobuf-5.28.3 uritemplate-4.1.1 urllib3-1.26.20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spacy-transformers 1.3.5 requires transformers<4.42.0,>=3.4.0, but you have transformers 4.43.0.dev0 which is incompatible.\n",
      "tensorflow-intel 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.28.3 which is incompatible.\n",
      "tensorflow-metadata 1.15.0 requires protobuf<5,>=4.25.2; python_version >= \"3.11\", but you have protobuf 5.28.3 which is incompatible.\n",
      "types-requests 2.32.0.20241016 requires urllib3>=2, but you have urllib3 1.26.20 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install neo4j langchain openai google-generativeai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59d1b0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neo4j in c:\\users\\omidm\\anaconda3\\lib\\site-packages (5.26.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: pytz in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from neo4j) (2022.7)\n"
     ]
    }
   ],
   "source": [
    "pip install neo4j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40c1b7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Installing Neo4j', 'content': None}]\n",
      "Title: Installing Neo4j\n",
      "Content: None\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Connect to Neo4j\n",
    "driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"12345678\"))\n",
    "def search_documents_by_keyword(keyword):\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\n",
    "            \"\"\"\n",
    "            MATCH (k:Keyword {name: $keyword})<-[:HAS_KEYWORD]-(d:Document)\n",
    "            RETURN d.title AS title, d.content AS content\n",
    "            \"\"\", keyword=keyword\n",
    "        )\n",
    "        return [{\"title\": record[\"title\"], \"content\": record[\"content\"]} for record in result]\n",
    "\n",
    "docs = search_documents_by_keyword(\"Install\")\n",
    "print(docs)\n",
    "for doc in docs:\n",
    "    print(f\"Title: {doc['title']}\\nContent: {doc['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c548961f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\omidm\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from requests) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from requests) (2024.7.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6dc419c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: How do I know if I am eligible?\n",
      "Content: For the enginering students, please contact engit-placements [at] unimelb [dot] edu [dot] au. For the data science and maths students, please contact science-industry-internships[at] unimelb [dot] edu [dot] au.\n",
      "Topic: FAQ\n",
      "Keywords: au, contact, dot, edu, science\n",
      "----------------------------------------\n",
      "Title: How flexible are the starting dates?\n",
      "Content: We are flexible. We aim to keep the same starting dates for everyone to make it easier to put people into the WEHI system, but the actual date you start can be flexible. You could start a week or two later if you need to. We are also flexible if you need to take time off during the internship as well.\n",
      "Topic: FAQ\n",
      "Keywords: dates, flexible, need, start, starting\n",
      "----------------------------------------\n",
      "Title: Where are the details I need to fill in my form?\n",
      "Content: You can find the information here:\n",
      "Topic: FAQ\n",
      "Keywords: details, form, information, need\n",
      "----------------------------------------\n",
      "Title: I know that the internships are usually 100% offsite, but what if I want to go into the office sometimes?\n",
      "Content: We are open to having some opportunities to go to the office, especially if we can catchup with the other students. It would not be that regular though, but this can be discussed with other students.\n",
      "Topic: FAQ\n",
      "Keywords: 100, catchup, discussed, office, students\n",
      "----------------------------------------\n",
      "Title: How do I know you won’t get disengaged with the students?\n",
      "Content: We are committed to providing guidance, support, and mentorship throughout their internship experience. We recognize the importance of maintaining open lines of communication and being accessible to address their needs.\n",
      "Topic: FAQ\n",
      "Keywords: accessible, open, providing, recognize, students\n",
      "----------------------------------------\n",
      "Title: What is the difference between data engineering, data analysis, and software engineering?\n",
      "Content: Data engineering is focused on streamlining and cleaning data systematically. Data analysis is focused on cleaning data and analysing it using statistical or machine learning algorithms. Software engineering is focused on systematising analysis or tools that help us make decisions.\n",
      "Topic: FAQ\n",
      "Keywords: analysis, cleaning, data, engineering, focused\n",
      "----------------------------------------\n",
      "Title: The Workday email says “On your first day, please arrive at 9.00am unless your manager has advised an alternative time and ask for your manager upon arrival at reception.” - is this accurate?\n",
      "Content: No, it is not accurate. This is a 100% remote internship and that part of the Workday email can be safely ignored. On your first day, you will be scheduled some virtual drop-in sessions so you can meet the supervisor and other interns.\n",
      "Topic: FAQ\n",
      "Keywords: accurate, day, email, manager, workday\n",
      "----------------------------------------\n",
      "Title: I setup my Workday (HR system) through an initial email but now that password doesn’t work or I cannot login to my WEHI email\n",
      "Content: The links you might have previously used to access Workday before your official start date will no longer allow access.  Email hr [at] wehi [dot] edu [dot] au as this is the contact provided if you encounter any issue in regard to Workday. They will provided you with the new credentials to set up your WEHI email. You may need to go into Incognito mode to get it to work.\n",
      "Topic: FAQ\n",
      "Keywords: email, provided, wehi, work, workday\n",
      "----------------------------------------\n",
      "Title: What courses in Workday do I need to complete?\n",
      "Content: These are the key courses you need to do:\n",
      "Topic: FAQ\n",
      "Keywords: complete, courses, key, need, workday\n",
      "----------------------------------------\n",
      "Title: How do I get access to the WEHI-wide student intern group using my WEHI email address?\n",
      "Content: To get access to WEHI-wide student intern group using your WEHI email address. We need to do this as we will be deleting the unimelb email access once everyone has their WEHI email addresses.\n",
      "Topic: FAQ\n",
      "Keywords: access, address, email, group, wehi\n",
      "----------------------------------------\n",
      "Title: Given that the internship is remote, am I allowed to complete the internship while on travel?\n",
      "Content: Yes, that is correct.\n",
      "Topic: FAQ\n",
      "Keywords: allowed, complete, correct, given, internship\n",
      "----------------------------------------\n",
      "Title: The description stated that so many hrs per week is expected, but at roughly which times and for how long?\n",
      "Content: As it is remote, we are very flexible but there are times when we do get together, such as the weekly project meeting. This is explained in the Student Internship Handbook.\n",
      "Topic: FAQ\n",
      "Keywords: description, roughly, stated, student, times\n",
      "----------------------------------------\n",
      "Title: I need to use storage and compute. What are my options?\n",
      "Content: We have a few options at WEHI for storage and compute.\n",
      "Topic: FAQ\n",
      "Keywords: compute, need, options, storage, use\n",
      "----------------------------------------\n",
      "Title: If I want to use Nectar, what suggestions would you have?\n",
      "Content: Make sure you use “Any Availability Zone” if you are using Nectar as some of the University of Melbourne hosts are full.\n",
      "Topic: FAQ\n",
      "Keywords: availability, hosts, make, nectar, use\n",
      "----------------------------------------\n",
      "Title: Is it OK for me to post on social media?\n",
      "Content: Yes, but please read the Social Media Policy for student interns.\n",
      "Topic: FAQ\n",
      "Keywords: interns, media, ok, policy, social\n",
      "----------------------------------------\n",
      "Title: My project is complex and ambiguous - what can I do to deal with this?\n",
      "Content: All of the projects are complex and ambiguous.\n",
      "Topic: FAQ\n",
      "Keywords: ambiguous, complex, deal, project, projects\n",
      "----------------------------------------\n",
      "Title: What is the overall structure of the internship going to look like?\n",
      "Content: To understand how the overall process of the project please look at the Key milestones and onboarding emails page.\n",
      "Topic: FAQ\n",
      "Keywords: emails, going, internship, look, overall\n",
      "----------------------------------------\n",
      "Title: You ask us to be as independent as possible. How can we do that?\n",
      "Content: Rules of thumb for being independent:\n",
      "Topic: FAQ\n",
      "Keywords: ask, independent, possible, rules, thumb\n",
      "----------------------------------------\n",
      "Title: We are required to interview a number of people to gather insight into their career pathway. How can I arrange this with you?\n",
      "Content: You can see more in Ask About Career on page 25 of the RCP Student Onboarding Checklist\n",
      "Topic: FAQ\n",
      "Keywords: 25, arrange, ask, career, checklist\n",
      "----------------------------------------\n",
      "Title: We are required to request supervisor signature for the Work Log. How can I arrange this with you?\n",
      "Content: For those doing the Bachelor of Science or the Master of Data Science course, it is required to complete this supervisor signature work using DocuSign. This ensures that your work log is verified accurately and submitted on time.\n",
      "Topic: FAQ\n",
      "Keywords: required, science, signature, supervisor, work\n",
      "----------------------------------------\n",
      "Title: What should I put in the public wiki?\n",
      "Content: The public wiki is to share information with future students the things you needed to understand at a high level to be able to start working on the technical side of the project.\n",
      "Topic: FAQ\n",
      "Keywords: able, future, high, public, wiki\n",
      "----------------------------------------\n",
      "Title: What should I put in my technical diary?\n",
      "Content: Within your project channel in Sharepoint (ie. within the WEHI-wide student intern group in Teams > Files), you should have a Technical notes folder for your intake eg. Semester 2 2023 Technical notes. This is to help future students understand what you did in detail to get your results. This also includes things that should not be made public. So descriptions of where you put data or how you ran a script on Milton should not be made public and should go in Sharepoint.\n",
      "Topic: FAQ\n",
      "Keywords: notes, public, sharepoint, technical, understand\n",
      "----------------------------------------\n",
      "Title: How should I ask for help to solve a problem?\n",
      "Content: There is a way to escalate how to ask for help. This shows you how you can do your proper due diligence before you send your supervsior an email with a question.\n",
      "Topic: FAQ\n",
      "Keywords: ask, diligence, email, escalate, help\n",
      "----------------------------------------\n",
      "Title: What are the key things to do before the weekly meetings?\n",
      "Content: Key things to do before for the regular weekly meeting (yes even the first one that is usually in week 2 although it will be mostly empty):\n",
      "Topic: FAQ\n",
      "Keywords: key, meeting, meetings, things, weekly\n",
      "----------------------------------------\n",
      "Title: What happens over Christmas / New Year / Easter period?\n",
      "Content: We take a break between Christmas and New Year, as well as the first week of January as well. During the time away there is no need to write and send the weekly update email during the break. We do encourage you to write down questions and what you have done in your technical diary so that you can ask questions when we are back in the second week of January.\n",
      "Topic: FAQ\n",
      "Keywords: january, new, questions, week, write\n",
      "----------------------------------------\n",
      "Title: What do I need to do for my final presentation and summary report?\n",
      "Content: The final presentation and summary report are due on the last week of the internship. They are usually done at the same time as the regular weekly project meeting. It is important to provide an early draft and a late draft to your supervisors for both the final presentation and the summary report. The early draft is to make sure you are on the right track, and the late draft is to polish things. Please put them into Teams Files / Sharepoint so that they can be commented on directly by your supervisors.\n",
      "Topic: FAQ\n",
      "Keywords: draft, final, presentation, report, summary\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from rake_nltk import Rake\n",
    "\n",
    "# Function to generate keywords using TF-IDF\n",
    "def generate_keywords_tfidf(content, top_n=5):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_features=top_n)\n",
    "    X = vectorizer.fit_transform([content])\n",
    "    keywords = vectorizer.get_feature_names_out()\n",
    "    return list(keywords)\n",
    "\n",
    "# Function to generate keywords using RAKE\n",
    "def generate_keywords_rake(content, top_n=5):\n",
    "    r = Rake()\n",
    "    r.extract_keywords_from_text(content)\n",
    "    ranked_phrases = r.get_ranked_phrases()\n",
    "    return ranked_phrases[:top_n]\n",
    "\n",
    "# Function to scrape data\n",
    "def scrape_web_page(url):\n",
    "    # Send a GET request to the web page\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check for successful response\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch page: {response.status_code}\")\n",
    "        return None\n",
    "    \n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Define the structure to store scraped data\n",
    "    documents = []\n",
    "    \n",
    "    # Locate FAQ sections by inspecting the page structure\n",
    "    faq_titles = soup.find_all('h2')  # Adjust based on observed structure\n",
    "    \n",
    "    for title in faq_titles:\n",
    "        # Extract the question title\n",
    "        question = title.text.strip()\n",
    "        \n",
    "        # Extract the answer (assume it's the next sibling paragraph or list)\n",
    "        answer = title.find_next('p').text.strip() if title.find_next('p') else \"No answer found\"\n",
    "        \n",
    "        # Combine question and answer for keyword generation\n",
    "        content = question + \" \" + answer\n",
    "        \n",
    "        # Generate keywords using one of the methods\n",
    "        keywords = generate_keywords_tfidf(content)  # Use TF-IDF\n",
    "        # keywords = generate_keywords_rake(content)  # Uncomment to use RAKE\n",
    "        \n",
    "        # Append the data\n",
    "        documents.append({\n",
    "            \"title\": question,\n",
    "            \"content\": answer,\n",
    "            \"topic\": \"FAQ\",  # You can categorize manually or scrape additional context\n",
    "            \"keywords\": keywords\n",
    "        })\n",
    "    \n",
    "    return documents\n",
    "\n",
    "# URL of the webpage\n",
    "url = \"https://wehi-researchcomputing.github.io/faq#how-should-i-ask-for-help-to-solve-a-problem\"  \n",
    "\n",
    "# Scrape the webpage\n",
    "data = scrape_web_page(url)\n",
    "\n",
    "# Print the scraped data\n",
    "if data:\n",
    "    for doc in data:\n",
    "        print(f\"Title: {doc['title']}\")\n",
    "        print(f\"Content: {doc['content']}\")\n",
    "        print(f\"Topic: {doc['topic']}\")\n",
    "        print(f\"Keywords: {', '.join(doc['keywords'])}\")\n",
    "        print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a354a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rake-nltkNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading rake_nltk-1.0.6-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.6.2 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from rake-nltk) (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from click->nltk<4.0.0,>=3.6.2->rake-nltk) (0.4.6)\n",
      "Downloading rake_nltk-1.0.6-py3-none-any.whl (9.1 kB)\n",
      "Installing collected packages: rake-nltk\n",
      "Successfully installed rake-nltk-1.0.6\n"
     ]
    }
   ],
   "source": [
    "pip install rake-nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a39ea0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'How do I know if I am eligible?', 'content': 'For the enginering students, please contact engit-placements [at] unimelb [dot] edu [dot] au. For the data science and maths students, please contact science-industry-internships[at] unimelb [dot] edu [dot] au.', 'topic': 'FAQ', 'keywords': ['au', 'contact', 'dot', 'edu', 'science']}, {'title': 'How flexible are the starting dates?', 'content': 'We are flexible. We aim to keep the same starting dates for everyone to make it easier to put people into the WEHI system, but the actual date you start can be flexible. You could start a week or two later if you need to. We are also flexible if you need to take time off during the internship as well.', 'topic': 'FAQ', 'keywords': ['dates', 'flexible', 'need', 'start', 'starting']}, {'title': 'Where are the details I need to fill in my form?', 'content': 'You can find the information here:', 'topic': 'FAQ', 'keywords': ['details', 'form', 'information', 'need']}, {'title': 'I know that the internships are usually 100% offsite, but what if I want to go into the office sometimes?', 'content': 'We are open to having some opportunities to go to the office, especially if we can catchup with the other students. It would not be that regular though, but this can be discussed with other students.', 'topic': 'FAQ', 'keywords': ['100', 'catchup', 'discussed', 'office', 'students']}, {'title': 'How do I know you won’t get disengaged with the students?', 'content': 'We are committed to providing guidance, support, and mentorship throughout their internship experience. We recognize the importance of maintaining open lines of communication and being accessible to address their needs.', 'topic': 'FAQ', 'keywords': ['accessible', 'open', 'providing', 'recognize', 'students']}, {'title': 'What is the difference between data engineering, data analysis, and software engineering?', 'content': 'Data engineering is focused on streamlining and cleaning data systematically. Data analysis is focused on cleaning data and analysing it using statistical or machine learning algorithms. Software engineering is focused on systematising analysis or tools that help us make decisions.', 'topic': 'FAQ', 'keywords': ['analysis', 'cleaning', 'data', 'engineering', 'focused']}, {'title': 'The Workday email says “On your first day, please arrive at 9.00am unless your manager has advised an alternative time and ask for your manager upon arrival at reception.” - is this accurate?', 'content': 'No, it is not accurate. This is a 100% remote internship and that part of the Workday email can be safely ignored. On your first day, you will be scheduled some virtual drop-in sessions so you can meet the supervisor and other interns.', 'topic': 'FAQ', 'keywords': ['accurate', 'day', 'email', 'manager', 'workday']}, {'title': 'I setup my Workday (HR system) through an initial email but now that password doesn’t work or I cannot login to my WEHI email', 'content': 'The links you might have previously used to access Workday before your official start date will no longer allow access.  Email hr [at] wehi [dot] edu [dot] au as this is the contact provided if you encounter any issue in regard to Workday. They will provided you with the new credentials to set up your WEHI email. You may need to go into Incognito mode to get it to work.', 'topic': 'FAQ', 'keywords': ['email', 'provided', 'wehi', 'work', 'workday']}, {'title': 'What courses in Workday do I need to complete?', 'content': 'These are the key courses you need to do:', 'topic': 'FAQ', 'keywords': ['complete', 'courses', 'key', 'need', 'workday']}, {'title': 'How do I get access to the WEHI-wide student intern group using my WEHI email address?', 'content': 'To get access to WEHI-wide student intern group using your WEHI email address. We need to do this as we will be deleting the unimelb email access once everyone has their WEHI email addresses.', 'topic': 'FAQ', 'keywords': ['access', 'address', 'email', 'group', 'wehi']}, {'title': 'Given that the internship is remote, am I allowed to complete the internship while on travel?', 'content': 'Yes, that is correct.', 'topic': 'FAQ', 'keywords': ['allowed', 'complete', 'correct', 'given', 'internship']}, {'title': 'The description stated that so many hrs per week is expected, but at roughly which times and for how long?', 'content': 'As it is remote, we are very flexible but there are times when we do get together, such as the weekly project meeting. This is explained in the Student Internship Handbook.', 'topic': 'FAQ', 'keywords': ['description', 'roughly', 'stated', 'student', 'times']}, {'title': 'I need to use storage and compute. What are my options?', 'content': 'We have a few options at WEHI for storage and compute.', 'topic': 'FAQ', 'keywords': ['compute', 'need', 'options', 'storage', 'use']}, {'title': 'If I want to use Nectar, what suggestions would you have?', 'content': 'Make sure you use “Any Availability Zone” if you are using Nectar as some of the University of Melbourne hosts are full.', 'topic': 'FAQ', 'keywords': ['availability', 'hosts', 'make', 'nectar', 'use']}, {'title': 'Is it OK for me to post on social media?', 'content': 'Yes, but please read the Social Media Policy for student interns.', 'topic': 'FAQ', 'keywords': ['interns', 'media', 'ok', 'policy', 'social']}, {'title': 'My project is complex and ambiguous - what can I do to deal with this?', 'content': 'All of the projects are complex and ambiguous.', 'topic': 'FAQ', 'keywords': ['ambiguous', 'complex', 'deal', 'project', 'projects']}, {'title': 'What is the overall structure of the internship going to look like?', 'content': 'To understand how the overall process of the project please look at the Key milestones and onboarding emails page.', 'topic': 'FAQ', 'keywords': ['emails', 'going', 'internship', 'look', 'overall']}, {'title': 'You ask us to be as independent as possible. How can we do that?', 'content': 'Rules of thumb for being independent:', 'topic': 'FAQ', 'keywords': ['ask', 'independent', 'possible', 'rules', 'thumb']}, {'title': 'We are required to interview a number of people to gather insight into their career pathway. How can I arrange this with you?', 'content': 'You can see more in Ask About Career on page 25 of the RCP Student Onboarding Checklist', 'topic': 'FAQ', 'keywords': ['25', 'arrange', 'ask', 'career', 'checklist']}, {'title': 'We are required to request supervisor signature for the Work Log. How can I arrange this with you?', 'content': 'For those doing the Bachelor of Science or the Master of Data Science course, it is required to complete this supervisor signature work using DocuSign. This ensures that your work log is verified accurately and submitted on time.', 'topic': 'FAQ', 'keywords': ['required', 'science', 'signature', 'supervisor', 'work']}, {'title': 'What should I put in the public wiki?', 'content': 'The public wiki is to share information with future students the things you needed to understand at a high level to be able to start working on the technical side of the project.', 'topic': 'FAQ', 'keywords': ['able', 'future', 'high', 'public', 'wiki']}, {'title': 'What should I put in my technical diary?', 'content': 'Within your project channel in Sharepoint (ie. within the WEHI-wide student intern group in Teams > Files), you should have a Technical notes folder for your intake eg. Semester 2 2023 Technical notes. This is to help future students understand what you did in detail to get your results. This also includes things that should not be made public. So descriptions of where you put data or how you ran a script on Milton should not be made public and should go in Sharepoint.', 'topic': 'FAQ', 'keywords': ['notes', 'public', 'sharepoint', 'technical', 'understand']}, {'title': 'How should I ask for help to solve a problem?', 'content': 'There is a way to escalate how to ask for help. This shows you how you can do your proper due diligence before you send your supervsior an email with a question.', 'topic': 'FAQ', 'keywords': ['ask', 'diligence', 'email', 'escalate', 'help']}, {'title': 'What are the key things to do before the weekly meetings?', 'content': 'Key things to do before for the regular weekly meeting (yes even the first one that is usually in week 2 although it will be mostly empty):', 'topic': 'FAQ', 'keywords': ['key', 'meeting', 'meetings', 'things', 'weekly']}, {'title': 'What happens over Christmas / New Year / Easter period?', 'content': 'We take a break between Christmas and New Year, as well as the first week of January as well. During the time away there is no need to write and send the weekly update email during the break. We do encourage you to write down questions and what you have done in your technical diary so that you can ask questions when we are back in the second week of January.', 'topic': 'FAQ', 'keywords': ['january', 'new', 'questions', 'week', 'write']}, {'title': 'What do I need to do for my final presentation and summary report?', 'content': 'The final presentation and summary report are due on the last week of the internship. They are usually done at the same time as the regular weekly project meeting. It is important to provide an early draft and a late draft to your supervisors for both the final presentation and the summary report. The early draft is to make sure you are on the right track, and the late draft is to polish things. Please put them into Teams Files / Sharepoint so that they can be commented on directly by your supervisors.', 'topic': 'FAQ', 'keywords': ['draft', 'final', 'presentation', 'report', 'summary']}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from rake_nltk import Rake\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Connect to Neo4j\n",
    "driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"12345678\"))\n",
    "\n",
    "# Function to generate keywords using TF-IDF\n",
    "def generate_keywords_tfidf(content, top_n=5):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_features=top_n)\n",
    "    X = vectorizer.fit_transform([content])\n",
    "    keywords = vectorizer.get_feature_names_out()\n",
    "    return list(keywords)\n",
    "\n",
    "# Function to generate keywords using RAKE\n",
    "def generate_keywords_rake(content, top_n=5):\n",
    "    r = Rake()\n",
    "    r.extract_keywords_from_text(content)\n",
    "    ranked_phrases = r.get_ranked_phrases()\n",
    "    return ranked_phrases[:top_n]\n",
    "\n",
    "# Function to scrape data\n",
    "def scrape_web_page(url):\n",
    "    # Send a GET request to the web page\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check for successful response\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch page: {response.status_code}\")\n",
    "        return None\n",
    "    \n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Define the structure to store scraped data\n",
    "    documents = []\n",
    "    \n",
    "    # Locate FAQ sections by inspecting the page structure\n",
    "    faq_titles = soup.find_all('h2')  # Adjust based on observed structure\n",
    "    \n",
    "    for title in faq_titles:\n",
    "        # Extract the question title\n",
    "        question = title.text.strip()\n",
    "        \n",
    "        # Extract the answer (assume it's the next sibling paragraph or list)\n",
    "        answer = title.find_next('p').text.strip() if title.find_next('p') else \"No answer found\"\n",
    "        \n",
    "        # Combine question and answer for keyword generation\n",
    "        content = question + \" \" + answer\n",
    "        \n",
    "        # Generate keywords using one of the methods\n",
    "        keywords = generate_keywords_tfidf(content)  # Use TF-IDF\n",
    "        # keywords = generate_keywords_rake(content)  # Uncomment to use RAKE\n",
    "        \n",
    "        # Append the data\n",
    "        documents.append({\n",
    "            \"title\": question,\n",
    "            \"content\": answer,\n",
    "            \"topic\": \"FAQ\",  # You can categorize manually or scrape additional context\n",
    "            \"keywords\": keywords\n",
    "        })\n",
    "    \n",
    "    return documents\n",
    "\n",
    "# Function to insert data into Neo4j\n",
    "def insert_into_neo4j(documents):\n",
    "    with driver.session() as session:\n",
    "        for doc in documents:\n",
    "            # Create Document node\n",
    "            session.run(\n",
    "                \"\"\"\n",
    "                MERGE (d:Document {title: $title, content: $content, topic: $topic})\n",
    "                \"\"\",\n",
    "                title=doc['title'], content=doc['content'], topic=doc['topic']\n",
    "            )\n",
    "            \n",
    "            # Create Keyword nodes and relationships\n",
    "            for keyword in doc['keywords']:\n",
    "                session.run(\n",
    "                    \"\"\"\n",
    "                    MERGE (k:Keyword {name: $keyword})\n",
    "                    MERGE (d:Document {title: $title})\n",
    "                    MERGE (d)-[:HAS_KEYWORD]->(k)\n",
    "                    \"\"\",\n",
    "                    keyword=keyword, title=doc['title']\n",
    "                )\n",
    "\n",
    "# URL of the webpage\n",
    "url = \"https://wehi-researchcomputing.github.io/faq#how-should-i-ask-for-help-to-solve-a-problem\"  \n",
    "\n",
    "# Scrape the webpage\n",
    "data = scrape_web_page(url)\n",
    "print(data)\n",
    "\n",
    "# Insert data into Neo4j\n",
    "if data:\n",
    "    insert_into_neo4j(data)\n",
    "    print(\"Data inserted into Neo4j successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "828fd83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: How do I know if I am eligible?\n",
      "Content: For the enginering students, please contact engit-placements [at] unimelb [dot] edu [dot] au. For the data science and maths students, please contact science-industry-internships[at] unimelb [dot] edu [dot] au.\n",
      "----------------------------------------\n",
      "Title: How flexible are the starting dates?\n",
      "Content: We are flexible. We aim to keep the same starting dates for everyone to make it easier to put people into the WEHI system, but the actual date you start can be flexible. You could start a week or two later if you need to. We are also flexible if you need to take time off during the internship as well.\n",
      "----------------------------------------\n",
      "Title: Where are the details I need to fill in my form?\n",
      "Content: You can find the information here:\n",
      "----------------------------------------\n",
      "Title: I know that the internships are usually 100% offsite, but what if I want to go into the office sometimes?\n",
      "Content: We are open to having some opportunities to go to the office, especially if we can catchup with the other students. It would not be that regular though, but this can be discussed with other students.\n",
      "----------------------------------------\n",
      "Title: How do I know you won’t get disengaged with the students?\n",
      "Content: We are committed to providing guidance, support, and mentorship throughout their internship experience. We recognize the importance of maintaining open lines of communication and being accessible to address their needs.\n",
      "----------------------------------------\n",
      "Title: What is the difference between data engineering, data analysis, and software engineering?\n",
      "Content: Data engineering is focused on streamlining and cleaning data systematically. Data analysis is focused on cleaning data and analysing it using statistical or machine learning algorithms. Software engineering is focused on systematising analysis or tools that help us make decisions.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Connect to Neo4j\n",
    "driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"12345678\"))\n",
    "\n",
    "def get_first_records(limit=10):\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\n",
    "            \"\"\"\n",
    "            MATCH (d:Document)\n",
    "            RETURN d.title AS title, d.content AS content\n",
    "            LIMIT $limit\n",
    "            \"\"\",\n",
    "            limit=limit\n",
    "        )\n",
    "        return [{\"title\": record[\"title\"], \"content\": record[\"content\"]} for record in result]\n",
    "\n",
    "# Fetch the first 6 records\n",
    "documents = get_first_records(limit=6)\n",
    "\n",
    "# Print the records\n",
    "for doc in documents:\n",
    "    print(f\"Title: {doc['title']}\")\n",
    "    print(f\"Content: {doc['content']}\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f5abaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: What happens over Christmas / New Year / Easter period?\n",
      "Content: We take a break between Christmas and New Year, as well as the first week of January as well. During the time away there is no need to write and send the weekly update email during the break. We do encourage you to write down questions and what you have done in your technical diary so that you can ask questions when we are back in the second week of January.\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Connect to Neo4j\n",
    "driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"12345678\"))\n",
    "\n",
    "def get_documents_by_keyword(keyword):\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\n",
    "            \"\"\"\n",
    "            MATCH (d:Document)\n",
    "            WHERE d.title CONTAINS $keyword\n",
    "            RETURN d.title AS title, d.content AS content\n",
    "            \"\"\",\n",
    "            keyword=keyword\n",
    "        )\n",
    "        return [{\"title\": record[\"title\"], \"content\": record[\"content\"]} for record in result]\n",
    "\n",
    "# Fetch documents containing \"Christmas\" in their title\n",
    "docs = get_documents_by_keyword(\"Christmas\")\n",
    "\n",
    "# Print the results\n",
    "for doc in docs:\n",
    "    print(f\"Title: {doc['title']}\\nContent: {doc['content']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0091e63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\omidm\\anaconda3\\lib\\site-packages (0.1.0)\n",
      "Requirement already satisfied: neo4j in c:\\users\\omidm\\anaconda3\\lib\\site-packages (5.26.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\omidm\\anaconda3\\lib\\site-packages (4.43.0.dev0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain) (3.8.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain) (0.6.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.9 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain) (0.0.12)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.7 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain) (0.1.23)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.77 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain) (0.0.87)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: pytz in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from neo4j) (2022.7)\n",
      "Requirement already satisfied: filelock in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.7->langchain) (3.5.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.7->langchain) (1.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (0.4.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain neo4j transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c93ead01",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not use APOC procedures. Please ensure the APOC plugin is installed in Neo4j and that 'apoc.meta.data()' is allowed in Neo4j configuration ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_community\\graphs\\neo4j_graph.py:89\u001b[0m, in \u001b[0;36mNeo4jGraph.__init__\u001b[1;34m(self, url, username, password, database)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 89\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefresh_schema()\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m neo4j\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mClientError:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_community\\graphs\\neo4j_graph.py:122\u001b[0m, in \u001b[0;36mNeo4jGraph.refresh_schema\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;124;03mRefreshes the Neo4j graph schema information.\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m node_properties \u001b[38;5;241m=\u001b[39m [el[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery(node_properties_query)]\n\u001b[0;32m    123\u001b[0m rel_properties \u001b[38;5;241m=\u001b[39m [el[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery(rel_properties_query)]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_community\\graphs\\neo4j_graph.py:113\u001b[0m, in \u001b[0;36mNeo4jGraph.query\u001b[1;34m(self, query, params)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 113\u001b[0m     data \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mrun(query, params)\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [r\u001b[38;5;241m.\u001b[39mdata() \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m data]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\neo4j\\_sync\\work\\session.py:327\u001b[0m, in \u001b[0;36mSession.run\u001b[1;34m(self, query, parameters, **kwargs)\u001b[0m\n\u001b[0;32m    326\u001b[0m parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(parameters \u001b[38;5;129;01mor\u001b[39;00m {}, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 327\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_auto_result\u001b[38;5;241m.\u001b[39m_run(\n\u001b[0;32m    328\u001b[0m     query,\n\u001b[0;32m    329\u001b[0m     parameters,\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mdatabase,\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mimpersonated_user,\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mdefault_access_mode,\n\u001b[0;32m    333\u001b[0m     bookmarks,\n\u001b[0;32m    334\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mnotifications_min_severity,\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mnotifications_disabled_classifications,\n\u001b[0;32m    336\u001b[0m )\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_auto_result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\neo4j\\_sync\\work\\result.py:231\u001b[0m, in \u001b[0;36mResult._run\u001b[1;34m(self, query, parameters, db, imp_user, access_mode, bookmarks, notifications_min_severity, notifications_disabled_classifications)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39msend_all()\n\u001b[1;32m--> 231\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attach()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\neo4j\\_sync\\work\\result.py:425\u001b[0m, in \u001b[0;36mResult._attach\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m--> 425\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mfetch_message()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\neo4j\\_sync\\io\\_common.py:184\u001b[0m, in \u001b[0;36mConnectionErrorHandler.__getattr__.<locals>.outer.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 184\u001b[0m     func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (Neo4jError, ServiceUnavailable, SessionExpired) \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py:994\u001b[0m, in \u001b[0;36mBolt.fetch_message\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    991\u001b[0m tag, fields \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minbox\u001b[38;5;241m.\u001b[39mpop(\n\u001b[0;32m    992\u001b[0m     hydration_hooks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponses[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mhydration_hooks\n\u001b[0;32m    993\u001b[0m )\n\u001b[1;32m--> 994\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_message(tag, fields)\n\u001b[0;32m    995\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midle_since \u001b[38;5;241m=\u001b[39m monotonic()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\neo4j\\_sync\\io\\_bolt5.py:496\u001b[0m, in \u001b[0;36mBolt5x0._process_message\u001b[1;34m(self, tag, fields)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 496\u001b[0m     response\u001b[38;5;241m.\u001b[39mon_failure(summary_metadata \u001b[38;5;129;01mor\u001b[39;00m {})\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ServiceUnavailable, DatabaseUnavailable):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\neo4j\\_sync\\io\\_common.py:254\u001b[0m, in \u001b[0;36mResponse.on_failure\u001b[1;34m(self, metadata)\u001b[0m\n\u001b[0;32m    253\u001b[0m Util\u001b[38;5;241m.\u001b[39mcallback(handler)\n\u001b[1;32m--> 254\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hydrate_error(metadata)\n",
      "\u001b[1;31mClientError\u001b[0m: {code: Neo.ClientError.Procedure.ProcedureNotFound} {message: There is no procedure with the name `apoc.meta.data` registered for this database instance. Please ensure you've spelled the procedure name correctly and that the procedure is properly deployed.}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraphs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Neo4jGraph\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Connect to Neo4j database\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m graph \u001b[38;5;241m=\u001b[39m Neo4jGraph(\n\u001b[0;32m      7\u001b[0m     url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbolt://localhost:7687\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Adjust if you're using a different port\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     username\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneo4j\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      9\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m12345678\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Verify the connection\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(graph\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMATCH (n) RETURN COUNT(n) AS node_count\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\langchain_community\\graphs\\neo4j_graph.py:91\u001b[0m, in \u001b[0;36mNeo4jGraph.__init__\u001b[1;34m(self, url, username, password, database)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefresh_schema()\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m neo4j\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mClientError:\n\u001b[1;32m---> 91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     92\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not use APOC procedures. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the APOC plugin is installed in Neo4j and that \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapoc.meta.data()\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is allowed in Neo4j configuration \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     95\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Could not use APOC procedures. Please ensure the APOC plugin is installed in Neo4j and that 'apoc.meta.data()' is allowed in Neo4j configuration "
     ]
    }
   ],
   "source": [
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.graphs import Neo4jGraph\n",
    "\n",
    "# Connect to Neo4j database\n",
    "graph = Neo4jGraph(\n",
    "    url=\"bolt://localhost:7687\",  # Adjust if you're using a different port\n",
    "    username=\"neo4j\",\n",
    "    password=\"12345678\"\n",
    ")\n",
    "\n",
    "# Verify the connection\n",
    "print(graph.query(\"MATCH (n) RETURN COUNT(n) AS node_count\"))\n",
    "# Initialize the LLM (e.g., OpenAI GPT)\n",
    "llm = OpenAI(temperature=0, model=\"text-davinci-003\")  # Ensure the model matches your setup\n",
    "\n",
    "# Set up LangChain's GraphCypherQAChain\n",
    "chain = GraphCypherQAChain.from_llm(llm=llm, graph=graph)\n",
    "\n",
    "# Example query\n",
    "query = \"What documents are related to Christmas?\"\n",
    "response = chain.run(query)\n",
    "\n",
    "# Output the result\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dec83679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "class Neo4jQueryTool:\n",
    "    def __init__(self, uri, user, password):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "    def query(self, cypher_query, params=None):\n",
    "        with self.driver.session() as session:\n",
    "            return session.run(cypher_query, params)\n",
    "\n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "\n",
    "# Initialize Neo4j Tool\n",
    "neo4j_tool = Neo4jQueryTool(\"bolt://localhost:7687\", \"neo4j\", \"12345678\")\n",
    "with neo4j_tool.driver.session() as session:\n",
    "    result = session.run(\"RETURN 'Connection successful' AS message\")\n",
    "    print(result.single()[\"message\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5960d0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain 0.1.0 requires langchain-core<0.2,>=0.1.7, but you have langchain-core 0.3.21 which is incompatible.\n",
      "langchain 0.1.0 requires langsmith<0.1.0,>=0.0.77, but you have langsmith 0.1.147 which is incompatible.\n",
      "langchain-community 0.0.12 requires langchain-core<0.2,>=0.1.9, but you have langchain-core 0.3.21 which is incompatible.\n",
      "langchain-community 0.0.12 requires langsmith<0.1.0,>=0.0.63, but you have langsmith 0.1.147 which is incompatible.\n",
      "langchain-openai 0.0.2 requires langchain-core<0.2,>=0.1.7, but you have langchain-core 0.3.21 which is incompatible.\n",
      "langchain-text-splitters 0.2.2 requires langchain-core<0.3.0,>=0.2.10, but you have langchain-core 0.3.21 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in c:\\users\\omidm\\anaconda3\\lib\\site-packages (0.8.3)\n",
      "Collecting langchain-google-genai\n",
      "  Downloading langchain_google_genai-2.0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting streamlit\n",
      "  Downloading streamlit-1.40.2-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from google-generativeai) (0.6.10)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from google-generativeai) (2.23.0)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from google-generativeai) (2.154.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from google-generativeai) (2.22.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from google-generativeai) (5.28.3)\n",
      "Requirement already satisfied: pydantic in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from google-generativeai) (2.8.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from google-generativeai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from google-ai-generativelanguage==0.6.10->google-generativeai) (1.25.0)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain-google-genai) (1.2.0)\n",
      "Collecting langchain-core<0.4,>=0.3.15 (from langchain-google-genai)\n",
      "  Downloading langchain_core-0.3.21-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting altair<6,>=4.0 (from streamlit)\n",
      "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.0.0 (from streamlit)\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from streamlit) (5.3.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from streamlit) (8.0.4)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from streamlit) (1.24.3)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from streamlit) (23.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from streamlit) (1.5.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from streamlit) (10.4.0)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from streamlit) (11.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from streamlit) (13.3.5)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from streamlit) (8.2.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from streamlit) (2.1.6)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from streamlit) (3.1.43)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from streamlit) (6.3.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.17.3)\n",
      "Collecting narwhals>=1.14.2 (from altair<6,>=4.0->streamlit)\n",
      "  Downloading narwhals-1.15.1-py3-none-any.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (1.63.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (1.16.0)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (1.26.20)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain-core<0.4,>=0.3.15->langchain-google-genai) (6.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langchain-core<0.4,>=0.3.15->langchain-google-genai) (1.33)\n",
      "Collecting langsmith<0.2.0,>=0.1.125 (from langchain-core<0.4,>=0.3.15->langchain-google-genai)\n",
      "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2022.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2024.7.4)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.15.1)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.68.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.68.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.15->langchain-google-genai) (2.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (3.10.6)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (1.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.4.8)\n",
      "Requirement already satisfied: anyio in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (3.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (1.0.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\omidm\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (0.14.0)\n",
      "Downloading langchain_google_genai-2.0.6-py3-none-any.whl (41 kB)\n",
      "   ---------------------------------------- 0.0/41.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 41.3/41.3 kB ? eta 0:00:00\n",
      "Downloading streamlit-1.40.2-py2.py3-none-any.whl (8.6 MB)\n",
      "   ---------------------------------------- 0.0/8.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/8.6 MB 6.7 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.6/8.6 MB 7.0 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.6/8.6 MB 5.1 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.0/8.6 MB 5.7 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.3/8.6 MB 5.9 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.6/8.6 MB 5.7 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.9/8.6 MB 6.1 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.2/8.6 MB 6.2 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.5/8.6 MB 6.0 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.8/8.6 MB 6.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.1/8.6 MB 6.2 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 3.4/8.6 MB 6.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 3.7/8.6 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.1/8.6 MB 6.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 4.4/8.6 MB 6.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 4.7/8.6 MB 6.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.0/8.6 MB 6.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.3/8.6 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 5.6/8.6 MB 6.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 5.9/8.6 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 6.2/8.6 MB 6.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.4/8.6 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.8/8.6 MB 6.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.1/8.6 MB 6.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.3/8.6 MB 6.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.6/8.6 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.0/8.6 MB 6.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.3/8.6 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.6/8.6 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.6/8.6 MB 6.4 MB/s eta 0:00:00\n",
      "Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "   ---------------------------------------- 0.0/731.2 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 256.0/731.2 kB 7.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 563.2/731.2 kB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 731.2/731.2 kB 6.6 MB/s eta 0:00:00\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading langchain_core-0.3.21-py3-none-any.whl (409 kB)\n",
      "   ---------------------------------------- 0.0/409.5 kB ? eta -:--:--\n",
      "   --------------------------- ------------ 276.5/409.5 kB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 409.5/409.5 kB 6.3 MB/s eta 0:00:00\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "   ---------------------------------------- 0.0/6.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/6.9 MB 7.7 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 0.6/6.9 MB 7.5 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.9/6.9 MB 7.3 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.2/6.9 MB 6.7 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 1.5/6.9 MB 7.1 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 1.7/6.9 MB 6.8 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 2.0/6.9 MB 6.8 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.4/6.9 MB 6.8 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 2.7/6.9 MB 6.8 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 2.9/6.9 MB 6.7 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 3.2/6.9 MB 6.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 3.5/6.9 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 3.8/6.9 MB 6.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 4.1/6.9 MB 6.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 4.4/6.9 MB 6.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 4.6/6.9 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.9/6.9 MB 6.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 5.3/6.9 MB 6.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 5.6/6.9 MB 6.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.8/6.9 MB 6.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 6.2/6.9 MB 6.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 6.5/6.9 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.9/6.9 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.9/6.9 MB 6.7 MB/s eta 0:00:00\n",
      "Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
      "   ---------------------------------------- 0.0/311.8 kB ? eta -:--:--\n",
      "   ---------------------------------------  307.2/311.8 kB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 311.8/311.8 kB 6.4 MB/s eta 0:00:00\n",
      "Downloading narwhals-1.15.1-py3-none-any.whl (232 kB)\n",
      "   ---------------------------------------- 0.0/232.5 kB ? eta -:--:--\n",
      "   -------------------------------------- - 225.3/232.5 kB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 232.5/232.5 kB 4.7 MB/s eta 0:00:00\n",
      "Installing collected packages: narwhals, blinker, pydeck, altair, streamlit, langsmith, langchain-core, langchain-google-genai\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.0.87\n",
      "    Uninstalling langsmith-0.0.87:\n",
      "      Successfully uninstalled langsmith-0.0.87\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.1.23\n",
      "    Uninstalling langchain-core-0.1.23:\n",
      "      Successfully uninstalled langchain-core-0.1.23\n",
      "Successfully installed altair-5.5.0 blinker-1.9.0 langchain-core-0.3.21 langchain-google-genai-2.0.6 langsmith-0.1.147 narwhals-1.15.1 pydeck-0.9.1 streamlit-1.40.2\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "1. **Mars:** The Red Planet has polar ice caps which contain more water ice than the Earth's polar ice caps combined.\n",
       "2. **Saturn:** The ringed planet has a hexagonal-shaped storm at its north pole that is about twice the size of Earth.\n",
       "3. **Neptune:** The blue planet has a magnetic field that is 27 times stronger than Earth's, making it the second strongest magnetic field in the Solar System after Jupiter's.\n",
       "4. **Venus:** The hottest planet in the Solar System, Venus has a surface temperature of about 864 degrees Fahrenheit (462 degrees Celsius).\n",
       "5. **Jupiter:** The largest planet in the Solar System, Jupiter has a Great Red Spot, a storm that has been raging for at least 300 years and is twice the size of Earth."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "!pip install google-generativeai langchain-google-genai streamlit\n",
    "\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "from IPython.display import Markdown\n",
    "\n",
    "# Set API key securely in the environment\n",
    "os.environ['GOOGLE_API_KEY'] = \"AIzaSyDpTvl6KQLte4DksHn83iYDbhZlARYig8Y\"  # Replace with your actual API key\n",
    "genai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n",
    "\n",
    "# Instantiate the GenerativeModel with the 'gemini-pro' model\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "# Generate content for the first prompt\n",
    "response1 = model.generate_content(\"List 5 planets each with an interesting fact\")\n",
    "Markdown(response1.text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93e062fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Key Points:**\n",
      "\n",
      "* **Eligibility:** Engineering students contact engit-placements@unimelb.edu.au, while data science and math students contact science-industry-internships@unimelb.edu.au.\n",
      "* **Flexibility:** Starting dates and time off are negotiable.\n",
      "* **Form details:** Available at a specified link.\n",
      "* **Work environment:** Internships are typically remote, but office visits may be possible for catch-ups.\n",
      "* **Guidance:** Students receive support and mentorship from the company.\n",
      "* **Disciplinary distinctions:** Data engineering focuses on data management, data analysis on statistical and machine learning analysis, and software engineering on systematization of analysis tools.\n",
      "\n",
      "**Advice:**\n",
      "\n",
      "* Contact the appropriate email address for eligibility inquiries.\n",
      "* Be flexible with starting dates and time off requests.\n",
      "* Fill out the form completely and accurately.\n",
      "* Communicate with the company if you desire any office visits.\n",
      "* Trust in the company's commitment to providing guidance and support.\n",
      "* Research the different disciplines and choose the one that aligns with your interests and career goals.\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "from IPython.display import Markdown\n",
    "\n",
    "# Set up Neo4j connection\n",
    "class Neo4jQueryTool:\n",
    "    def __init__(self, uri, user, password):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "    def query(self, cypher_query, params=None):\n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(cypher_query, params)\n",
    "            # Explicitly fetch all records into a list before processing\n",
    "            return list(result)\n",
    "\n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "\n",
    "# Initialize Neo4j Tool\n",
    "neo4j_tool = Neo4jQueryTool(\"bolt://localhost:7687\", \"neo4j\", \"12345678\")\n",
    "\n",
    "# Set up Google Gemini LLM API key\n",
    "os.environ['GOOGLE_API_KEY'] = \"AIzaSyDpTvl6KQLte4DksHn83iYDbhZlARYig8Y\"  # Replace with your actual API key\n",
    "genai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n",
    "\n",
    "# Instantiate the GenerativeModel with the 'gemini-pro' model\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "# Function to fetch data from Neo4j and pass it to Gemini LLM\n",
    "def fetch_and_generate_content(limit=6):\n",
    "    # Query Neo4j to retrieve the first 6 document titles and contents\n",
    "    result = neo4j_tool.query(\"\"\"\n",
    "        MATCH (d:Document)\n",
    "        RETURN d.title AS title, d.content AS content\n",
    "        LIMIT $limit\n",
    "    \"\"\", {\"limit\": limit})\n",
    "    \n",
    "    # Format the result into a string suitable for the LLM\n",
    "    document_info = \"\\n\".join([f\"Title: {record['title']}\\nContent: {record['content']}\" for record in result])\n",
    "    \n",
    "    # Construct the prompt for the LLM\n",
    "    prompt = f\"Here are the details of some documents:\\n{document_info}\\nCan you summarize the key points and provide advice about these documents?\"\n",
    "    \n",
    "    # Generate content from Gemini LLM\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "# Example usage: fetch data and generate content\n",
    "response_text = fetch_and_generate_content(limit=6)\n",
    "print(response_text)\n",
    "\n",
    "# Close the Neo4j tool after use\n",
    "neo4j_tool.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f904c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omidm\\AppData\\Local\\Temp\\ipykernel_30320\\1561249609.py:69: DeprecationWarning: \n",
      "        on_event is deprecated, use lifespan event handlers instead.\n",
      "\n",
      "        Read more about it in the\n",
      "        [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).\n",
      "        \n",
      "  @app.on_event(\"shutdown\")\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from neo4j import GraphDatabase\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "from IPython.display import Markdown\n",
    "\n",
    "# Set up Neo4j connection\n",
    "class Neo4jQueryTool:\n",
    "    def __init__(self, uri, user, password):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "    def query(self, cypher_query, params=None):\n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(cypher_query, params)\n",
    "            # Explicitly fetch all records into a list before processing\n",
    "            return list(result)\n",
    "\n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "\n",
    "# Set up Google Gemini LLM API key\n",
    "os.environ['GOOGLE_API_KEY'] = \"AIzaSyDpTvl6KQLte4DksHn83iYDbhZlARYig8Y\"  # Replace with your actual API key\n",
    "genai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n",
    "\n",
    "# Instantiate the GenerativeModel with the 'gemini-pro' model\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "# FastAPI setup\n",
    "app = FastAPI()\n",
    "\n",
    "# Define input model for the chat interface\n",
    "class QueryModel(BaseModel):\n",
    "    limit: int = 6\n",
    "\n",
    "# Initialize Neo4j Tool\n",
    "neo4j_tool = Neo4jQueryTool(\"bolt://localhost:7687\", \"neo4j\", \"12345678\")\n",
    "\n",
    "# Function to fetch data from Neo4j and pass it to Gemini LLM\n",
    "def fetch_and_generate_content(limit=6):\n",
    "    # Query Neo4j to retrieve the first `limit` document titles and contents\n",
    "    result = neo4j_tool.query(\"\"\"\n",
    "        MATCH (d:Document)\n",
    "        RETURN d.title AS title, d.content AS content\n",
    "        LIMIT $limit\n",
    "    \"\"\", {\"limit\": limit})\n",
    "    \n",
    "    # Format the result into a string suitable for the LLM\n",
    "    document_info = \"\\n\".join([f\"Title: {record['title']}\\nContent: {record['content']}\" for record in result])\n",
    "    \n",
    "    # Construct the prompt for the LLM\n",
    "    prompt = f\"Here are the details of some documents:\\n{document_info}\\nCan you summarize the key points and provide advice about these documents?\"\n",
    "    \n",
    "    # Generate content from Gemini LLM\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "# FastAPI endpoint for chatbot\n",
    "@app.post(\"/chat\")\n",
    "def chat(query: QueryModel):\n",
    "    try:\n",
    "        # Fetch data and generate content\n",
    "        response_text = fetch_and_generate_content(limit=query.limit)\n",
    "        return {\"response\": response_text}\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# Close the Neo4j tool after the app shuts down\n",
    "@app.on_event(\"shutdown\")\n",
    "def shutdown_event():\n",
    "    neo4j_tool.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f2f44dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!uvicorn app:app --reload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc28c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uvicorn app:app --reload --host 0.0.0.0 --port 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62192bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
