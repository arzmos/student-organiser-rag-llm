{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "885ce24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Content from RCP#0032 Intake 10 Student Internship Summary reports (share with all)\n",
      "Content: RCP#0032\n",
      "Intake\n",
      "10\n",
      "Student \n",
      "Internship\n",
      "Summary\n",
      "reports\n",
      "Table\n",
      "of\n",
      "Contents\n",
      "Link\n",
      "to\n",
      "Intake\n",
      "9\n",
      "Summary\n",
      "Report\n",
      "RCP#0016\n",
      "Intake\n",
      "9\n",
      "Student\n",
      "Internship\n",
      "Summary\n",
      "reports.pdf\n",
      "that\n",
      "can\n",
      "be\n",
      "used\n",
      "as\n",
      "an\n",
      "example.AIVE\n",
      "Student\n",
      "Project\n",
      "Interns:\n",
      "Si\n",
      "Yang\n",
      "(Sean)\n",
      "Chen,\n",
      "Chun-Tung\n",
      "(Chloe)\n",
      "Tsai,\n",
      "Jiawen\n",
      "Deng\n",
      "High-Level\n",
      "Domain\n",
      "work\n",
      "During\n",
      "the\n",
      "first\n",
      "4-5\n",
      "weeks,\n",
      "we\n",
      "learned\n",
      "about\n",
      "and\n",
      "tried\n",
      "to\n",
      "understand\n",
      "the\n",
      "AIVE\n",
      "workflow\n",
      "for\n",
      "converting\n",
      "2D\n",
      "cell\n",
      "image\n",
      "stacks\n",
      "into\n",
      "3D\n",
      "models\n",
      "and\n",
      "familiarised\n",
      "ourselves\n",
      "with\n",
      "software\n",
      "tools\n",
      "used\n",
      "in\n",
      "the\n",
      "workflow\n",
      "such\n",
      "as\n",
      "ImageJ,\n",
      "MIB\n",
      "and\n",
      "WEKA.\n",
      "Our\n",
      "in-depth\n",
      "understanding\n",
      "was\n",
      "presented\n",
      "in\n",
      "the\n",
      "whiteboard\n",
      "presentation,\n",
      "which\n",
      "detailed\n",
      "key\n",
      "stages\n",
      "in\n",
      "AIVE’s\n",
      "workflow.\n",
      "The\n",
      "team\n",
      "also\n",
      "developed\n",
      "high-level\n",
      "flowcharts\n",
      "showing\n",
      "the\n",
      "entire\n",
      "process\n",
      "and\n",
      "the\n",
      "interconnected\n",
      "stages.\n",
      "Subsequently ,\n",
      "we\n",
      "decided\n",
      "to\n",
      "work\n",
      "on\n",
      "the\n",
      "organelle\n",
      "segmentation\n",
      "stage.\n",
      "We\n",
      "converted \n",
      "two\n",
      "ImageJ\n",
      "macros\n",
      "(macros\n",
      "1\n",
      "and\n",
      "1b)\n",
      "from\n",
      "ImageJ\n",
      "Macro\n",
      "Language\n",
      "into\n",
      "Python\n",
      "code \n",
      "for\n",
      "better\n",
      "reproducibility .\n",
      "Building\n",
      "on\n",
      "the\n",
      "public\n",
      "wiki\n",
      "created\n",
      "by\n",
      "previous\n",
      "interns,\n",
      "we \n",
      "added\n",
      "technical\n",
      "documentation\n",
      "and\n",
      "additional\n",
      "notes\n",
      "for\n",
      "both\n",
      "our\n",
      "and\n",
      "previous\n",
      "features, \n",
      "including\n",
      "detailed\n",
      "explanations\n",
      "and\n",
      "flowcharts,\n",
      "to\n",
      "help\n",
      "future\n",
      "interns\n",
      "and\n",
      "people\n",
      "without \n",
      "prior\n",
      "knowledge\n",
      "understand\n",
      "AIVE\n",
      "more\n",
      "easily.\n",
      "Architecture\n",
      "/\n",
      "Algorithm\n",
      "work\n",
      "Macro\n",
      "1:Macro\n",
      "1b:\n",
      "Technical\n",
      "work\n",
      "Macro\n",
      "1:\n",
      "Image\n",
      "stack\n",
      "is\n",
      "loaded\n",
      "into\n",
      "program\n",
      "and\n",
      "all\n",
      "unique\n",
      "pixel\n",
      "values\n",
      "in\n",
      "entire\n",
      "stack\n",
      "are \n",
      "computed.\n",
      "These\n",
      "pixel\n",
      "values\n",
      "are\n",
      "used\n",
      "as\n",
      "thresholds,\n",
      "which\n",
      "are\n",
      "applied\n",
      "to\n",
      "each\n",
      "image \n",
      "slice\n",
      "in\n",
      "stack\n",
      "to\n",
      "create\n",
      "stacks\n",
      "of\n",
      "binary\n",
      "masks.\n",
      "The\n",
      "mask\n",
      "stack\n",
      "is\n",
      "saved\n",
      "and\n",
      "this\n",
      "is \n",
      "repeated\n",
      "for\n",
      "each\n",
      "threshold.\n",
      "Macro\n",
      "1b:\n",
      "The\n",
      "process\n",
      "starts\n",
      "by\n",
      "selecting\n",
      "the\n",
      "input\n",
      "image\n",
      "file\n",
      "(\n",
      "HeLa.tiff\n",
      ")\n",
      "and\n",
      "specifying\n",
      "the\n",
      "output \n",
      "directory.\n",
      "A\n",
      "Gaussian\n",
      "blur\n",
      "is\n",
      "then\n",
      "applied\n",
      "with\n",
      "an\n",
      "XYZ\n",
      "radius\n",
      "of\n",
      "X\n",
      "=\n",
      "3,\n",
      "Y\n",
      "=\n",
      "3,\n",
      "and\n",
      "Z\n",
      "=\n",
      "1, \n",
      "chosen\n",
      "to\n",
      "account\n",
      "for\n",
      "the\n",
      "anisotropic\n",
      "voxel\n",
      "dimensions\n",
      "(3\n",
      "nm\n",
      "in\n",
      "X\n",
      "and\n",
      "Y,\n",
      "10\n",
      "nm\n",
      "in\n",
      "Z). \n",
      "These\n",
      "values\n",
      "ensure\n",
      "consistent\n",
      "blurring\n",
      "across\n",
      "the\n",
      "real-world\n",
      "voxel\n",
      "sizes.\n",
      "Users\n",
      "may \n",
      "need\n",
      "to\n",
      "adjust\n",
      "blur\n",
      "parameters\n",
      "or\n",
      "consider\n",
      "kernel\n",
      "size\n",
      "for\n",
      "different\n",
      "datasets.\n",
      "The\n",
      "macro \n",
      "then\n",
      "processes\n",
      "the\n",
      "entire\n",
      "image\n",
      "stack,\n",
      "saving\n",
      "the\n",
      "results\n",
      "in\n",
      "new\n",
      "stacks.\n",
      "Key\n",
      "Links\n",
      "●\n",
      "Whiteboard\n",
      "Presentation:\n",
      "Whiteboard\n",
      "presentation\n",
      "flowchart\n",
      "●\n",
      "Final\n",
      "Presentation:\n",
      "Final\n",
      "Presentation\n",
      "slides\n",
      "●\n",
      "Public\n",
      "GitHub:\n",
      "https://github.com/MitochondRuna/AIVE-Intro/wiki\n",
      "●\n",
      "Python\n",
      "Macros\n",
      "Link:\n",
      "https://github.com/MitochondRuna/AIVE-Intro/ImageJ\n",
      "macros\n",
      "●\n",
      "Personal\n",
      "Technical\n",
      "Notes:\n",
      "Technical\n",
      "Notes\n",
      "Clinical\n",
      "Dashboards\n",
      "Student\n",
      "Project\n",
      "Interns:\n",
      "Kathleen\n",
      "Wongso,\n",
      "Jane\n",
      "Xu,\n",
      "Lucas\n",
      "Valente,\n",
      "Yixin\n",
      "Jiang\n",
      "High-Level\n",
      "Domain\n",
      "work\n",
      "REDCap\n",
      "/\n",
      "Simulacrum\n",
      "Aspect: \n",
      "One\n",
      "of\n",
      "our\n",
      "goals\n",
      "for\n",
      "this\n",
      "aspect\n",
      "of\n",
      "the\n",
      "project\n",
      "was\n",
      "to\n",
      "make\n",
      "use\n",
      "of\n",
      "a\n",
      "larger\n",
      "and\n",
      "more \n",
      "complex\n",
      "dataset\n",
      "(i.e.\n",
      "Simulacrum)\n",
      "than\n",
      "the\n",
      "previous\n",
      "intake\n",
      "used.\n",
      "We\n",
      "aimed\n",
      "to\n",
      "upload \n",
      "as\n",
      "much\n",
      "of\n",
      "the\n",
      "Simulacrum\n",
      "V2\n",
      "data\n",
      "as\n",
      "we\n",
      "could\n",
      "to\n",
      "REDCap,\n",
      "which\n",
      "shaped\n",
      "how\n",
      "we \n",
      "cleaned\n",
      "our\n",
      "dataset.\n",
      "We\n",
      "also\n",
      "wanted\n",
      "to\n",
      "see\n",
      "if\n",
      "we\n",
      "would\n",
      "break\n",
      "REDCap\n",
      "with\n",
      "the\n",
      "new, \n",
      "larger\n",
      "dataset.\n",
      "Security\n",
      "Aspect:\n",
      "xArchitecture\n",
      "/\n",
      "Algorithm\n",
      "work\n",
      "The\n",
      "structure\n",
      "of\n",
      "this\n",
      "project\n",
      "is\n",
      "demonstrated\n",
      "by\n",
      "the\n",
      "following\n",
      "flow\n",
      "chart:\n",
      "REDCap\n",
      "/\n",
      "Simulacrum\n",
      "Aspect:\n",
      "1.\n",
      "Cleaned\n",
      "Simulacrum\n",
      "V2\n",
      "data \n",
      "a.\n",
      "Fixed\n",
      "column\n",
      "names\n",
      "(lowercased\n",
      "all\n",
      "field\n",
      "variable\n",
      "names\n",
      "and\n",
      "added \n",
      "underscores\n",
      "due\n",
      "to\n",
      "REDCap\n",
      "guidelines\n",
      "for\n",
      "field\n",
      "names) \n",
      "b.\n",
      "Identified\n",
      "invalid\n",
      "records \n",
      "●\n",
      "Assumed\n",
      "‘gender_patient’\n",
      "was\n",
      "based\n",
      "on\n",
      "sex\n",
      "assigned\n",
      "at\n",
      "birth\n",
      "-> \n",
      "records\n",
      "of\n",
      "female\n",
      "patients\n",
      "with\n",
      "prostate\n",
      "cancer\n",
      "&\n",
      "male\n",
      "patients\n",
      "with \n",
      "gynaecological\n",
      "cancer \n",
      "●\n",
      "Records\n",
      "where\n",
      "treatment\n",
      "(radiotherapy\n",
      "and\n",
      "chemotherapy \n",
      "/hormonal\n",
      "therapy)\n",
      "occurs\n",
      "after\n",
      "death\n",
      "of\n",
      "patient \n",
      "●\n",
      "Patients\n",
      "that\n",
      "died\n",
      "before\n",
      "treatment\n",
      "/\n",
      "diagnosis \n",
      "●\n",
      "Treatments\n",
      "that\n",
      "occurred\n",
      "before\n",
      "tumour\n",
      "diagnosis \n",
      "c.\n",
      "Removed\n",
      "invalid\n",
      "records\n",
      "across\n",
      "the\n",
      "different\n",
      "tables\n",
      "2.\n",
      "Defined\n",
      "a\n",
      "data\n",
      "dictionary\n",
      "for\n",
      "REDCap \n",
      "a.\n",
      "Defined\n",
      "the\n",
      "instruments:\n",
      "Av\n",
      "Patient,\n",
      "Av\n",
      "Tumour,\n",
      "Av\n",
      "Gene,\n",
      "Sact\n",
      "Regimen \n",
      "Outcome,\n",
      "Sact\n",
      "Cycle,\n",
      "Sact\n",
      "Drug,\n",
      "Rtds\n",
      "(each\n",
      "is\n",
      "a\n",
      "separate\n",
      "table) \n",
      "b.\n",
      "Defined\n",
      "repeating\n",
      "instruments\n",
      "(number\n",
      "of\n",
      "treatments\n",
      "and\n",
      "tumours\n",
      "varied \n",
      "across\n",
      "the\n",
      "patients) \n",
      "c.\n",
      "Defined\n",
      "valid\n",
      "field\n",
      "value\n",
      "types\n",
      "for\n",
      "certain\n",
      "field\n",
      "variables\n",
      "(e.g. \n",
      "‘gleason_combined’\n",
      "in\n",
      "av_tumour\n",
      "defined\n",
      "to\n",
      "only\n",
      "take\n",
      "type\n",
      "‘integer’)\n",
      "3.\n",
      "Uploaded\n",
      "onto\n",
      "REDCap\n",
      "through\n",
      "the\n",
      "API \n",
      "a.\n",
      "Obtained\n",
      "REDCap\n",
      "API\n",
      "token \n",
      "b.\n",
      "Obtained\n",
      "importing\n",
      "function\n",
      "from\n",
      "previous\n",
      "intake’s\n",
      "git \n",
      "c.\n",
      "Uploaded\n",
      "tables\n",
      "via\n",
      "the\n",
      "API\n",
      "Security\n",
      "Aspect:\n",
      "Technical\n",
      "work\n",
      "REDCap\n",
      "/\n",
      "Simulacrum\n",
      "Aspect: \n",
      "Python\n",
      "was\n",
      "the\n",
      "main\n",
      "programming\n",
      "language\n",
      "that\n",
      "we\n",
      "used.\n",
      "We\n",
      "conducted\n",
      "data \n",
      "preprocessing\n",
      "on\n",
      "the\n",
      "Simulacrum\n",
      "dataset\n",
      "by\n",
      "removing\n",
      "records\n",
      "that\n",
      "are\n",
      "not\n",
      "accurately \n",
      "reflected\n",
      "in\n",
      "the\n",
      "real\n",
      "world\n",
      "(e.g.\n",
      "female\n",
      "patients\n",
      "with\n",
      "prostate\n",
      "cancer,\n",
      "treatments\n",
      "that \n",
      "occurred\n",
      "after\n",
      "death).\n",
      "We\n",
      "also\n",
      "ensured\n",
      "consistent\n",
      "schema\n",
      "for\n",
      "the\n",
      "dataset\n",
      "in\n",
      "order\n",
      "to \n",
      "adhere\n",
      "with\n",
      "the\n",
      "data\n",
      "dictionary\n",
      "defined\n",
      "in\n",
      "REDCap.\n",
      "We\n",
      "had\n",
      "to\n",
      "define\n",
      "repeating \n",
      "instruments\n",
      "in\n",
      "REDCap\n",
      "due\n",
      "to\n",
      "the\n",
      "varying\n",
      "nature\n",
      "of\n",
      "number\n",
      "of\n",
      "treatments\n",
      "or\n",
      "tumours \n",
      "per\n",
      "patient.\n",
      "Finally,\n",
      "we\n",
      "uploaded\n",
      "(to\n",
      "the\n",
      "best\n",
      "of\n",
      "our\n",
      "abilities)\n",
      "the\n",
      "cleaned\n",
      "datasets\n",
      "ontoREDCap\n",
      "using\n",
      "the\n",
      "API.\n",
      "However,\n",
      "due\n",
      "to\n",
      "complications\n",
      "caused\n",
      "by\n",
      "uploading\n",
      "via\n",
      "the\n",
      "API \n",
      "we\n",
      "were\n",
      "only\n",
      "able\n",
      "to\n",
      "upload\n",
      "the\n",
      "av\n",
      "tables\n",
      "and\n",
      "some\n",
      "of\n",
      "the\n",
      "sact_outcome_regimen \n",
      "merged\n",
      "table\n",
      "that\n",
      "we\n",
      "created\n",
      "after\n",
      "cleaning\n",
      "the\n",
      "data.\n",
      "Hence,\n",
      "we\n",
      "broke\n",
      "REDCap\n",
      "and\n",
      "it \n",
      "presents\n",
      "the\n",
      "question:\n",
      "“is\n",
      "REDCap\n",
      "the\n",
      "best\n",
      "way\n",
      "to\n",
      "store\n",
      "this\n",
      "information?”.\n",
      "Also, \n",
      "Simulacrum\n",
      "does\n",
      "NOT\n",
      "include\n",
      "location-specific\n",
      "data\n",
      "(the\n",
      "closest\n",
      "is\n",
      "the\n",
      "type\n",
      "of\n",
      "place\n",
      "a \n",
      "patient\n",
      "died,\n",
      "e.g.\n",
      "a\n",
      "hospital\n",
      "or\n",
      "hospice),\n",
      "so\n",
      "a\n",
      "new\n",
      "visualisation\n",
      "dashboard\n",
      "might\n",
      "need\n",
      "to \n",
      "be\n",
      "made\n",
      "if\n",
      "that’s\n",
      "the\n",
      "aim\n",
      "of\n",
      "a\n",
      "future\n",
      "intake.\n",
      "Security\n",
      "Aspect:\n",
      "We\n",
      "created\n",
      "a\n",
      "Django\n",
      "application\n",
      "to\n",
      "act\n",
      "as\n",
      "an\n",
      "authentication\n",
      "wrapper\n",
      "around\n",
      "an\n",
      "Rshiny \n",
      "app.\n",
      "Thus\n",
      "access\n",
      "is\n",
      "controlled\n",
      "by\n",
      "Django’s\n",
      "authentication\n",
      "layer\n",
      "and\n",
      "users\n",
      "log\n",
      "in\n",
      "via \n",
      "SSO,\n",
      "which\n",
      "we\n",
      "paired\n",
      "Django\n",
      "with\n",
      "mozilla-django-oidc\n",
      "to\n",
      "accomplish.\n",
      "Currently\n",
      "our \n",
      "SSO\n",
      "server\n",
      "is\n",
      "auth0\n",
      "but\n",
      "the\n",
      "aim\n",
      "is\n",
      "to\n",
      "move\n",
      "to\n",
      "AAF.\n",
      "We\n",
      "have\n",
      "set\n",
      "up\n",
      "the\n",
      "application\n",
      "such \n",
      "that\n",
      "all\n",
      "that\n",
      "would\n",
      "be\n",
      "needed\n",
      "to\n",
      "move\n",
      "to\n",
      "AAF\n",
      "would\n",
      "be\n",
      "to\n",
      "set\n",
      "the\n",
      "environment\n",
      "variables \n",
      "for\n",
      "server\n",
      "address\n",
      "&\n",
      "security\n",
      "key\n",
      "once\n",
      "AAF\n",
      "provides\n",
      "those,\n",
      "as\n",
      "well\n",
      "as\n",
      "doign\n",
      "any \n",
      "configurations\n",
      "that\n",
      "AAF\n",
      "require\n",
      "on\n",
      "their\n",
      "end.\n",
      "The\n",
      "authorisation\n",
      "is\n",
      "achieved\n",
      "by\n",
      "Django \n",
      "creating\n",
      "user\n",
      "sessions\n",
      "with\n",
      "the\n",
      "‘users’\n",
      "from\n",
      "SSO\n",
      "stored\n",
      "in\n",
      "a\n",
      "PostgresSQL\n",
      "database. \n",
      "Testing\n",
      "was\n",
      "done\n",
      "locally\n",
      "but\n",
      "the\n",
      "application\n",
      "is\n",
      "packaged\n",
      "in\n",
      "docker\n",
      "and\n",
      "can\n",
      "easily\n",
      "be \n",
      "deployed\n",
      "to\n",
      "a\n",
      "correctly\n",
      "configured\n",
      "nectar\n",
      "server\n",
      "that\n",
      "opens\n",
      "the\n",
      "relevant\n",
      "ports.\n",
      "Currently \n",
      "the\n",
      "embedded\n",
      "application\n",
      "is\n",
      "Key\n",
      "Links\n",
      "●\n",
      "Our\n",
      "final\n",
      "presentation\n",
      "●\n",
      "Our\n",
      "Github\n",
      "repository\n",
      "●\n",
      "Our\n",
      "technical\n",
      "diaryBioNix\n",
      "Student\n",
      "Project\n",
      "Interns:\n",
      "Cat\n",
      "Tuong\n",
      "Anh\n",
      "Nguyen,\n",
      "Di\n",
      "Wu,\n",
      "Liam\n",
      "Mclnerney\n",
      "High-Level\n",
      "Domain\n",
      "work\n",
      "During\n",
      "the\n",
      "first\n",
      "few\n",
      "weeks\n",
      "of\n",
      "the\n",
      "project,\n",
      "we\n",
      "learned\n",
      "about\n",
      "the\n",
      "Nix\n",
      "ecosystem\n",
      "and\n",
      "the \n",
      "required\n",
      "bioinformatics\n",
      "knowledge\n",
      "for\n",
      "the\n",
      "software\n",
      "that\n",
      "we\n",
      "are\n",
      "going\n",
      "to\n",
      "wrap\n",
      "into \n",
      "BioNix.\n",
      "In\n",
      "particular,\n",
      "terms\n",
      "like\n",
      "metagenomics\n",
      "or\n",
      "taxonomic\n",
      "classification\n",
      "for\n",
      "Kraken2, \n",
      "or\n",
      "tandem\n",
      "repeats\n",
      "for\n",
      "TRF.\n",
      "All\n",
      "our\n",
      "knowledges\n",
      "are\n",
      "then\n",
      "presented\n",
      "in\n",
      "a\n",
      "meeting\n",
      "on\n",
      "a \n",
      "whiteboard\n",
      "for\n",
      "our\n",
      "supervisors\n",
      "to\n",
      "correct\n",
      "any\n",
      "false\n",
      "interpretation.\n",
      "The\n",
      "research\n",
      "is\n",
      "then\n",
      "compiled\n",
      "by\n",
      "us\n",
      "to\n",
      "be\n",
      "added\n",
      "into\n",
      "the\n",
      "existing\n",
      "BioNix\n",
      "wiki\n",
      "by\n",
      "WEHI, \n",
      "including\n",
      "any\n",
      "modifications\n",
      "so\n",
      "that\n",
      "the\n",
      "page\n",
      "is\n",
      "more\n",
      "coherent\n",
      "and\n",
      "user-friendly .\n",
      "We \n",
      "added\n",
      "a\n",
      "project\n",
      "introduction\n",
      "page,\n",
      "added\n",
      "some\n",
      "more\n",
      "questions\n",
      "to\n",
      "the\n",
      "FAQ,\n",
      "and\n",
      "had\n",
      "a \n",
      "scan\n",
      "through\n",
      "the\n",
      "existing\n",
      "information\n",
      "to\n",
      "make\n",
      "sure\n",
      "they\n",
      "are\n",
      "non-repetitive,\n",
      "correct, \n",
      "coherent,\n",
      "uniform\n",
      "and\n",
      "change\n",
      "them\n",
      "if\n",
      "necessary\n",
      "Architecture\n",
      "/\n",
      "Algorithm\n",
      "work\n",
      "We\n",
      "had\n",
      "help\n",
      "from\n",
      "our\n",
      "instructor\n",
      "to\n",
      "visualize\n",
      "what\n",
      "an\n",
      "expression\n",
      "to\n",
      "wrap\n",
      "our\n",
      "software \n",
      "would\n",
      "look\n",
      "like,\n",
      "combined\n",
      "with\n",
      "our\n",
      "learning\n",
      "from\n",
      "both\n",
      "the\n",
      "existing\n",
      "package-base,\n",
      "and \n",
      "our\n",
      "personal\n",
      "research.\n",
      "We\n",
      "understood\n",
      "the\n",
      "basic\n",
      "structure\n",
      "of\n",
      "the\n",
      "expression,\n",
      "and\n",
      "how \n",
      "Kraken2\n",
      "would\n",
      "require\n",
      "no\n",
      "configuration,\n",
      "because\n",
      "all\n",
      "the\n",
      "configs\n",
      "are\n",
      "already\n",
      "in\n",
      "the \n",
      "GitHub\n",
      "repository,\n",
      "or\n",
      "how\n",
      "TRF\n",
      "require\n",
      "thorough\n",
      "management\n",
      "of\n",
      "its\n",
      "dependencies.\n",
      "In\n",
      "addition,\n",
      "we\n",
      "understood\n",
      "the\n",
      "contribution\n",
      "steps\n",
      "for\n",
      "nixpkgs\n",
      "and\n",
      "ensure\n",
      "that\n",
      "our \n",
      "expressions\n",
      "abide\n",
      "by\n",
      "the\n",
      "rules.\n",
      "Technical\n",
      "work\n",
      "●\n",
      "Finalized\n",
      "the\n",
      "expression\n",
      "of\n",
      "wrapping\n",
      "TRF\n",
      "to\n",
      "BioNix. \n",
      "●\n",
      "Made\n",
      "prototypes\n",
      "of\n",
      "expressions\n",
      "to\n",
      "wrap\n",
      "Kraken2. \n",
      "●\n",
      "Wrote\n",
      "and\n",
      "tested\n",
      "the\n",
      "prototype\n",
      "expressions\n",
      "for\n",
      "Kraken2.\n",
      "Key\n",
      "Links\n",
      "●\n",
      "Fork\n",
      "repo\n",
      "of\n",
      "the\n",
      "wiki\n",
      "●\n",
      "Trello\n",
      "to\n",
      "manage\n",
      "tasks\n",
      "●\n",
      "Final\n",
      "Presentation\n",
      "Conference\n",
      "Organiser\n",
      "Student\n",
      "ProjectInterns:\n",
      "Zheyuan\n",
      "Wu,\n",
      "Antonio\n",
      "Wang,\n",
      "Wingyee\n",
      "He,\n",
      "Natasha\n",
      "Ngo,\n",
      "Jiaxi\n",
      "Zheng\n",
      "High-Level\n",
      "Domain\n",
      "work\n",
      "The\n",
      "Conference\n",
      "Organiser\n",
      "project\n",
      "aims\n",
      "to\n",
      "streamline\n",
      "the\n",
      "annual\n",
      "RSEAA\n",
      "conference,\n",
      "which\n",
      "fosters\n",
      "inclusivity\n",
      "and\n",
      "recognition\n",
      "for\n",
      "software\n",
      "engineers\n",
      "worldwide.\n",
      "In\n",
      "the\n",
      "second\n",
      "intake,\n",
      "the\n",
      "team\n",
      "focused\n",
      "on\n",
      "two\n",
      "key\n",
      "areas.\n",
      "First,\n",
      "a\n",
      "dynamic\n",
      "HTML\n",
      "page\n",
      "was\n",
      "developed\n",
      "to\n",
      "update\n",
      "key\n",
      "dates\n",
      "on\n",
      "the\n",
      "main\n",
      "website,\n",
      "RSEAA.org.au,\n",
      "enhancing\n",
      "user\n",
      "experience.\n",
      "Second,\n",
      "the\n",
      "team\n",
      "focused\n",
      "on\n",
      "creating\n",
      "a\n",
      "platform\n",
      "that\n",
      "drew\n",
      "inspiration\n",
      "from\n",
      "a\n",
      "popular\n",
      "live\n",
      "polling\n",
      "application\n",
      "called\n",
      "CrowdPurr.\n",
      "Within\n",
      "this\n",
      "polling\n",
      "project,\n",
      "the\n",
      "team\n",
      "was\n",
      "divided\n",
      "among\n",
      "two\n",
      "sub-projects:\n",
      "One\n",
      "focused\n",
      "on\n",
      "extending\n",
      "Claper,\n",
      "an\n",
      "existing\n",
      "open-source\n",
      "live\n",
      "polling\n",
      "tool,\n",
      "while\n",
      "the\n",
      "other\n",
      "group\n",
      "built\n",
      "a\n",
      "custom\n",
      "live\n",
      "polling\n",
      "application\n",
      "from\n",
      "the\n",
      "ground\n",
      "up\n",
      "using\n",
      "React.\n",
      "Architecture\n",
      "/\n",
      "Algorithm\n",
      "work\n",
      "Claper\n",
      "architecture:\n",
      "React\n",
      "Live\n",
      "Polling:\n",
      "High-level\n",
      "Architecture: \n",
      "Database\n",
      "Architecture:\n",
      "Technical\n",
      "work\n",
      "Live\n",
      "polling\n",
      "application:\n",
      "Frontend:\n",
      "React\n",
      "Library\n",
      "(HTML,\n",
      "Javascript,\n",
      "CSS) \n",
      "Backend\n",
      "(Database\n",
      "and\n",
      "functionality): \n",
      "Testing\n",
      "and\n",
      "integration:\n",
      "NectarVM\n",
      "(used\n",
      "for\n",
      "docking)\n",
      "Claper:\n",
      "Frontend:\n",
      "HTML,\n",
      "TailwindCSS \n",
      "Backend:\n",
      "Elixir,\n",
      "Phoenix \n",
      "Testing\n",
      "and\n",
      "integration:\n",
      "NectarVM\n",
      "Webpage:\n",
      "Simple\n",
      "HTML,\n",
      "CSS\n",
      "and\n",
      "JavaScript\n",
      "Key\n",
      "Links−\n",
      "Live\n",
      "polling\n",
      "react\n",
      "application:\n",
      "https://github.com/ngonatasha/WEHI-Conference-Organiser\n",
      "−\n",
      "RSEAA\n",
      "webpage:\n",
      "https://github.com/ngonatasha/RSEAA.github.io\n",
      "−\n",
      "Project\n",
      "Claper:\n",
      "https://github.com/Jazzzheng9/Claper .git\n",
      "−\n",
      "Original\n",
      "Claper:\n",
      "https://github.com/ClaperCo/Claper\n",
      "−\n",
      "Final\n",
      "presentation:\n",
      "Conference\n",
      "Organiser\n",
      "Final\n",
      "Presentation.pdf\n",
      "−\n",
      "Whiteboard\n",
      "presentation:\n",
      "Conference\n",
      "Organiser\n",
      "Whiteboard\n",
      "presentation.pdf\n",
      "−\n",
      "Technical\n",
      "diary:\n",
      "Technical\n",
      "Diary\n",
      "Data\n",
      "Commons\n",
      "/\n",
      "REDMANE\n",
      "Data\n",
      "Registry\n",
      "Student\n",
      "ProjectInterns:\n",
      "Haoxuan\n",
      "Lu,\n",
      "Jeremy\n",
      "Lau,\n",
      "Natasha\n",
      "Mulay\n",
      "High-Level\n",
      "Domain\n",
      "work\n",
      "The\n",
      "Data\n",
      "Registry\n",
      "is\n",
      "a\n",
      "web-application\n",
      "that\n",
      "connects\n",
      "Raw\n",
      "and\n",
      "Processed\n",
      "Data\n",
      "to\n",
      "the \n",
      "Data\n",
      "Portals\n",
      "such\n",
      "as\n",
      "cBioPortal,\n",
      "Omero,\n",
      "Aquila\n",
      "etc.,\n",
      "to\n",
      "form\n",
      "the\n",
      "Data \n",
      "Commons/REDMANE.\n",
      "It\n",
      "has\n",
      "four\n",
      "main\n",
      "components,\n",
      "the\n",
      "front\n",
      "end,\n",
      "the\n",
      "backend,\n",
      "the \n",
      "database\n",
      "and\n",
      "the\n",
      "virtual\n",
      "machine\n",
      "(Nectar).\n",
      "As\n",
      "the\n",
      "Data\n",
      "Registry\n",
      "subgroup,\n",
      "we \n",
      "addressed\n",
      "the\n",
      "frontend,\n",
      "backend\n",
      "and\n",
      "VM\n",
      "as\n",
      "the\n",
      "main\n",
      "areas\n",
      "of\n",
      "work.\n",
      "The\n",
      "frontend \n",
      "involved\n",
      "the\n",
      "creation\n",
      "of\n",
      "different\n",
      "components\n",
      "such\n",
      "as\n",
      "the\n",
      "Projects\n",
      "components\n",
      "which \n",
      "linked\n",
      "to\n",
      "the\n",
      "Patients\n",
      "and\n",
      "Datasets\n",
      "components\n",
      "(Figure\n",
      "1).\n",
      "Architecture\n",
      "/\n",
      "Algorithm\n",
      "work\n",
      "Figure\n",
      "1.\n",
      "ER\n",
      "diagram\n",
      "of\n",
      "different\n",
      "components\n",
      "within\n",
      "the\n",
      "frontend\n",
      "of\n",
      "the\n",
      "Data\n",
      "Registry \n",
      "and\n",
      "how\n",
      "they\n",
      "link\n",
      "together.\n",
      "Lorem\n",
      "ipsum\n",
      "dolor\n",
      "sit\n",
      "amet,\n",
      "consectetur\n",
      "adipiscing\n",
      "elit,\n",
      "sed\n",
      "do\n",
      "eiusmod\n",
      "tempor \n",
      "incididunt\n",
      "ut\n",
      "labore\n",
      "et\n",
      "dolore\n",
      "magna\n",
      "aliqua.\n",
      "Ut\n",
      "enim\n",
      "ad\n",
      "minim\n",
      "veniam,\n",
      "quis\n",
      "nostrud \n",
      "exercitation\n",
      "ullamco\n",
      "laboris\n",
      "nisi\n",
      "ut\n",
      "aliquip\n",
      "ex\n",
      "ea\n",
      "commodo\n",
      "consequat.\n",
      "Duis\n",
      "aute\n",
      "irure \n",
      "dolor\n",
      "in\n",
      "reprehenderit\n",
      "in\n",
      "voluptate\n",
      "velit\n",
      "esse\n",
      "cillum\n",
      "dolore\n",
      "eu\n",
      "fugiat\n",
      "nulla\n",
      "pariatur. \n",
      "Excepteur\n",
      "sint\n",
      "occaecat\n",
      "cupidatat\n",
      "non\n",
      "proident,\n",
      "sunt\n",
      "in\n",
      "culpa\n",
      "qui\n",
      "officia\n",
      "deserunt\n",
      "mollit \n",
      "anim\n",
      "id\n",
      "est\n",
      "laborum.\n",
      "Technical\n",
      "work\n",
      "Lorem\n",
      "ipsum\n",
      "dolor\n",
      "sit\n",
      "amet,\n",
      "consectetur\n",
      "adipiscing\n",
      "elit,\n",
      "sed\n",
      "do\n",
      "eiusmod\n",
      "tempor \n",
      "incididunt\n",
      "ut\n",
      "labore\n",
      "et\n",
      "dolore\n",
      "magna\n",
      "aliqua.\n",
      "Ut\n",
      "enim\n",
      "ad\n",
      "minim\n",
      "veniam,\n",
      "quis\n",
      "nostrud \n",
      "exercitation\n",
      "ullamco\n",
      "laboris\n",
      "nisi\n",
      "ut\n",
      "aliquip\n",
      "ex\n",
      "ea\n",
      "commodo\n",
      "consequat.\n",
      "Duis\n",
      "aute\n",
      "irure \n",
      "dolor\n",
      "in\n",
      "reprehenderit\n",
      "in\n",
      "voluptate\n",
      "velit\n",
      "esse\n",
      "cillum\n",
      "dolore\n",
      "eu\n",
      "fugiat\n",
      "nulla\n",
      "pariatur. \n",
      "Excepteur\n",
      "sint\n",
      "occaecat\n",
      "cupidatat\n",
      "non\n",
      "proident,\n",
      "sunt\n",
      "in\n",
      "culpa\n",
      "qui\n",
      "officia\n",
      "deserunt\n",
      "mollit \n",
      "anim\n",
      "id\n",
      "est\n",
      "laborum.\n",
      "Key\n",
      "Links\n",
      "Frontend\n",
      "with\n",
      "React\n",
      "(Current):\n",
      "https://github.com/jeremlll/REDMANE_react.js\n",
      "Frontend\n",
      "with\n",
      "React\n",
      "(Base):\n",
      "https://github.com/HxLu03/DataCommons\n",
      "FAST\n",
      "API\n",
      "(Working\n",
      "one):\n",
      "GitHub\n",
      "-\n",
      "jeremlll/REDMANE_fastapiData\n",
      "Commons\n",
      "/\n",
      "REDMANE\n",
      "Data\n",
      "Ingestion\n",
      "Student\n",
      "Project\n",
      "Interns:\n",
      "Xinyu\n",
      "Wang,\n",
      "Boyu\n",
      "Chen,\n",
      "Chelsea\n",
      "Kwan,\n",
      "Bucheng\n",
      "Liu\n",
      "High-Level\n",
      "Domain\n",
      "work\n",
      "The\n",
      "aim\n",
      "of\n",
      "the\n",
      "Data\n",
      "Commons\n",
      "Project\n",
      "is\n",
      "to: \n",
      "Allow\n",
      "for\n",
      "ease\n",
      "of\n",
      "access\n",
      "to\n",
      "various\n",
      "datasets\n",
      "for\n",
      "researchers\n",
      "and\n",
      "stakeholders \n",
      "Ability\n",
      "to\n",
      "locate\n",
      "raw/processed\n",
      "data\n",
      "stored\n",
      "on\n",
      "local\n",
      "servers\n",
      "through\n",
      "links\n",
      "on\n",
      "the\n",
      "data \n",
      "registry\n",
      "Access\n",
      "summarised\n",
      "data\n",
      "and\n",
      "visualisations\n",
      "on\n",
      "data\n",
      "portals \n",
      "Form\n",
      "connections\n",
      "between\n",
      "data\n",
      "registry,\n",
      "local\n",
      "servers\n",
      "and\n",
      "external\n",
      "data\n",
      "portals \n",
      "(cBioPortal,\n",
      "Aquila\n",
      "etc.) \n",
      "For\n",
      "the\n",
      "Data\n",
      "Ingestion,\n",
      "the\n",
      "primary\n",
      "goal\n",
      "is\n",
      "to\n",
      "Ensure\n",
      "that\n",
      "datasets\n",
      "are\n",
      "validated\n",
      "and \n",
      "ingested\n",
      "into\n",
      "cBioPortal.\n",
      "Key\n",
      "responsibilities\n",
      "would\n",
      "include\n",
      "validating\n",
      "datasets\n",
      "using \n",
      "the\n",
      "validator\n",
      "tool,\n",
      "ingesting\n",
      "validated\n",
      "datasets\n",
      "into\n",
      "the\n",
      "cBioPortal\n",
      "system,\n",
      "and\n",
      "setting\n",
      "up \n",
      "and\n",
      "manage\n",
      "the\n",
      "infrastructure\n",
      "for\n",
      "the\n",
      "ingestion\n",
      "process.\n",
      "Architecture\n",
      "/\n",
      "Algorithm\n",
      "work\n",
      "Summary\n",
      "Diagram:\n",
      "Architecture:\n",
      "Platform\n",
      "Data\n",
      "Workflow\n",
      "Technical\n",
      "work\n",
      "Setting\n",
      "up\n",
      "the\n",
      "virtual\n",
      "environment: \n",
      "Ubuntu\n",
      "VM\n",
      "Setup:\n",
      "Create\n",
      "an\n",
      "Ubuntu\n",
      "virtual\n",
      "machine\n",
      "(VM)\n",
      "on\n",
      "the\n",
      "server\n",
      "to\n",
      "run\n",
      "the \n",
      "validator\n",
      "and\n",
      "manage\n",
      "the\n",
      "ingestion\n",
      "process. \n",
      "Portainer\n",
      "for\n",
      "Docker\n",
      "Management:\n",
      "Install\n",
      "and\n",
      "use\n",
      "Portainer\n",
      "to\n",
      "manage\n",
      "Docker \n",
      "containers\n",
      "for\n",
      "deploying\n",
      "the\n",
      "ingestion\n",
      "environment. \n",
      "Key\n",
      "LinksData\n",
      "Ingestion\n",
      "Documentation\n",
      "Data\n",
      "validator\n",
      "repo:\n",
      "https://github.com/Morning-NFX/DataCommons-cBioPortal\n",
      "Example\n",
      "dataset\n",
      "repo:\n",
      "https://github.com/Morning-NFX/DataCommons-dataset\n",
      "https://github.com/cBioPortal/cbioportal \n",
      "https://docs.cbioportal.org/using-the-dataset-validator/ \n",
      "https://docs.cbioportal.org/file-formats/Data\n",
      "Commons\n",
      "/\n",
      "REDMANE\n",
      "Authentication\n",
      "Student\n",
      "Project\n",
      "Interns:\n",
      "Trung\n",
      "Ngo,\n",
      "Lucas\n",
      "Speak\n",
      "High-Level\n",
      "Domain\n",
      "work\n",
      "The\n",
      "primary\n",
      "focus\n",
      "of\n",
      "the\n",
      "project\n",
      "was\n",
      "to\n",
      "establish\n",
      "a\n",
      "modern\n",
      "and\n",
      "seamless\n",
      "authentication\n",
      "system\n",
      "to\n",
      "protect\n",
      "sensitive\n",
      "data\n",
      "within\n",
      "a\n",
      "medical\n",
      "research\n",
      "data\n",
      "registry.\n",
      "The\n",
      "data\n",
      "registry\n",
      "is\n",
      "a\n",
      "web\n",
      "application\n",
      "which\n",
      "was\n",
      "concurrently\n",
      "developed\n",
      "by\n",
      "the\n",
      "Data\n",
      "Commons\n",
      "Data\n",
      "registry\n",
      "team.\n",
      "Authentication\n",
      "ensures\n",
      "that\n",
      "only\n",
      "authorized\n",
      "users\n",
      "can\n",
      "access\n",
      "the\n",
      "system,\n",
      "preventing\n",
      "unauthorized\n",
      "access\n",
      "and\n",
      "data\n",
      "misuse.\n",
      "This\n",
      "protection\n",
      "is\n",
      "critical\n",
      "because\n",
      "it\n",
      "safeguards\n",
      "not\n",
      "only\n",
      "WEHI's\n",
      "research\n",
      "interests\n",
      "but\n",
      "also\n",
      "the\n",
      "privacy\n",
      "rights\n",
      "of\n",
      "patients\n",
      "whose\n",
      "medical\n",
      "data\n",
      "is\n",
      "being\n",
      "managed.\n",
      "The\n",
      "choice\n",
      "of\n",
      "authentication\n",
      "protocols\n",
      "had\n",
      "to\n",
      "align\n",
      "with\n",
      "industry\n",
      "standards\n",
      "and\n",
      "requirements\n",
      "to\n",
      "ensure\n",
      "compliance\n",
      "with\n",
      "security\n",
      "and\n",
      "privacy\n",
      "regulations\n",
      "while\n",
      "supporting\n",
      "Single\n",
      "Sign-On\n",
      "(SSO)\n",
      "for\n",
      "ease\n",
      "of\n",
      "access.\n",
      "High\n",
      "level\n",
      "work\n",
      "consisted\n",
      "of:\n",
      "-\n",
      "Researching\n",
      "what\n",
      "resources\n",
      "were\n",
      "available\n",
      "and\n",
      "suitable\n",
      "for\n",
      "this\n",
      "project.-\n",
      "Understanding\n",
      "how\n",
      "different\n",
      "authentication\n",
      "protocols\n",
      "worked,\n",
      "and\n",
      "the\n",
      "advantages/disadvantages\n",
      "of\n",
      "each.\n",
      "-\n",
      "Identifying\n",
      "the\n",
      "requirements\n",
      "of\n",
      "the\n",
      "authentication\n",
      "system.\n",
      "This\n",
      "work\n",
      "resulted\n",
      "in\n",
      "making\n",
      "the\n",
      "following\n",
      "decisions:\n",
      "-\n",
      "OpenID\n",
      "Connect\n",
      "(OIDC)\n",
      "was\n",
      "selected\n",
      "as\n",
      "the\n",
      "primary\n",
      "authentication\n",
      "protocol\n",
      "due\n",
      "to\n",
      "its\n",
      "suitability\n",
      "for\n",
      "research\n",
      "organizations,\n",
      "as\n",
      "recommended\n",
      "by\n",
      "the\n",
      "Australian\n",
      "Access\n",
      "Federation\n",
      "(AAF).\n",
      "OIDC\n",
      "supports\n",
      "both\n",
      "SSO\n",
      "and\n",
      "social\n",
      "login,\n",
      "offers\n",
      "flexibility\n",
      "in\n",
      "integrating\n",
      "different\n",
      "identity\n",
      "providers,\n",
      "and\n",
      "is\n",
      "simpler\n",
      "to\n",
      "implement\n",
      "compared\n",
      "to\n",
      "alternatives\n",
      "like\n",
      "SAML.\n",
      "-\n",
      "Keycloak,\n",
      "an\n",
      "open-source\n",
      "identity\n",
      "and\n",
      "access\n",
      "management\n",
      "system,\n",
      "was\n",
      "chosen\n",
      "to\n",
      "run\n",
      "on\n",
      "the\n",
      "authentication\n",
      "server.\n",
      "It\n",
      "offers\n",
      "ease\n",
      "of\n",
      "setup,\n",
      "sufficient\n",
      "security\n",
      "for\n",
      "non-critical\n",
      "use\n",
      "cases,\n",
      "and\n",
      "eliminates\n",
      "the\n",
      "licensing\n",
      "costs\n",
      "associated\n",
      "with\n",
      "platforms\n",
      "like\n",
      "Auth0.\n",
      "Keycloak\n",
      "also\n",
      "allows\n",
      "integration\n",
      "with\n",
      "AAF\n",
      "as\n",
      "an\n",
      "identity\n",
      "provider,\n",
      "leveraging\n",
      "OIDC\n",
      "to\n",
      "provide\n",
      "seamless\n",
      "access\n",
      "for\n",
      "Australian\n",
      "researchers.\n",
      "Architecture\n",
      "/\n",
      "Algorithm\n",
      "work\n",
      "The\n",
      "following\n",
      "diagram\n",
      "depicts\n",
      "the\n",
      "typical\n",
      "authentication\n",
      "sequence\n",
      "for\n",
      "a\n",
      "user\n",
      "signing\n",
      "into\n",
      "the\n",
      "data\n",
      "registry\n",
      "using\n",
      "their\n",
      "Okta\n",
      "credentials:\n",
      "Technical\n",
      "work\n",
      "Luke:\n",
      "-\n",
      "Researched\n",
      "OIDC\n",
      "and\n",
      "authentication\n",
      "tools.\n",
      "-\n",
      "Discovered,\n",
      "installed\n",
      "and\n",
      "configured\n",
      "Keycloak\n",
      "-\n",
      "Implemented\n",
      "OIDC\n",
      "authentication\n",
      "flow\n",
      "with\n",
      "demo\n",
      "Python\n",
      "script\n",
      "and\n",
      "keycloak.\n",
      "Trung:\n",
      "-\n",
      "Deployed\n",
      "Keycloak\n",
      "with\n",
      "test\n",
      "web\n",
      "application\n",
      "to\n",
      "implement\n",
      "the\n",
      "OIDC\n",
      "authentication\n",
      "protocol.\n",
      "-\n",
      "Modified\n",
      "Keycloak\n",
      "realm\n",
      "to\n",
      "accept\n",
      "Auth0\n",
      "as\n",
      "an\n",
      "Identity\n",
      "Provider.\n",
      "-\n",
      "Created\n",
      "and\n",
      "performed\n",
      "authentication\n",
      "demo\n",
      "in\n",
      "final\n",
      "presentation.Key\n",
      "Links\n",
      "Authentication\n",
      "set-up\n",
      "docs:\n",
      "https://wehieduau.sharepoint.com/:f:/r/sites/StudentInternGroupatWEHI/Shared%20 \n",
      "Documents/Data%20Commons/2024%20Semester%202/Authentication?csf=1&web \n",
      "=1&e=54AxBl\n",
      "Final\n",
      "presentation\n",
      "(slides):\n",
      "https://wehieduau.sharepoint.com/:p:/s/StudentInternGroupatWEHI/EYQh5qAhApVJj \n",
      "h51r84NQgcBKihFHMF2nj8x3ctK39fQjw?wdOrigin=TEAMS-MAGLEV.null_ns.rwc&wdE \n",
      "xp=TEAMS-TREATMENT&wdhostclicktime=1728513382398&web=1\n",
      "^OUTDATED\n",
      "OIDC\n",
      "demo\n",
      "python\n",
      "script\n",
      "(rough):\n",
      "https://wehieduau.sharepoint.com/:f:/r/sites/StudentInternGroupatWEHI/Shared%20 \n",
      "Documents/Data%20Commons/2024%20Semester%202/Authentication/OIDC%20Py \n",
      "thon%20demo?csf=1&web=1&e=dlAegm\n",
      "Genomics\n",
      "Invoicing\n",
      "Student\n",
      "Project\n",
      "Interns:\n",
      "Changyuan\n",
      "Ni,\n",
      "Jiayi,\n",
      "Li,\n",
      "Iffat\n",
      "Azeez,\n",
      "Ramon\n",
      "Felipe\n",
      "High-Level\n",
      "Domain\n",
      "work\n",
      "Lorem\n",
      "ipsum\n",
      "dolor\n",
      "sit\n",
      "amet,\n",
      "consectetur\n",
      "adipiscing\n",
      "elit,\n",
      "sed\n",
      "do\n",
      "eiusmod\n",
      "tempor \n",
      "incididunt\n",
      "ut\n",
      "labore\n",
      "et\n",
      "dolore\n",
      "magna\n",
      "aliqua.\n",
      "Ut\n",
      "enim\n",
      "ad\n",
      "minim\n",
      "veniam,\n",
      "quis\n",
      "nostrud \n",
      "exercitation\n",
      "ullamco\n",
      "laboris\n",
      "nisi\n",
      "ut\n",
      "aliquip\n",
      "ex\n",
      "ea\n",
      "commodo\n",
      "consequat.\n",
      "Duis\n",
      "aute\n",
      "irure \n",
      "dolor\n",
      "in\n",
      "reprehenderit\n",
      "in\n",
      "voluptate\n",
      "velit\n",
      "esse\n",
      "cillum\n",
      "dolore\n",
      "eu\n",
      "fugiat\n",
      "nulla\n",
      "pariatur. \n",
      "Excepteur\n",
      "sint\n",
      "occaecat\n",
      "cupidatat\n",
      "non\n",
      "proident,\n",
      "sunt\n",
      "in\n",
      "culpa\n",
      "qui\n",
      "officia\n",
      "deserunt\n",
      "mollit \n",
      "anim\n",
      "id\n",
      "est\n",
      "laborum.\n",
      "Architecture\n",
      "/\n",
      "Algorithm\n",
      "work\n",
      "Lorem\n",
      "ipsum\n",
      "dolor\n",
      "sit\n",
      "amet,\n",
      "consectetur\n",
      "adipiscing\n",
      "elit,\n",
      "sed\n",
      "do\n",
      "eiusmod\n",
      "tempor \n",
      "incididunt\n",
      "ut\n",
      "labore\n",
      "et\n",
      "dolore\n",
      "magna\n",
      "aliqua.\n",
      "Ut\n",
      "enim\n",
      "ad\n",
      "minim\n",
      "veniam,\n",
      "quis\n",
      "nostrud \n",
      "exercitation\n",
      "ullamco\n",
      "laboris\n",
      "nisi\n",
      "ut\n",
      "aliquip\n",
      "ex\n",
      "ea\n",
      "commodo\n",
      "consequat.\n",
      "Duis\n",
      "aute\n",
      "irure \n",
      "dolor\n",
      "in\n",
      "reprehenderit\n",
      "in\n",
      "voluptate\n",
      "velit\n",
      "esse\n",
      "cillum\n",
      "dolore\n",
      "eu\n",
      "fugiat\n",
      "nulla\n",
      "pariatur. \n",
      "Excepteur\n",
      "sint\n",
      "occaecat\n",
      "cupidatat\n",
      "non\n",
      "proident,\n",
      "sunt\n",
      "in\n",
      "culpa\n",
      "qui\n",
      "officia\n",
      "deserunt\n",
      "mollit \n",
      "anim\n",
      "id\n",
      "est\n",
      "laborum.Technical\n",
      "work\n",
      "Lorem\n",
      "ipsum\n",
      "dolor\n",
      "sit\n",
      "amet,\n",
      "consectetur\n",
      "adipiscing\n",
      "elit,\n",
      "sed\n",
      "do\n",
      "eiusmod\n",
      "tempor \n",
      "incididunt\n",
      "ut\n",
      "labore\n",
      "et\n",
      "dolore\n",
      "magna\n",
      "aliqua.\n",
      "Ut\n",
      "enim\n",
      "ad\n",
      "minim\n",
      "veniam,\n",
      "quis\n",
      "nostrud \n",
      "exercitation\n",
      "ullamco\n",
      "laboris\n",
      "nisi\n",
      "ut\n",
      "aliquip\n",
      "ex\n",
      "ea\n",
      "commodo\n",
      "consequat.\n",
      "Duis\n",
      "aute\n",
      "irure \n",
      "dolor\n",
      "in\n",
      "reprehenderit\n",
      "in\n",
      "voluptate\n",
      "velit\n",
      "esse\n",
      "cillum\n",
      "dolore\n",
      "eu\n",
      "fugiat\n",
      "nulla\n",
      "pariatur. \n",
      "Excepteur\n",
      "sint\n",
      "occaecat\n",
      "cupidatat\n",
      "non\n",
      "proident,\n",
      "sunt\n",
      "in\n",
      "culpa\n",
      "qui\n",
      "officia\n",
      "deserunt\n",
      "mollit \n",
      "anim\n",
      "id\n",
      "est\n",
      "laborum.\n",
      "Key\n",
      "Links\n",
      "●\n",
      "Haemosphere\n",
      "Student\n",
      "Project\n",
      "Interns:\n",
      "Michele\n",
      "Meliala,\n",
      "Lady\n",
      "Feren\n",
      "Pangjaya,\n",
      "Thanh\n",
      "Pham,\n",
      "Thi\n",
      "Hong\n",
      "Minh\n",
      "Dao,\n",
      "Zachary\n",
      "Iskandar\n",
      "High-Level\n",
      "Domain\n",
      "work\n",
      "Our\n",
      "group’s\n",
      "work\n",
      "was\n",
      "the\n",
      "continuation\n",
      "of\n",
      "the\n",
      "ongoing\n",
      "migration\n",
      "of\n",
      "Haemosphere\n",
      "from\n",
      "Python\n",
      "2\n",
      "to\n",
      "Python\n",
      "3,\n",
      "due\n",
      "to\n",
      "Python\n",
      "2\n",
      "no\n",
      "longer\n",
      "being\n",
      "supported.\n",
      "We\n",
      "mainly\n",
      "focused\n",
      "on\n",
      "improving\n",
      "overall\n",
      "speed\n",
      "on\n",
      "the\n",
      "site,\n",
      "and\n",
      "improving\n",
      "the\n",
      "scalability\n",
      "of\n",
      "the\n",
      "site\n",
      "to\n",
      "accommodate\n",
      "multiple\n",
      "simultaneous\n",
      "users\n",
      "without\n",
      "crashing.\n",
      "After\n",
      "extensive\n",
      "testing,\n",
      "we\n",
      "determined\n",
      "that\n",
      "a\n",
      "caching-related\n",
      "approach\n",
      "was\n",
      "the\n",
      "best\n",
      "solution\n",
      "for\n",
      "performance\n",
      "enhancement.\n",
      "In\n",
      "addition,\n",
      "we\n",
      "made\n",
      "minor\n",
      "improvements\n",
      "to\n",
      "the\n",
      "existing\n",
      "tutorials\n",
      "and\n",
      "documentation,\n",
      "so\n",
      "that\n",
      "hopefully\n",
      "future\n",
      "intakes\n",
      "will\n",
      "have\n",
      "a\n",
      "smoother\n",
      "and\n",
      "less\n",
      "confusing\n",
      "onboarding\n",
      "experience.\n",
      "We\n",
      "implore\n",
      "future\n",
      "intakes\n",
      "to\n",
      "explore\n",
      "this\n",
      "caching\n",
      "solution\n",
      "in\n",
      "greater\n",
      "depth\n",
      "to\n",
      "assess\n",
      "its\n",
      "feasibility,\n",
      "and\n",
      "to\n",
      "debug\n",
      "some\n",
      "datasets\n",
      "such\n",
      "as\n",
      "Schultze\n",
      "and\n",
      "Immgen\n",
      "to\n",
      "make\n",
      "them\n",
      "compatible\n",
      "with\n",
      "the\n",
      "new\n",
      "Python\n",
      "3\n",
      "framework,\n",
      "as\n",
      "well\n",
      "as\n",
      "any\n",
      "other\n",
      "necessary\n",
      "improvements\n",
      "to\n",
      "the\n",
      "site\n",
      "to\n",
      "further\n",
      "enhance\n",
      "the\n",
      "user\n",
      "experience.\n",
      "In\n",
      "the\n",
      "longer\n",
      "term,\n",
      "we\n",
      "also\n",
      "recommend\n",
      "Haemosphere\n",
      "to\n",
      "be\n",
      "migrated\n",
      "to\n",
      "a\n",
      "supported\n",
      "version\n",
      "of\n",
      "Python,\n",
      "as\n",
      "support\n",
      "for\n",
      "the\n",
      "destination\n",
      "version\n",
      "(Python\n",
      "3.6)\n",
      "ceased\n",
      "in\n",
      "December\n",
      "2021,\n",
      "almost\n",
      "three\n",
      "years\n",
      "ago\n",
      "at\n",
      "the\n",
      "time\n",
      "of\n",
      "writing.\n",
      "Architecture\n",
      "/\n",
      "Algorithm\n",
      "work\n",
      "We\n",
      "trialled\n",
      "several\n",
      "different\n",
      "solutions\n",
      "and\n",
      "measured\n",
      "the\n",
      "impact\n",
      "each\n",
      "solution\n",
      "had\n",
      "on\n",
      "improving\n",
      "speed\n",
      "and\n",
      "performance.\n",
      "These\n",
      "included\n",
      "increasing\n",
      "the\n",
      "RAM\n",
      "of\n",
      "the\n",
      "virtual\n",
      "machine,\n",
      "pre-loading\n",
      "data\n",
      "onto\n",
      "RAM\n",
      "cache\n",
      "and\n",
      "utilising\n",
      "disk\n",
      "cache.\n",
      "Through\n",
      "performance\n",
      "testing,\n",
      "we\n",
      "found\n",
      "that\n",
      "a\n",
      "large\n",
      "memory\n",
      "virtual\n",
      "machine\n",
      "with\n",
      "caching\n",
      "was\n",
      "the\n",
      "most\n",
      "efficient\n",
      "in\n",
      "terms\n",
      "of\n",
      "speed\n",
      "and\n",
      "reliability.\n",
      "We\n",
      "also\n",
      "explored\n",
      "changing\n",
      "file\n",
      "formats\n",
      "using\n",
      ".h5\n",
      "and\n",
      ".parquet,\n",
      "but\n",
      "this\n",
      "method\n",
      "was\n",
      "overcomplicated\n",
      "and\n",
      "only\n",
      "yielded\n",
      "minimal\n",
      "improvements\n",
      "compared\n",
      "to\n",
      "other\n",
      "methods.\n",
      "Technical\n",
      "workFixed\n",
      "minor\n",
      "bugs\n",
      "that\n",
      "prevented\n",
      "us\n",
      "from\n",
      "running\n",
      "the\n",
      "server\n",
      "(typos,\n",
      "missing\n",
      "dependencies\n",
      "during\n",
      "the \n",
      "onboarding\n",
      "process,\n",
      "tweaks\n",
      "to\n",
      "config\n",
      "files) \n",
      "Took\n",
      "the\n",
      "opportunity\n",
      "to\n",
      "explore\n",
      "the\n",
      "option\n",
      "of\n",
      "a\n",
      "higher\n",
      "memory\n",
      "VM\n",
      "after\n",
      "the\n",
      "hosting\n",
      "arrangement\n",
      "with\n",
      "the \n",
      "University\n",
      "for\n",
      "the\n",
      "publicly\n",
      "accessible\n",
      "version\n",
      "of\n",
      "Haemosphere\n",
      "was\n",
      "changed \n",
      "Conducted\n",
      "performance\n",
      "testing\n",
      "on\n",
      "various\n",
      "differential\n",
      "expression\n",
      "datasets\n",
      "to\n",
      "assess\n",
      "performance\n",
      "and \n",
      "detect\n",
      "errors\n",
      "for\n",
      "future\n",
      "intakes\n",
      "to\n",
      "fix,\n",
      "as\n",
      "well\n",
      "as\n",
      "to\n",
      "compare\n",
      "different\n",
      "server\n",
      "configurations \n",
      "Implemented\n",
      "RAM\n",
      "and\n",
      "disk\n",
      "caching,\n",
      "which\n",
      "significantly\n",
      "improved\n",
      "performance\n",
      "Key\n",
      "Links\n",
      "●\n",
      "Haemosphere\n",
      "website\n",
      "●\n",
      "Public\n",
      "Github\n",
      "repository\n",
      "●\n",
      "Sharepoint\n",
      "●\n",
      "YouTube\n",
      "link\n",
      "for\n",
      "presentation\n",
      "(add\n",
      "link\n",
      "when\n",
      "uploaded)\n",
      "Student\n",
      "Organizer\n",
      "Student\n",
      "Project\n",
      "Interns:\n",
      "Jiaman(Mandy)\n",
      "Xu,\n",
      "Xiaoqing(Betty)\n",
      "Hu,\n",
      "Yiyang\n",
      "Chen,\n",
      "Yovela\n",
      "Budiman\n",
      "High-Level\n",
      "Domain\n",
      "work\n",
      "The\n",
      "team\n",
      "analyzed\n",
      "the\n",
      "web\n",
      "app's\n",
      "code,\n",
      "setting\n",
      "short,\n",
      "mid,\n",
      "and\n",
      "long-term\n",
      "goals.\n",
      "Short-term\n",
      "tasks,\n",
      "like\n",
      "improving\n",
      "the\n",
      "navigation\n",
      "bar,\n",
      "creating\n",
      "filtered\n",
      "student\n",
      "lists,\n",
      "and\n",
      "updating\n",
      "the\n",
      "public\n",
      "data\n",
      "schema\n",
      "and\n",
      "database,\n",
      "were\n",
      "completed.\n",
      "Mid-term\n",
      "goals,\n",
      "such\n",
      "as\n",
      "linking\n",
      "project\n",
      "and\n",
      "intake\n",
      "pages\n",
      "and\n",
      "refining\n",
      "the\n",
      "UI,\n",
      "are\n",
      "underway.\n",
      "Long-term\n",
      "goals,\n",
      "including\n",
      "database\n",
      "optimization\n",
      "and\n",
      "platform\n",
      "migration,\n",
      "are\n",
      "set\n",
      "for\n",
      "future\n",
      "interns.\n",
      "Documentation\n",
      "in\n",
      "the\n",
      "project\n",
      "wiki\n",
      "and\n",
      "SQL\n",
      "scripts\n",
      "ensure\n",
      "smooth\n",
      "handovers\n",
      "for\n",
      "upcoming\n",
      "cohorts.\n",
      "Architecture\n",
      "/\n",
      "Algorithm\n",
      "work\n",
      "The\n",
      "project\n",
      "uses\n",
      "a\n",
      "modular\n",
      "architecture\n",
      ",\n",
      "making\n",
      "it\n",
      "easy\n",
      "to\n",
      "test\n",
      "and\n",
      "integrate\n",
      "new \n",
      "features.\n",
      "A\n",
      "responsive\n",
      "navigation\n",
      "bar\n",
      "adapts\n",
      "to\n",
      "different\n",
      "screen\n",
      "sizes,\n",
      "with\n",
      "dropdowns \n",
      "for\n",
      "better\n",
      "organization.\n",
      "Key\n",
      "features\n",
      "include\n",
      "dynamic\n",
      "student\n",
      "lists,\n",
      "email\n",
      "copy \n",
      "functionality ,\n",
      "and\n",
      "direct\n",
      "links\n",
      "between\n",
      "project,\n",
      "intake\n",
      "pages,\n",
      "and\n",
      "filtered\n",
      "student\n",
      "lists, \n",
      "streamlining\n",
      "navigation.\n",
      "Technical\n",
      "work\n",
      "●\n",
      "Frontend\n",
      "(UI/UX):ο\n",
      "Designed\n",
      "a\n",
      "responsive\n",
      "navigation\n",
      "bar\n",
      "using\n",
      "HTML\n",
      "and\n",
      "CSS\n",
      "for\n",
      "seamless\n",
      "navigation\n",
      "across\n",
      "devices,\n",
      "incorporating\n",
      "dropdown\n",
      "menus\n",
      "for\n",
      "different\n",
      "sections.\n",
      "ο\n",
      "Developed\n",
      "subpages\n",
      "for\n",
      "student\n",
      "lists\n",
      "(current,\n",
      "future,\n",
      "past,\n",
      "all\n",
      "students)\n",
      "and\n",
      "added\n",
      "buttons\n",
      "linking\n",
      "intake\n",
      "and\n",
      "project\n",
      "pages\n",
      "with\n",
      "pre-filtered\n",
      "data.\n",
      "●\n",
      "Backend\n",
      "(Database\n",
      "&\n",
      "Functionality):\n",
      "ο\n",
      "Generated\n",
      "fake\n",
      "test\n",
      "data\n",
      "and\n",
      "updated\n",
      "database\n",
      "schemas\n",
      "accordingly .\n",
      "ο\n",
      "Created\n",
      "upgrade_database.sql\n",
      "to\n",
      "document\n",
      "and\n",
      "maintain\n",
      "database\n",
      "changes\n",
      "for\n",
      "future\n",
      "students.\n",
      "●\n",
      "Testing\n",
      "&\n",
      "Integration:\n",
      "ο\n",
      "Tested\n",
      "the\n",
      "system\n",
      "using\n",
      "Nectar\n",
      "VM\n",
      "to\n",
      "simulate\n",
      "real-world\n",
      "user\n",
      "behavior\n",
      "and\n",
      "ensure\n",
      "smooth\n",
      "functionality .\n",
      "Key\n",
      "Links\n",
      "1.\n",
      "Link\n",
      "to\n",
      "the\n",
      "wiki:\n",
      "https://github.com/WEHI-ResearchComputing/student-intern-organiser/wiki\n",
      "2.\n",
      "Link\n",
      "to\n",
      "the\n",
      "Technical\n",
      "notes:\n",
      "Technical\n",
      "Notes\n",
      "2024\n",
      "S2\n",
      "3.\n",
      "Link\n",
      "to\n",
      "the\n",
      "Final\n",
      "Presentation\n",
      "slides\n",
      "in\n",
      "SharePoint:Genomics\n",
      "Invoicing\n",
      "Project:\n",
      "Interns:\n",
      "Changyuan\n",
      "(David)\n",
      "Ni,\n",
      "Jiayi\n",
      "(Joyce)\n",
      "Li,\n",
      "Ramon\n",
      "Felipe,\n",
      "Iffat\n",
      "Abdul\n",
      "Azeez\n",
      "High-Level\n",
      "Domain\n",
      "work\n",
      "The\n",
      "team\n",
      "first\n",
      "learns\n",
      "in\n",
      "detail\n",
      "the\n",
      "client’s\n",
      "original\n",
      "workflow,\n",
      "in\n",
      "which\n",
      "the\n",
      "client\n",
      "wishes\n",
      "to\n",
      "have\n",
      "the\n",
      "tedious\n",
      "manual\n",
      "process\n",
      "of\n",
      "producing\n",
      "invoices\n",
      "automated.\n",
      "The\n",
      "team\n",
      "drafted\n",
      "and\n",
      "refined\n",
      "the\n",
      "wireframe\n",
      "for\n",
      "the\n",
      "concept\n",
      "of\n",
      "automation\n",
      "app\n",
      "in\n",
      "generation\n",
      "of\n",
      "genomic\n",
      "invoices.\n",
      "The\n",
      "team\n",
      "considered\n",
      "architectural\n",
      "limitations\n",
      "of\n",
      "the\n",
      "deployment\n",
      "environment\n",
      "and\n",
      "develops\n",
      "software\n",
      "architecture\n",
      "of\n",
      "the\n",
      "app\n",
      "based\n",
      "on\n",
      "the\n",
      "limitations.\n",
      "Architecture\n",
      "/\n",
      "Algorithm\n",
      "work\n",
      "Here\n",
      "is\n",
      "the\n",
      "link\n",
      "to\n",
      "the\n",
      "architecture\n",
      "diagram\n",
      "the\n",
      "team\n",
      "developed:\n",
      "https://lucid.app/lucidchart/295c39f2-77b2-4cd8-9a64-bced69e188b7/edit?viewport_loc\n",
      "=379%2C407%2C4469%2C21 10%2C0_0&invitationId=inv_91729030-3e45-4bcf-aac6-\n",
      "ce3bb4682304\n",
      "Technical\n",
      "work\n",
      "The\n",
      "team\n",
      "configured\n",
      "and\n",
      "tested\n",
      "the\n",
      "local\n",
      "development\n",
      "environment,\n",
      "server-side\n",
      "deployment\n",
      "environment\n",
      "and\n",
      "the\n",
      "protocol\n",
      "for\n",
      "connecting\n",
      "to\n",
      "the\n",
      "server\n",
      "at\n",
      "WEHI.\n",
      "The\n",
      "team\n",
      "develops\n",
      "an\n",
      "upload\n",
      "interface,\n",
      "with\n",
      "testing\n",
      "files\n",
      "and\n",
      "correct\n",
      "output\n",
      "ready.\n",
      "Key\n",
      "Links\n",
      "1.\n",
      "Link\n",
      "to\n",
      "wiki,\n",
      "all\n",
      "relevant\n",
      "links\n",
      "are\n",
      "found\n",
      "in\n",
      "the\n",
      "wiki:\n",
      "Genomics\n",
      "‐\n",
      "invoicing\n",
      "wiki\n",
      "· \n",
      "Ayacolyte/genomics-invoicing\n",
      "Wiki\n",
      "·\n",
      "GitHub\n",
      "Topic: RCP#0032 Intake 10 Student Internship Summary reports (share with all)\n",
      "Keywords: data, github, project, technical, work\n",
      "Source: None\n",
      "----------------------------------------\n",
      "Title: Content from Research Computing Platform Student Internship Handbook\n",
      "Content: Research\n",
      "Computing\n",
      "Platform\n",
      "Student Handbook3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8Introduction\n",
      "Philosophy\n",
      "Benefits for Students\n",
      "Numbers behind the program\n",
      "Code of Conduct\n",
      "Want to know more?Table of ContentsIntroduction\n",
      "The Research Computing Platform (RCP) is a  \n",
      "collaborative, multi-disciplinary lab that\n",
      "supports and advocates for researchers and\n",
      "their computational research needs at WEHI.\n",
      "RCP has established a 100% remote, unpaid\n",
      "student internship program with subjects\n",
      "provided at the University of Melbourne. We\n",
      "did this to leverage the experience we have in\n",
      "the RCP of working with student software\n",
      "interns by collaborating with labs. \n",
      "Because this is unpaid, we aim to get students  \n",
      "via the official programs at the University of\n",
      "Melbourne so they can obtain course credit.\n",
      "This program allows us to share our\n",
      "knowledge and experiences with the students\n",
      "to help them to build their confidence so thatthey know that they have the skills and\n",
      "initiative to handle future situations.\n",
      "There are three intakes during the year,\n",
      "Semester 1, Semester 2, and Summer.\n",
      "We aim to share the information from our\n",
      "current student interns to our future student\n",
      "interns. We do this by getting our current\n",
      "students to document the nuances of the\n",
      "project and the challenges that they faced. \n",
      "We are constantly trying to improve the\n",
      "experience for our students and always\n",
      "appreciate feedback.\n",
      "While our most consistent feedback is to have  \n",
      "an in-person work environment, we are only\n",
      "providing 100% online work environments.\n",
      "WEHI RCP  Student Handbook | 3Students at RSE Parkville lunch that happens on the second Thursday of each month.Proactive\n",
      "ProactiveProactive\n",
      "Proactive\n",
      "Concept-first approach\n",
      "It is important for students to\n",
      "understand the high-level concepts of\n",
      "the domain the student is working in.\n",
      "This increases the independence of\n",
      "the student to work through complexity.\n",
      "Test your limits\n",
      "The ability to learn quickly by doing\n",
      "your own research is important.\n",
      "Finding out how fast you learn and\n",
      "where your limits are, in a safe space,\n",
      "can help you to know yourself better.Philosophy\n",
      "Documentation is Key\n",
      "Students need to recognise the limited\n",
      "time they have and what they can\n",
      "achieve. This is why documentation is\n",
      "key to ensure information is passed to\n",
      "future students.\n",
      "Collaboration is vital\n",
      "There are multiple internships running\n",
      "at the same time. We encourage\n",
      "students to collaborate within projects\n",
      "and across sister projects (similar\n",
      "projects) via co-working meetings.\n",
      "WEHI RCP  Student Handbook | 4Benefits for Students\n",
      "There are many benefits for student interns in\n",
      "this program to help them progress in their\n",
      "careers by giving them opportunities to grow\n",
      "and learn in a safe environment and achieve\n",
      "their potential, which builds confidence.\n",
      "Many students start the program having some\n",
      "level of technical skills, but very little\n",
      "understanding of how important it is to know\n",
      "the nuances and concepts of the work\n",
      "environment and domain knowledge.\n",
      "This is why we give them the time to research\n",
      "the concepts and give them feedback on how\n",
      "to refine those concepts.\n",
      "Student interns are provided with honest\n",
      "feedback to show where their skills and\n",
      "abilities place them, what kind of organisation\n",
      "they might be a good fit with, and how they\n",
      "can improve during and after the internship.Students also get the opportunity to learn real-\n",
      "world skills such as keeping meeting notes,\n",
      "documentation, learning how to communicate,\n",
      "and giving presentations. \n",
      "Students also get the opportunity to deal with\n",
      "realistic data and real world problems, where\n",
      "the answers and the technical solution is not\n",
      "so clear as in their coursework.\n",
      "Students are encouraged to self-direct during\n",
      "the internship. Balancing what the student\n",
      "wants to do and benefiting WEHI is a great\n",
      "example of a fantastic project.\n",
      "All in all, students have the opportunity to\n",
      "leave the internship with an improved sense of\n",
      "confidence that they have the ability to handle\n",
      "new environments and domains, even if they\n",
      "haven't worked in that area before. This is the\n",
      "best outcome we can hope for as supervisors.\n",
      "WEHI RCP  Student Handbook | 5\n",
      "Top L-R: Youran Zhou, Marika Benetti-Hille. Bottom L-R: Rowland Mosbergen, Gilbert Putra.Numbers behind the program\n",
      "17\n",
      "student projects\n",
      "104\n",
      "student interns\n",
      "19,000+\n",
      "hours of effort4.7/5\n",
      "student rating\n",
      "9\n",
      "projects per intake\n",
      "30\n",
      "students per intake\n",
      "WEHI RCP  Student Handbook | 6Code of Conduct\n",
      "This was originally taken from the Code of\n",
      "Conduct from Django. This is a snippet of the\n",
      "full Code of Conduct on the website.\n",
      "This community is made up of a diverse\n",
      "mixture of researchers, research software\n",
      "engineers, professionals and students.\n",
      "Diversity is what we are hoping to improve our\n",
      "communities and workplaces, but it can also\n",
      "lead to communication issues and\n",
      "unhappiness. \n",
      "To that end, we have a few ground rules that\n",
      "we ask people to adhere to. This code applies\n",
      "equally to founders, mentors and those\n",
      "seeking help and guidance.\n",
      "This isn’t an exhaustive list of things that you\n",
      "can’t do. Rather, take it in the spirit in which\n",
      "it’s intended -a guide to make it easier to\n",
      "enrich all of us and the technical communities\n",
      "in which we participate.\n",
      "This code of conduct applies to all spaces\n",
      "managed by the group. This includes chat\n",
      "rooms, the mailing lists, events, and any other\n",
      "forums created by the platform which the\n",
      "community uses for communication. \n",
      "In addition, violations of this code outside\n",
      "these spaces may affect a person's ability to\n",
      "participate within them. If you believe\n",
      "someone is violating the code of conduct,\n",
      "please let us know.\n",
      "The key points are:\n",
      "Be friendly and patient.\n",
      "Be welcoming.\n",
      "Be considerate.\n",
      "Be respectful.\n",
      "Be careful with the words you choose.We strive to be a community that welcomes\n",
      "and supports people of all backgrounds and\n",
      "identities. This includes, but is not limited to\n",
      "members of any race, ethnicity, culture,\n",
      "national origin, colour, immigration status,\n",
      "social and economic class, educational level,\n",
      "sex, sexual orientation, gender identity and\n",
      "expression, age, size, family status, political\n",
      "belief, religion, and mental and physical ability.\n",
      "Your work will be used by other people, and\n",
      "you in turn will depend on the work of others.\n",
      "Any decision you take will affect users and\n",
      "colleagues, and you should take those\n",
      "consequences into account when making\n",
      "decisions. Remember that we’re a diverse\n",
      "community, so you might not be\n",
      "communicating in someone else’s primary\n",
      "language.\n",
      "Not all of us will agree all the time, but\n",
      "disagreement is no excuse for poor behavior\n",
      "and poor manners. We might all experience\n",
      "some frustration now and then, but we cannot\n",
      "allow that frustration to turn into a personal\n",
      "attack. It’s important to remember that a\n",
      "community where people feel uncomfortable\n",
      "or threatened is not a productive one.\n",
      "Members of the community should be\n",
      "respectful when dealing with other members\n",
      "as well as with people outside the community.\n",
      "When we disagree, try to understand why.\n",
      "Disagreements, both social and technical,\n",
      "happen all the time and we are no exception. It\n",
      "is important that we resolve disagreements\n",
      "and differing views constructively. Remember\n",
      "that we’re different. The strength of this\n",
      "community comes from its diversity. Different\n",
      "people have different perspectives on issues.\n",
      "Being unable to understand why someone\n",
      "holds a viewpoint doesn’t mean that they’re\n",
      "wrong. \n",
      "WEHI RCP  Student Handbook | 7Want to know more?\n",
      "All the information on this page is on the\n",
      "website’s main student page via the QR code\n",
      "down below.\n",
      "FAQ\n",
      "There is a FAQ on the website under “Key\n",
      "Documents to review and FAQ”.\n",
      "This FAQ provides information on:\n",
      "Applying for the internship program,\n",
      "Onboarding onto the program,\n",
      "What is expected at meetings, and\n",
      "What is expected when you finish.\n",
      "Key Milestones and Emails\n",
      "The Key Milestones and Emails page can be\n",
      "found under “Key Documents to review and\n",
      "FAQ”.\n",
      "At the bottom fo the Key Milestones and\n",
      "Emails page you can find the onboarding\n",
      "emails that are sent out throughout the intake\n",
      "to remind students of the expectations of the\n",
      "program.\n",
      "Learn real world skills\n",
      "We prepare students for the real-world by\n",
      "teaching them:\n",
      "how understanding the domain problem\n",
      "and the users is more important than\n",
      "technical skills, and how to work on a\n",
      "complex, ambiguous project,\n",
      "showing them how to become as\n",
      "independent as possible,\n",
      "show them how to document and share\n",
      "knowledge to others in a professional\n",
      "manner,\n",
      "explain how a software maturity model can\n",
      "help clarify expectations, and\n",
      "teaching them how to work productively in\n",
      "a remote environment.We even tell students how to try to avoid the\n",
      "top 5 mistakes that students make.\n",
      "Available Projects\n",
      "There is a list of available projects under the\n",
      "title “List of student intern projects”.\n",
      "These projects change from intake to intake,\n",
      "so please reach out if you are unsure via\n",
      "email:  mosbergen [dot] r [at] wehi [dot] edu\n",
      "[dot] au.\n",
      "How to Apply\n",
      "We suggest that you write a 1 page cover\n",
      "letter introducing yourself, along with your\n",
      "resume. You can find more details under “How\n",
      "to Apply”.\n",
      "This is a popular program as we can get over\n",
      "60 applications per intake for only 30 student\n",
      "places. This is why it can be challenging to\n",
      "accomodate all students. We do try our best to\n",
      "provide feedback but this is limited due to the\n",
      "numbers involved.\n",
      "WEHI RCP  Student Handbook | 8Research\n",
      "Computing\n",
      "Platform\n",
      "Topic: Research Computing Platform Student Internship Handbook\n",
      "Keywords: program, projects, rcp, student, students\n",
      "Source: None\n",
      "----------------------------------------\n",
      "Title: Content from RCP0026 Welcome Students Semeter 2 Intake 10\n",
      "Content: Walter and Eliza Hall Institute of Medical ResearchRCP Student Internship Welcome \n",
      "Summer 2024 2025\n",
      "Week of 25th November 2024Acknowledgement of Country\n",
      "I acknowledge the Wurundjeri and Boon Wurrung people, on\n",
      "whose unceded lands some of us live and work here in\n",
      "Naarm (Melbourne). I respectfully acknowledge their Elders,\n",
      "past and present. I also acknowledge all the Traditional\n",
      "Owners of Country throughout the continent of Australia. I\n",
      "pay my respects to their Elders past and present. \n",
      "02Agenda\n",
      "Ask the audience \n",
      "Introduce yourself\n",
      "Philosophy\n",
      "Expectations\n",
      "Project Summaries\n",
      "Questions\n",
      "03The code of conduct is available in the QR\n",
      "code. In summary:\n",
      "Be kind\n",
      "Be patient\n",
      "Be respectful\n",
      "Be understanding \n",
      "Code of Conduct\n",
      "04To participate in answering\n",
      "some questions, please go to\n",
      "this QR code. First 20 people\n",
      "get to vote due to limitations.\n",
      "05Introduce OurselvesPhilosophyBest effort internship\n",
      "This is a best effort internship. \n",
      "This means that you don’t have a clear goal, this is about seeing how\n",
      "far you can go.\n",
      "We don’t really expect you to do anything except learn and contribute\n",
      "and see how well you can handle the problem.\n",
      "This means we may not want to tell you what to do. We want you to\n",
      "come up with solutions and explain why you think it would work.\n",
      "This is an opportunity for you to try new things in a safe environment.\n",
      "08Continuous Improvement Culture\n",
      "This is a continuous improvement culture.\n",
      "It is an attitude that relies on courage to highlight issues early.\n",
      "Focusing on solving the problem and getting the most from people.\n",
      "All ideas are welcomed, all ideas need to be reviewed - judge the\n",
      "idea, not the person who came up with it.\n",
      "Work through ideas as a group.\n",
      "Asking questions when you don’t know is important!\n",
      "Be careful of asking questions that have already been answered.\n",
      "09Key Continuous Improvement Skills\n",
      "To be successful in your career, you will need to have good continuous\n",
      "improvement skills. These are:\n",
      "Tolerance for Complexity,\n",
      "Tolerance for Ambiguity,\n",
      "Critical Thinking,\n",
      "Learnability,\n",
      "Adaptability,\n",
      "Collaborative by Default.\n",
      "This internship is here to really test your continuous improvement skills in\n",
      "a safe environment.10Communication is key in a\n",
      "remote workplace\n",
      "If you haven’t told me what you have done as an individual and as a\n",
      "group, I won’t know what is happening.\n",
      "The more you tell me, the easier it is for me to give you a good\n",
      "recommendation in the future.\n",
      "It is also easier for me to remember who you are and your personality if\n",
      "you speak up in the meeting. Please make sure everyone in your team\n",
      "has a chance to talk in the weekly project meeting with your supervisor.\n",
      "11How to work on a complex project\n",
      "12Stage 1\n",
      "Understand the high\n",
      "level context. Why do\n",
      "we want to solve this? Stage 2\n",
      "What are the best tools,\n",
      "architecture, and high level\n",
      "tasks to solve this? Stage 3\n",
      "Once you know the\n",
      "context, you can apply\n",
      "your technical skills.\n",
      "NOTE: Your technical skills are not as valuable as being able to understand the problem and its nuances, and then\n",
      "being able to solve the problem with as little help as possible.13Proactive\n",
      "Independent, curious, thinks before doing\n",
      "Asks questions after doing research and\n",
      "asking team mates\n",
      "Keeps team mates and supervisor\n",
      "updated regularly\n",
      "Understands high level context.Reactive\n",
      "Waits for supervisor to tell them what to\n",
      "do next, or does things without thinking\n",
      "Wants answers without research\n",
      "Doesn’t keep anyone up to date about\n",
      "progress or issues\n",
      "Doesn’t understand high level context.Two types of interns - which are you?I’m not the only one...\n",
      "Employers' gripe with young people today is their\n",
      "lack of motivation or initiative—50% of the leaders\n",
      "surveyed cited that as the reason why things didn’t\n",
      "work out with their new hire.\n",
      "Bosses also pointed to Gen Z being unprofessional,\n",
      "unorganized, and having poor communication skills\n",
      "as their top reasons for having to sack grads.\n",
      "https://finance.yahoo.com/news/bosses-firing-gen-z-\n",
      "grads-111719818.html 14If you are struggling, please reach out!\n",
      "We need to make sure our students are in\n",
      "a safe place. Please reach out to your team\n",
      "mates if you need help understanding what\n",
      "is needed. \n",
      "Please reach out to your supervisor if your\n",
      "team mates cannot help.\n",
      "Remember, it is more important to help\n",
      "your team mates than making progress on\n",
      "the project. Collaboration is highly prized.15ExpectationsTimeline\n",
      "Week 1\n",
      "StartWeek 4\n",
      "Whiteboard\n",
      "presentationWeek 5\n",
      "Meet Subject\n",
      "Matter ExpertsWeek 11\n",
      "Practice talk\n",
      "& reportWeek 12\n",
      "Final talk\n",
      "17Three weekly meetings\n",
      "Aim for at least three meetings per week:\n",
      "One with your project group and your supervisor 1.\n",
      "One with your project group only as a co-working\n",
      "session2.\n",
      "One with your sister project as a co-working session 3.\n",
      "An email was sent last week with a list of all students and\n",
      "projects.\n",
      "Please use this to reach out to your fellow students in your\n",
      "project and your sister projects.\n",
      "We need to organise\n",
      "regular weekly meetings\n",
      "as soon as possible. One\n",
      "person from each team\n",
      "should email me with four\n",
      "day/times between\n",
      "Monday and Wednesday\n",
      "that all students can\n",
      "attend, so I can organise\n",
      "with other supervisors.\n",
      "Please cc the other\n",
      "students when you send\n",
      "this email.\n",
      "Rowland Mosbergen 18Whiteboard Presentation guidelines\n",
      "We want you to explain Stage 1 and\n",
      "Stage 2 in the week 4 whiteboard\n",
      "presentation. The key questions are:\n",
      "Why do we want to solve this?\n",
      "What are the best tools,\n",
      "architecture, and algorithms to\n",
      "solve this?\n",
      "How are you going to contribute to\n",
      "solving the problem?\n",
      "19Your WEHI email address\n",
      "When you get your WEHI email address, go to this spreadsheet\n",
      "to add your WEHI email to your name. This link has been sent by\n",
      "email.1.\n",
      "Also setup your WEHI email to access the WEHI-wide student\n",
      "intern group. Details for this are on the next slide.2.\n",
      "Also add in your profile picture under the folder Profile Pictures\n",
      "(in the WEHI-wide student intern group) and make sure the file\n",
      "name is in the format: Project Name + Name (e.g. Peter Parker\n",
      "in Student Management Project =>\n",
      "“Student_Management_Peter_Parker.png”)3.\n",
      "Please note that Open Source Contributors won’t have WEHI emails. 20Code for accessing Teams group\n",
      "We have a specific Microsoft Teams group for\n",
      "students, the “WEHI-wide student intern group”.\n",
      "Please use this code to access this group\n",
      "through your Teams - once you get your WEHI\n",
      "email address setup and log into teams.\n",
      "The code is: mjwo2mn\n",
      "Open source contributors will be added to this\n",
      "team manually.21Please send a weekly email update 24 hours before\n",
      "the meeting with:1.\n",
      "what each student has done, a.\n",
      "write down any questions you have for the\n",
      "meeting to use as an agenda,b.\n",
      "provide a link to the wiki, and c.\n",
      "provide a link to the technical notes in Sharepoint d.\n",
      "Remember to ask to record the meeting to more\n",
      "easily keep notes if needed2.\n",
      "Document the action items and make sure they are in\n",
      "the weekly email update for next week3.Weekly meeting expectations\n",
      "22Top 5 mistakes that students make\n",
      "The top 5 mistakes that students make:\n",
      "They don’t read the documentation 1.\n",
      "They try to solve a problem they don’t understand 2.\n",
      "They wait to be told what to do 3.\n",
      "They don’t know how to escalate feedback 4.\n",
      "They don’t know how to share their knowledge 5.\n",
      "23Asking a confirmation question\n",
      "It is good practice to confirm that what you are thinking matches with\n",
      "what your supervisor is thinking. One way to test this it to ask a\n",
      "confirmation question.\n",
      "A confirmation question is always welcome! Here are some examples:\n",
      "Just to confirm, you want to do X because ...?\n",
      "Have I got this right - you want us to review X because ....?\n",
      "I wanted to clarify - does that mean if we do X it will ....\n",
      "24Asking your supervisor a question\n",
      "Do your proper due diligence before you send your supervisor an email\n",
      "with a question:\n",
      "Did you search through the FAQ, check the onboarding doc, and the\n",
      "wiki onboarding page via the project pages? \n",
      "Did you ask your project teammates to help you? \n",
      "Did you write down in the email what actions you took in steps #2 and\n",
      "#3 so I know what you have tried?\n",
      "Did you specify exactly what you are having a problem with?\n",
      "Did you cc in your team mates into the email?\n",
      "25There are some ways to network\n",
      "Here are some ways to network with other RSEs (Research Software\n",
      "Engineers):\n",
      "RSE Parkville lunch on the 2nd Thursday of every month (in-person) 1.\n",
      "RSE monthly online meeting 4th Thursday of every month (online) 2.\n",
      "Previous students in projects have caught up in-person 3.\n",
      "Reach out and be proactive 4.\n",
      "26Project SummariesUnderstand Stage 1 and Stage 2\n",
      "There is a lot of documentation so to avoid confusion:\n",
      "The most accurate explanations are in Rowland’s Students\n",
      "Project Outline\n",
      "The 2nd most accurate explanations are the final presentations\n",
      "from previous students (the more recent, the more accurate)\n",
      "The 3rd most accurate are the week 4 whiteboard\n",
      "presentations from previous students (the more recent, the\n",
      "more accurate)\n",
      "The 4th most accurate are the project wikis\n",
      "There is also a FAQ, Internship handbook, and Code of Conduct.\n",
      "Work as a team, and as an intake, to cover all the documentation\n",
      "without duplication. 28Students Project Outline\n",
      "This project outline provides some ideas on what\n",
      "tasks you might consider doing.\n",
      "Please remember these are long-term goals and\n",
      "this internship is a best effort internship. This\n",
      "means that I am not expecting any of these\n",
      "goals to be completed. \n",
      "I am simply expecting that we're going to do the\n",
      "best that we can, collaboratively.  \n",
      "29Final and Whiteboard Presentations\n",
      "The final presentations are useful as they give\n",
      "you an idea of what previous students did and\n",
      "what they found useful and challenging.\n",
      "The whiteboard presentations are useful as they\n",
      "help you understand more details than the final\n",
      "presentations.\n",
      "Please note that the whiteboard presentations\n",
      "are less likely to be recorded than the final\n",
      "presentations and you will need WEHI access.30Most projects have a public wiki\n",
      "Most projects will have a public wiki that you can\n",
      "have a look at.\n",
      "Sometimes the last students updated them,\n",
      "sometimes they need to be updated.\n",
      "Once you have looked at the Students Project\n",
      "Outline and the final presentations, you should\n",
      "look through the wiki of your project and your\n",
      "sister projects.\n",
      "31Ask Me Anything sessions\n",
      "In the first week, I have sent you Ask Me Anything calendar\n",
      "invites in the morning and afternoon.\n",
      "This is a time to ask me anything about the process,\n",
      "organisation, and the projects.\n",
      "Remember you can:\n",
      "review this Welcome Presentation,\n",
      "connect with other students and sister projects via the\n",
      "names and emails spreadsheet, and\n",
      "review the Student Projects Outline of all the projects.32QuestionsTo participate in answering more\n",
      "questions, please go to this QR\n",
      "code. First 20 people get to vote\n",
      "due to limitations.\n",
      "34\n",
      "Thank you for being a part of our program!Doing technical without context\n",
      "It is like pushing a car\n",
      "because you don’t want to\n",
      "take time to learn how to\n",
      "drive.\n",
      "Photo by Sheikh Basharat : https://www.pexels.com/photo/men-\n",
      "pushing-the-white-car-on-snow-covered-road-15177095/\n",
      "32Doing technical with context\n",
      "Learning how to drive a car allows you to\n",
      "go faster for longer, not just now but in\n",
      "your career.\n",
      " https://pixabay.com/photos/car-vehicle-\n",
      "road-highway-5667107\n",
      "32\n",
      "Topic: RCP0026 Welcome Students Semeter 2 Intake 10\n",
      "Keywords: email, project, students, team, wehi\n",
      "Source: None\n",
      "----------------------------------------\n",
      "Title: Learn real world skills\n",
      "Content: Learn real world skills We prepare students for the real-world by teaching them: how understanding the domain problem and the users is more important than technical skills, and how to work on a complex, ambiguous project , showing them how to become as independent as possible , show them how to document and share knowledge to others in a professional manner, explain how a software maturity model can help clarify expectations , and teaching them how to work productively in a remote environment. We even tell students how to try to avoid the top 5 mistakes that students make .\n",
      "Topic: Unpaid Student Internship Program\n",
      "Keywords: real, skills, students, teaching, world\n",
      "Source: https://wehi-researchcomputing.github.io/students#learn-real-world-skills\n",
      "----------------------------------------\n",
      "Title: Types of projects\n",
      "Content: Types of projects Many of the projects work in the Data Analysis and Research Software Engineering space using High Performance Compute (HPC). We work across diverse projects such as imaging, cryo-EM, genomics, transcriptomics, clinical informatics, and capacity planning. We mainly work with projects that use R and Shiny, Python, Julia, bash, while also making the most out of other technologies such as RStudio, Jupyter notebooks, PowerBI and other applications within the data analytics space. Here are some of the recurring student intern projects and new projects we are working on .\n",
      "Topic: Unpaid Student Internship Program\n",
      "Keywords: data, notebooks, projects, space, work\n",
      "Source: https://wehi-researchcomputing.github.io/students#types-of-projects\n",
      "----------------------------------------\n",
      "Title: Open source contributors\n",
      "Content: Open source contributors Sometimes, we are in contact with students who cannot get course credit and are extremely keen to volunteer as an open source software contributor. In these situations, we have to be careful we do not act in an exploitative way. This is why we have written our expectations of potential open source contributors to make the expectations more transparent .\n",
      "Topic: Unpaid Student Internship Program\n",
      "Keywords: act, contributors, expectations, open, source\n",
      "Source: https://wehi-researchcomputing.github.io/students#open-source-contributors\n",
      "----------------------------------------\n",
      "Title: Hear from previous students\n",
      "Content: Hear from previous students You can listen to two students talk about their projects (click image below).\n",
      "Topic: Unpaid Student Internship Program\n",
      "Keywords: click, hear, image, listen, students\n",
      "Source: https://wehi-researchcomputing.github.io/students#hear-from-previous-students\n",
      "----------------------------------------\n",
      "Title: Key Documents to review and FAQ\n",
      "Content: Key Documents to review and FAQ To understand more about the program, you can read: the RCP Student Internship Program Handbook , the RCP Code of Conduct , the Social Media Policy for student interns , the online FAQ , and the key milestones and emails for the projects\n",
      "Topic: Unpaid Student Internship Program\n",
      "Keywords: faq, key, program, rcp, student\n",
      "Source: https://wehi-researchcomputing.github.io/students#key-documents-to-review-and-faq\n",
      "----------------------------------------\n",
      "Title: How to Apply\n",
      "Content: How to Apply We suggest that you write a 1 page cover letter introducing yourself. We also have material on how to write a good cover letter and what to look for when you are writing a resume . View the intake dates here Further details on how to apply are here .\n",
      "Topic: Unpaid Student Internship Program\n",
      "Keywords: apply, cover, dates, letter, write\n",
      "Source: https://wehi-researchcomputing.github.io/students#how-to-apply\n",
      "----------------------------------------\n",
      "Title: To make changes to this website\n",
      "Content: To make changes to this website Go to the GitHub repo to change this website\n",
      "Topic: Unpaid Student Internship Program\n",
      "Keywords: change, changes, github, make, website\n",
      "Source: https://wehi-researchcomputing.github.io/students#to-make-changes-to-this-website\n",
      "----------------------------------------\n",
      "Title: Philosophy\n",
      "Content: Philosophy Students are encouraged to self-direct during the internship and be as independent as possible, with supervision. Balancing what the student wants to do and benefiting WEHI is a great example of a fantastic project. The key continuous improvement skills that are tested and improved apon during this program are: Tolerance for Complexity Tolerance for Ambiguity Critical Thinking Adaptability Learnability Collaborative by Default It is important for students to understand the high-level concepts of the domain the student is working in. This increases the independence of the student to work through complexity. Students need to recognise the limited time they have and what they can achieve. This is why documentation is key to ensure information is passed to future students. The ability to learn quickly by doing your own research is important. Finding out how fast you learn and where your limits are, in a safe space, can help you to know yourself better. To get a better understanding of the internship, I provide a RCP student handbook . There are multiple internships running at the same time. We encourage students to collaborate within projects and across sister projects (similar projects) via co-working meetings.\n",
      "Topic: explanation about ohs\n",
      "Keywords: key, projects, student, students, tolerance\n",
      "Source: https://wehi-researchcomputing.github.io/explanation_about_ohs#philosophy\n",
      "----------------------------------------\n",
      "Title: Allocating Students to Projects\n",
      "Content: Allocating Students to Projects The way I allocate students to projects is based on their skills and interests. The process is as follows: I send an email to acknowledge their submission has been seen . If the application is not taken forward I email the  unsuccessful students as soon as possible.  If the application is taken forward I reach out to them for a short discussion. At that short discussion I explain to them the projects that might interest them and where I see that they could contribute. I explain the challenges and whether something is difficult or easy. I ask them to think about what they want. I also share with them the link to the project page so that they can see more options. This might take 15 minutes per student and takes up a lot of time, but I think it is worth it to make sure I understand them. Once they agree to a project that they want to do and that I can allocate them to, I will email them with an offer. At this point they can accept or refuse this offer.\n",
      "Topic: explanation about ohs\n",
      "Keywords: email, offer, projects, short, students\n",
      "Source: https://wehi-researchcomputing.github.io/explanation_about_ohs#allocating-students-to-projects\n",
      "----------------------------------------\n",
      "Title: During the project\n",
      "Content: During the project I ask students to meet a minimum of three times a week. One meeting is to meet as a team with the supervisor to understand the high-level concepts and the architectural or algorithmic limitations, another meeting is a co-working meeting with their fellow project members without the supervisor, and another meeting is a co-working meeting with “sister project” team members to help share information across projects. I ask the students to understand the basic concepts before they choose how they would like to improve the project. So, if they want to create a web application, they can, if it contributes to solving the broader problem. In that way, we are asking them to self-direct their project to something that is interesting to them and helps build the skills they want. I have changed the way I have setup the student projects so that now students are in groups of three or more. There have been times when I have not been able to make that happen, but that is the standard as of Summer 2023/2024. You can see the key milestones and the onboarding emails we send at regular intervals during the internship . Most projects are building on the previous set of students work as they are complicated and it can take a long time for average students to grasp new domain information. These average students want to be spoon-fed, which is a major criticism that businesses have of new graduates.\n",
      "Topic: explanation about ohs\n",
      "Keywords: meeting, project, projects, students, want\n",
      "Source: https://wehi-researchcomputing.github.io/explanation_about_ohs#during-the-project\n",
      "----------------------------------------\n",
      "Title: Documentation\n",
      "Content: Documentation By doing this I teach them that they need to document their new knowledge and technical work for the next set of students, which increases findability, usability and maintenance of the work that they have done. This is also a critical skill for their future careers for project handovers and maintenance work, which many students do not have experience with. As discussed earlier, the students and look at the wiki that shows what the previous students have done, and I also talk to them over the phone about the work of the previous students. This should not be a surprise to applicants that they are working on a project developed by previous interns. They can refuse the offer of the project if they find the project not to their liking. The current intake of the Genomics Metadata Multiplexing project is an example of an ongoing project that is working extremely well due to the foundational work done by previous students. This set of students are enjoying the work and the ability to make a difference.\n",
      "Topic: explanation about ohs\n",
      "Keywords: maintenance, previous, project, students, work\n",
      "Source: https://wehi-researchcomputing.github.io/explanation_about_ohs#documentation\n",
      "----------------------------------------\n",
      "Title: Other Interactions\n",
      "Content: Other Interactions I also have scheduled a voluntary follow-up session / networking session between students on Thursday across the entire student intake but have stopped these due to lack of uptake by the students. By the third week no-one attends, and I am left to myself. I also have added to the handbook and onboarding checklist the monthly in-person Research Software Engineer (RSE) lunches that I organise and attend but again, the uptake has been low. Roughly, less than 5% of students attend a lunch and none attend consistently. Last intake, I asked a group of students to liaise with another group on a project. I asked multiple times but this was not actioned. This intake, I did ask for more structure where a scheduled meeting with a sister project needed to be set and this has increased the communication between groups. In the projects where there is a need for a Subject Matter Expert (SME), I have been trialling to catchup with the SME at the 5-week mark for a Q and A. This allows the students to understand the information in the wiki and some basic terms and models of the domain so that they can make the most out of the SME’s time and answers. This has been a good working model so far. I go into the office once a month, mainly for the RSE lunches. I have worked at WEHI for over 3 years now and have had an in-person meeting with my supervisor once. I am basically a remote worker. So, to increase the opportunity of in-person meetups, I have tried to get students to meet me in-person as part of the RSE lunches, but there has been little uptake. I tried to organise an in-person tour of the WEHI building last year after some questions from students, but no students responded to the email. There used to be a weekly tour of the WEHI building but this been cancelled since the pandemic. I also emailed students about an in-person student intern conference that WEHI runs every year where they could present and meet fellow student interns, but no one responded. To ensure students are aware that this is 100% remote I have updated the website and I have amended the application form to now ask them to confirm that they know that this is a 100% remote internship as appears below: I recognise that this is a 100% remote role and that all meetings and interactions will be virtual. I also recognise that there are opportunities for in-person events like the monthly Parkville Research Software Engineer lunch.\n",
      "Topic: explanation about ohs\n",
      "Keywords: 100, person, remote, students, wehi\n",
      "Source: https://wehi-researchcomputing.github.io/explanation_about_ohs#other-interactions\n",
      "----------------------------------------\n",
      "Title: Other Resources\n",
      "Content: Other Resources Finally, I provide resources to the students that help them in every step of the program, including FAQS that include how I expect meetings to be run, how you can escalate a question, among other things. I also provide other ways that they can work towards independence by teaching them: how understanding the domain problem and the users is more important than technical skills, and how to work on a complex, ambiguous project , showing them how to become as independent as possible , show them how to document and share knowledge to others in a professional manner, explain how a software maturity model can help clarify expectations , and teaching them how to work productively in a remote environment. We even tell students how to try to avoid the top 5 mistakes that students make .\n",
      "Topic: explanation about ohs\n",
      "Keywords: provide, resources, students, teaching, work\n",
      "Source: https://wehi-researchcomputing.github.io/explanation_about_ohs#other-resources\n",
      "----------------------------------------\n",
      "Title: Feedback\n",
      "Content: Feedback We have had 169 students through the program since Semester 2, 2021 who have provided over 18 person years of effort to help us uncover and document complexity early in over 20 projects. Out of the 14 anonymous reviews that have been given by students as at 11th of October 2024, our internships have been rated a 4.7 out of 5.\n",
      "Topic: explanation about ohs\n",
      "Keywords: 11th, rated, reviews, semester, students\n",
      "Source: https://wehi-researchcomputing.github.io/explanation_about_ohs#feedback\n",
      "----------------------------------------\n",
      "Title: Semester 1 2025 Projects\n",
      "Content: Semester 1 2025 Projects The project would involve a series of stages to bring the software infrastructure to a level that will help with development in a complex research environment where currently only 2 people in the world know the software.  For more details see the AIVE project and the AIVE public wiki . This project helps with reproducibility in the field of Bioinformatics. For more details see BioNix project and the BioNix Getting Started Wiki . This project helps the Genomics lab quote their complex product range to internal and external clients. For more details see Genomics Invoicing project . This project helps the Genomics lab  streamline quality control plot generation for duplex sequencing data.  For more details see Duplex Sequencing Plugin project\n",
      "Topic: project wikis\n",
      "Keywords: details, genomics, helps, project, wiki\n",
      "Source: https://wehi-researchcomputing.github.io/project-wikis#semester-1-2025-projects\n",
      "----------------------------------------\n",
      "Title: Ongoing Projects\n",
      "Content: Ongoing Projects This project aims to create a proof-of-concept for a Data Lakehouse / Data Commons at WEHI. For more details see Introduction to REDMANE , Data Lakehouse / Data Commons project and the Data Commons Wiki . This project helps to setup foundational infrastructure for adding visualisation dashboards for clinically-adjacent data. For more details see Clinical Dashboards project. , the Extract PDF Wiki , and the Clinical Dashboards Wiki . This project aims to improve the web application that WEHI RCP uses to help streamline the recruitment of students for the internship program. For more details read the student organiser project.\n",
      "Topic: project wikis\n",
      "Keywords: dashboards, data, details, project, wiki\n",
      "Source: https://wehi-researchcomputing.github.io/project-wikis#ongoing-projects\n",
      "----------------------------------------\n",
      "Title: Potential Projects that are dependent on various factors\n",
      "Content: Potential Projects that are dependent on various factors This project helps to setup infrastructure to keep track of what happens to a sample once it reaches the Genomics Facility. For more details see Genomics Metadata Multiplexing project. and the Genomics Metadata Multiplexing Wiki This project is looking to create foundational knowledge of quantum computing in bioinformatics. For more details see Quantum Computing in Bioinformatics project and the Quantum Computing Wiki . This project helps with the current work around automated processing of images from microscopes to the High Performance Compute. For more details see Imaging project and the Imaging Getting Started Wiki . This project looks to make Cyton, a sophisticated mathematical model, accessible to the scientific community by creating a web application that researchers can access with their browsers from anywhere in the world. For more details see Immunology Web Application project. This project involves creating a web-based application to help conference organisers of RSEAA24, an international conference of Research Software Engineers that is held in September. For more details see the GitHub repo for the Conference Organiser .\n",
      "Topic: project wikis\n",
      "Keywords: application, details, project, quantum, wiki\n",
      "Source: https://wehi-researchcomputing.github.io/project-wikis#potential-projects-that-are-dependent-on-various-factors\n",
      "----------------------------------------\n",
      "Title: Previous projects\n",
      "Content: Previous projects This projects looks to improve on Haemosphere, which is like a web-based pocket dictionary for visualising and comparing genomic blood datasets. For more details see Haemosphere project and the Haemosphere wiki . This project looks to create models to forecast capacity and create dashboards to demonstrate current usage and help make informed decisions for storage and compute at WEHI. It also created a Storage Calculator that is now being implmented into REDMANE. For more details see Capacity Planning Storage and Compute project. This projects looks to improve the mixOmics toolkit, an R package dedicated to the statistical integration of omics data sets. For more details see mixOmics project. This project helps with understanding what could be streamlined when maintaining software packages for the popular Bioconductor community. For more details see schex Bioconductor project , the Bioconductor Maintenance wiki and the schex Bioconductor package . This project looks to define Research Data Management workflows and use them to benchmark High Performance Compute on WEHI infrastructure and beyond.\n",
      "To learn more about it, please read the presentation, Benchmarking domain-specific research workflow solutions at an international level as well as the GitHub from the students from 2023 that has three public Tableau graphs. A presentation of this work is available on Sharepoint (WEHI access only) . This project helps with enhancing the framework API for agent-based modelling in Immunology. For more details see Immunology modelling project This project helps to setup infrastructure to collate and display Quality Control (QC) information from Genomics workflows. For more details see Genomics Quality Control project. This project looks to report and analyse Big Data cryo-EM workflows and use machine learning to inform future experimental design. For more details see cryoEM project and the cryo-EM wiki . This project helps with the current work around automated processing of images from microscopes to the High Performance Compute. For more details see Flux project . This project looks to improve on LoxCodeR, a way of barcoding stem cells to follow how they differentiate to form other types of cells. For more details see LoxCode project.\n",
      "Topic: project wikis\n",
      "Keywords: bioconductor, compute, details, looks, project\n",
      "Source: https://wehi-researchcomputing.github.io/project-wikis#previous-projects\n",
      "----------------------------------------\n",
      "Title: Other documentation\n",
      "Content: Other documentation And a high level Getting started Guides - wiki\n",
      "Topic: project wikis\n",
      "Keywords: documentation, getting, guides, high, level\n",
      "Source: https://wehi-researchcomputing.github.io/project-wikis#other-documentation\n",
      "----------------------------------------\n",
      "Title: Introduction\n",
      "Content: Introduction LoxCode is a novel technology developed in the Naik lab at WEHI that allows to create on demand random tags (or barcodes) in the DNA of living cells. These tags are read out via next generation sequencing and help to study important questions in biology like cancer evolution or embryonic development. Given that both the technology and the data it generates are new, no software is currently available that would facilitate the analysis, especially for experimental researchers less familiar with programming and computation. Therefore, to make this tool available to a wider community, an easy to use R package (LoxcodeR) and a graphical use-interface (GUI) to process and analyze the sequencing data generated are under development.\n",
      "Topic: loxcoder\n",
      "Keywords: available, development, sequencing, technology, use\n",
      "Source: https://wehi-researchcomputing.github.io/student-loxcoder#introduction\n",
      "----------------------------------------\n",
      "Title: Duties while on placement\n",
      "Content: Duties while on placement The role of the intern is to: extend the existing LoxcodeR package and GUI software for the analysis of novel biological data work closely with experimental researchers to identify their needs around Loxcode data analysis and visualization Potential to develop new visualizations and analysis pipelines Potential to experiment with AI to create scripts to generate data analysis reports in a consistent automated or semi-automated way. There is also a fair amount of flexibility with this project to allow the student to inject their own ideas and introduce new features and functionality.\n",
      "Topic: loxcoder\n",
      "Keywords: analysis, automated, data, new, potential\n",
      "Source: https://wehi-researchcomputing.github.io/student-loxcoder#duties-while-on-placement\n",
      "----------------------------------------\n",
      "Title: Skills and Pre-requisites\n",
      "Content: Skills and Pre-requisites Skills and Pre-requisites: Interests in biological data analysis and biomedical research software applications Ability to learn and understand high-level concepts quickly Ability to work independently and to report to a group and discuss theories and results Good analytical skills\n",
      "Topic: loxcoder\n",
      "Keywords: ability, pre, requisites, skills, theories\n",
      "Source: https://wehi-researchcomputing.github.io/student-loxcoder#skills-and-pre-requisites\n",
      "----------------------------------------\n",
      "Title: Benefits for students\n",
      "Content: Benefits for students Benefits for students whilst undertaking the internship include: Learn new and apply already acquired data analytical skills to a cutting-edge biomedical application Gain insights into a modern interdisciplinary research environment at WEHI Deepen knowledge in the statistical computing language R\n",
      "Topic: loxcoder\n",
      "Keywords: acquired, benefits, statistical, students, undertaking\n",
      "Source: https://wehi-researchcomputing.github.io/student-loxcoder#benefits-for-students\n",
      "----------------------------------------\n",
      "Title: Introduction\n",
      "Content: Introduction As part of our ongoing efforts to evaluate and implement innovative data management strategies, we are offering an internship opportunity to work on a pre-production project for a data commons called REDMANE. We are seeking a motivated and detail-oriented intern to join our team and contribute to the development of a pre-production data infrastructure.\n",
      "Topic: student data commons\n",
      "Keywords: called, data, pre, production, strategies\n",
      "Source: https://wehi-researchcomputing.github.io/student-data-commons#introduction\n",
      "----------------------------------------\n",
      "Title: Multiple sub-projects within this project\n",
      "Content: Multiple sub-projects within this project This project is made up of the following sub-projects that an intern can apply for: Create synthetic multi-omics data to match synthetic clinical and other metadata Extend functionality of the Data Registry application in ReactJS and FASTAPI Ingestion of data and metadata into the Data Registry using Python, and authenticating to an API Setup standardisation in authentication and security for multiple Data Portals using OIDC, AAF, and KeyCloak Setup cBioPortal as a Data Portal on the Nectar Cloud secured with OIDC Setup generic secure Shiny/R App as a Data Portal on the Nectar Cloud secured with OIDC Setup Omero as a Data Portal on the Nectar Cloud secured with OIDC Setup Storage Calculator as a Data Portal on the Nectar Cloud secured with OIDC\n",
      "Topic: student data commons\n",
      "Keywords: data, oidc, portal, secured, setup\n",
      "Source: https://wehi-researchcomputing.github.io/student-data-commons#multiple-sub-projects-within-this-project\n",
      "----------------------------------------\n",
      "Title: Duties while on placement\n",
      "Content: Duties while on placement As a Research Software Engineer Intern, you will play a crucial role in supporting the design and implementation of a pre-production Research Data Management ecosystem called REDMANE. This internship will provide you with valuable hands-on experience in trialling, analysing, and improving different platforms. You will assist in building a scalable data management infrastructure and gain exposure to various aspects of data integration, modeling, and governance. The Research Software Engineer Intern role will generally: Assist in setup, extending, and testing Data Registry and Data Portals using synthetic data for multiple REDMANE ecosystems. Support the implementation of data ingestion pipelines for Data Registry and Data Portals securely. Contribute to the development of a base set of requirements for Data Portals to be able to be part of the REDMANE ecosystem. Setup environment to provide authentication across the Data Registry and Data Portals. Setup Data Portals for existing applications such as cBioPortal, Shniy, Omero and custom-made Storage Calculator. Assist in documenting the design decisions, and implementation processes. Contribute to creating technical documentation and user guides for future reference. Stay updated on emerging data management technologies and industry trends. Explore and experiment with new tools, frameworks, and platforms that can enhance the implementation.\n",
      "Topic: student data commons\n",
      "Keywords: data, implementation, portals, registry, research\n",
      "Source: https://wehi-researchcomputing.github.io/student-data-commons#duties-while-on-placement\n",
      "----------------------------------------\n",
      "Title: Skills and Pre-requisites\n",
      "Content: Skills and Pre-requisites To excel in this internship project, the ideal candidate should have a willingness to research system administration and development skilsl and processes, an ability to learn quickly, an enthusiasm for research software architecture, and a willingness to share and communicate information. It would be beneficial if the student had an interest in learning Python, Web site development, API development, command-line scripting, System administration, Virtual Machines, OpenStack Cloud, and how to improve business workflows.  It would also be of benefit if the student was interested in learning about bioinformatics data formats.\n",
      "Topic: student data commons\n",
      "Keywords: development, learning, research, student, willingness\n",
      "Source: https://wehi-researchcomputing.github.io/student-data-commons#skills-and-pre-requisites\n",
      "----------------------------------------\n",
      "Title: Further reading\n",
      "Content: Further reading Introduction to REDMANE Data Commons Wiki\n",
      "Topic: student data commons\n",
      "Keywords: commons, data, introduction, reading, redmane\n",
      "Source: https://wehi-researchcomputing.github.io/student-data-commons#further-reading\n",
      "----------------------------------------\n",
      "Title: Introduction\n",
      "Content: Introduction WEHI is currently focusing on improving its ability to handle big data from the multi-million dollar Cryogenic Electron Microscopy (cryo-EM) instrument. The candidate will develop an understanding of data flow from the cryo-EM facility and determine how data and metadata should be stored to support Findable Accessible Interoperable and Resuable data practices. The key output of the project is a framework for evaluating the suitability of third-party or in-house tools to support complex cryo-EMprocessing requirements.\n",
      "Topic: cryoem\n",
      "Keywords: ability, cryo, data, em, support\n",
      "Source: https://wehi-researchcomputing.github.io/student-cryoem#introduction\n",
      "----------------------------------------\n",
      "Title: Duties while on placement\n",
      "Content: Duties while on placement The Research Data Engineer Intern role will: review cryo-EM data transfer and storage and look to improve the scripts and tools available to the cyro-EM community, setup and test these scripts and tools to benchmark their speed, maintainability and extensibility, provide recommendations and suggestions for potential future projects. There is also flexibility with this project to allow the student to inject their own ideas and introduce new features and functionality.\n",
      "Topic: cryoem\n",
      "Keywords: data, em, placement, scripts, tools\n",
      "Source: https://wehi-researchcomputing.github.io/student-cryoem#duties-while-on-placement\n",
      "----------------------------------------\n",
      "Title: Skills and Pre-requisites\n",
      "Content: Skills and Pre-requisites Skills and Pre-requisites include: Interest in research and Big Data processing Basic knowledge of the Linux command-line and ability to learn on-the-fly Willingness and ability to learn and understand high-level concepts Ability to work independently and to report to a group and discuss theories and results Good analytical skills Previous experience with git would be useful but not necessary\n",
      "Topic: cryoem\n",
      "Keywords: ability, learn, pre, requisites, skills\n",
      "Source: https://wehi-researchcomputing.github.io/student-cryoem#skills-and-pre-requisites\n",
      "----------------------------------------\n",
      "Title: Benefits for students\n",
      "Content: Benefits for students Benefits for students whilst undertaking the internship include: Working in a High Performance Computing environment or adjacent environment. Practical experience with potential exposure to Bash, Python, C++. Gain understanding of how real-world software is assessed, developed and how priorities and requirements are established within a research environment. Gain understanding of the importance of maintainable, scalable and extensible code.\n",
      "Topic: cryoem\n",
      "Keywords: benefits, environment, gain, students, understanding\n",
      "Source: https://wehi-researchcomputing.github.io/student-cryoem#benefits-for-students\n",
      "----------------------------------------\n",
      "Title: Introduction\n",
      "Content: Introduction Post-sequencing quality control (QC) is an important step in ensuring that the quality of sequencing data meets expectations. Multiple tools exist to evaluate sequencing quality, such as FastQC[1], Fastq Screen[2] and Qualimap[3]. Core sequencing facilities, such as WEHI Genomics, process hundreds of sequencing runs every year. In order to troubleshoot sequencing issues and provide assurance of data quality to collaborators, sequencing facilities must implement robust data management workflows to ensure that QC data processing is automated where possible, is easily accessible and is appropriately archived for posterity. Given a large volume of runs, there exists the possibility of inter-run QC comparisons to better gauge run quality. MultiQC[4] is a software tool that collates and displays QC information from numerous supported bioinformatics tools. MultiQC operates on a per-run basis, however, MegaQC[5] collates the data from these reports for comparison. However, MegaQC has not been in active development since 2020 and is considered “pretty unstable” by the developers. Additionally, the software lacks functionality that lists extensive project metadata, so that experiments can be more easily tracked and MultiQC reports can be easily located. Lastly, the tool lacks easy exporting of data, so that analyses can be further analysed programmatically. Given that MegaQC overlaps with many of our use cases, it may be possible to modify and/or extend the software for our use cases. Alternatively, Shiny apps (shiny.rstudio.com) allow for interactive data analysis and provide an ideal platform for QC data collation. Integration with Monday.com and LabArchives used by the Genomics lab may also be of benefit for retrieving and/or depositing QC data and project metadata. FastQC. “FastQC: a quality control tool for high throughput sequence data.” (2016). Wingett, Steven W., and Simon Andrews. “FastQ Screen: A tool for multi-genome mapping and quality control.” F1000Research 7 (2018). Okonechnikov, Konstantin, Ana Conesa, and Fernando García-Alcalde. “Qualimap 2: advanced multi-sample quality control for high-throughput sequencing data.” Bioinformatics 32.2 (2016): 292-294. Ewels, Philip, et al. “MultiQC: summarize analysis results for multiple tools and samples in a single report.” Bioinformatics 32.19 (2016): 3047-3048. https://megaqc.info/\n",
      "Topic: genomics quantum computing\n",
      "Keywords: data, multiqc, qc, quality, sequencing\n",
      "Source: https://wehi-researchcomputing.github.io/student-genomics-qc#introduction\n",
      "----------------------------------------\n",
      "Title: Duties while on placement\n",
      "Content: Duties while on placement The Research Software Engineer Intern role will: work closely with researchers to identify their needs around Genomics quality control at scale Review the applications available for maintainability and extensibility Implement trial applications such as MegaQC to test fit-for-purpose There is also a fair amount of flexibility with this project to allow the student to inject their own ideas and introduce new features and functionality.\n",
      "Topic: genomics quantum computing\n",
      "Keywords: allow, applications, megaqc, needs, new\n",
      "Source: https://wehi-researchcomputing.github.io/student-genomics-qc#duties-while-on-placement\n",
      "----------------------------------------\n",
      "Title: Skills and Pre-requisites\n",
      "Content: Skills and Pre-requisites Skills and Pre-requisites: Basic knowledge or ability to learn quickly Python/Javascript/CSS, databases and Linux command-line Ability to learn and understand high-level concepts quickly Ability to work independently and to report to a group and discuss theories and results Good analytical skills Working with git would be an advantage\n",
      "Topic: genomics quantum computing\n",
      "Keywords: ability, pre, quickly, requisites, skills\n",
      "Source: https://wehi-researchcomputing.github.io/student-genomics-qc#skills-and-pre-requisites\n",
      "----------------------------------------\n",
      "Title: Benefits for students\n",
      "Content: Benefits for students Benefits for students whilst undertaking the internship include: Each student will get hands on experience in working in an emerging research software environment within a highly regarded medical research institute. Gain understanding of how real-world software is assessed, developed and how priorities and requirements are established within a research environment. Gain understanding of the importance of maintainable, scalable and extensible code. Improving oral and written communication skills in a team environment.\n",
      "Topic: genomics quantum computing\n",
      "Keywords: benefits, environment, research, students, understanding\n",
      "Source: https://wehi-researchcomputing.github.io/student-genomics-qc#benefits-for-students\n",
      "----------------------------------------\n",
      "Title: Introduction\n",
      "Content: Introduction Bioconductor is a pivotal and highly influential initiative in the field of bioinformatics and computational biology. It plays a critical role in helping researchers by providing an extensive and comprehensive ecosystem of software tools, packages, and resources tailored specifically for the analysis and interpretation of high-throughput biological data. Visualizations, especially visualizations of dimension reductions, are the workhorse of all scRNA-seq data analyses. They are hugely important during all stages of analysis, from exploring to presenting results. They often shape analysis decisions, like which batch correction approach to use, and can point to novel discoveries, like novel cell type marker genes or even new cell types. Unfortunately, currently employed visualization strategies struggle with the scale and sparsity of scRNA-seq data, sometimes with disastrous consequences. Overplotting is not a new problem and it has plagued many different fields, many of which have come up with unique solutions. Here, we suggest the use of hexagonal binning (Carr, 1990; Carr et al., 1987) for dimension reduction representations of scRNA-seq data. In order to make hexagonal plotting readily available to the scientific community, we developed schex (single-cell hexagonal plotting), an R package that allows users to produce hexagonal binning representations for dimension reductions of scRNA-seq. However, maintaining research software and making it easy to use can be difficult for researchers in the long run. This project is to aim at finding out which areas of software maintenance can possibly abstracted away from the researcher and into the hands of a Research Software Engineer (RSE).\n",
      "Topic: schex\n",
      "Keywords: data, hexagonal, scrna, seq, software\n",
      "Source: https://wehi-researchcomputing.github.io/student-schex#introduction\n",
      "----------------------------------------\n",
      "Title: Duties while on placement\n",
      "Content: Duties while on placement This project would suit a candidate who was interested in maintaining research software, wants to gain experience within an open source software environment like Bioconductor, and enjoys learning about complex processes. This role is challenging as the person will need to learn about the data, the package, how to understand the output, as well as looking at the code and the software requirements for open source frameworks such as Bioconductor. The role will include: Documenting how Bioconductor and the software maintenance process currently works, Identifying problem areas that could be reviewed, Brainstorming and prototyping solutions of ways to reduce maintenance costs by the researcher, and Suggest other options and prototype as needed.\n",
      "Topic: schex\n",
      "Keywords: bioconductor, maintenance, open, software, source\n",
      "Source: https://wehi-researchcomputing.github.io/student-schex#duties-while-on-placement\n",
      "----------------------------------------\n",
      "Title: Skills and Pre-requisites\n",
      "Content: Skills and Pre-requisites To excel in this internship project, the ideal candidate should have a willingness to research and learn about Bioconductor and schex, an ability to learn quickly, an enthusiasm for trying new things, and a willingness to share and communicate information.\n",
      "Topic: schex\n",
      "Keywords: learn, share, skills, things, willingness\n",
      "Source: https://wehi-researchcomputing.github.io/student-schex#skills-and-pre-requisites\n",
      "----------------------------------------\n",
      "Title: Benefits for students\n",
      "Content: Benefits for students The benefits for students whilst undertaking the internship include: The student will gain practical Research Software Engineering  (RSE) experience with potential exposure to Bioconductor, single-cell RNASeq, and how to setup workflows for reproducibility. The student will gain understanding of how real-world software is assessed, developed and how priorities and requirements are established within a research environment. The student will have an opportunity to self-direct and be proactive in their approach to a new environment.\n",
      "Topic: schex\n",
      "Keywords: benefits, research, software, student, students\n",
      "Source: https://wehi-researchcomputing.github.io/student-schex#benefits-for-students\n",
      "----------------------------------------\n",
      "Title: Further reading\n",
      "Content: Further reading schex Bioconductor package schex GitHub repository\n",
      "Topic: schex\n",
      "Keywords: bioconductor, github, package, reading, schex\n",
      "Source: https://wehi-researchcomputing.github.io/student-schex#further-reading\n",
      "----------------------------------------\n",
      "Title: Introduction\n",
      "Content: Introduction mixOmics is a large R package that provides statistical methods to integrate omics data sets (e.g transcriptomics, proteomics, metabolomics, metagenomics) that simultaneously measure the activity of thousands of biological features (e.g transcripts, proteins, metabolites, bacteria). Data integration enables identification of specific biological relationships between these features (e.g. genes and proteins), to create new insights into molecular processes involved in health and disease. MixOmics includes 19 data integration methods, amongst which 13 were developed in our lab. These methods are all based on dimension reduction using Projection to Latent Structures (PLS). Our users include computational biologists, molecular biologists and bioinformaticians who wish to integrate their data and identify signatures of genes, proteins etc. to explain or predict a disease outcome. The package (ranked in the top 5% package in Bioconductor) is easy to use because all methods use the same underlying PLS principles and produce numerous graphics for interpretation (Fig. 1). We continuously improve the mixOmics package based on the community feedback.\n",
      "Topic: mixOmics\n",
      "Keywords: data, methods, mixomics, package, proteins\n",
      "Source: https://wehi-researchcomputing.github.io/student-mixOmics.html#introduction\n",
      "----------------------------------------\n",
      "Title: Duties while on placement\n",
      "Content: Duties while on placement As this is a large project, the internship requires complementary skillsets to: improve specific aspects of the package (e.g increase coverage for unit tests, trouble-shoot bugs or provide new features requested by users, improve code quality, develop new graphics) improve our existing tutorials and develop new ones on www.mixOmics.org if there is an appropriate opportunity and motivation, respond to users questions on our discussion forum at https://mixomics-users.discourse.group. This is because it would require a good mastery of the methods and would only apply towards the end of the internship. After the (steep) learning phase, there will be opportunities for students to propose new features and functionalities in the package if they wish. Figure 1. Overview of the methods in mixOmics for data exploration and integration of multiple omics data sets (courtesy of Prof. Lê Cao)\n",
      "Topic: mixOmics\n",
      "Keywords: features, improve, mixomics, new, users\n",
      "Source: https://wehi-researchcomputing.github.io/student-mixOmics.html#duties-while-on-placement\n",
      "----------------------------------------\n",
      "Title: Skills and Pre-requisites\n",
      "Content: Skills and Pre-requisites Skills and Pre-requisites: Very good knowledge of R and Linux command-line Ability to learn and understand high-level statistical concepts quickly Ability to work independently and to report to a group and discuss theories and results Excellent skills in statistical analysis of complex data Ability to work with github Ability to interact with users Interest in biological applications\n",
      "Topic: mixOmics\n",
      "Keywords: ability, pre, requisites, skills, statistical\n",
      "Source: https://wehi-researchcomputing.github.io/student-mixOmics.html#skills-and-pre-requisites\n",
      "----------------------------------------\n",
      "Title: Benefits for students\n",
      "Content: Benefits for students Benefits for students whilst undertaking the internship include: Each student will get hands on experience in working in an emerging research software environment. Gain understanding of how real-world software is assessed, developed and how priorities and requirements are established within a research environment. Gain understanding of the importance of maintainable, scalable and extensible code. Improving oral and written communication skills in a team environment. Learn about new statistical methods for mining large data Learn about high-throughput biology\n",
      "Topic: mixOmics\n",
      "Keywords: benefits, environment, learn, research, understanding\n",
      "Source: https://wehi-researchcomputing.github.io/student-mixOmics.html#benefits-for-students\n",
      "----------------------------------------\n",
      "Title: Introduction\n",
      "Content: Introduction WEHI is currently reviewing its storage and compute capacity and would like to create models to forecast capacity and create dashboards to demonstrate current usage and help make informed decisions.\n",
      "Topic: capacity planning\n",
      "Keywords: capacity, create, models, reviewing, storage\n",
      "Source: https://wehi-researchcomputing.github.io/student-capacity-planning.html#introduction\n",
      "----------------------------------------\n",
      "Title: Duties while on placement\n",
      "Content: Duties while on placement The Capacity Planning Data Scientist Intern and Capacity Planning Data Engineering Intern role will: identify and integrate historical and current data from many different systems into an interactive dashboard for storage and compute, develop and test models of future growth based on historical data and upcoming trends using appropriate statistical or machine learning models create calculators and other tools to inform the decision making process There is also flexibility with this project to allow the student to inject their own ideas and introduce new features and functionality.\n",
      "Topic: capacity planning\n",
      "Keywords: capacity, data, historical, models, planning\n",
      "Source: https://wehi-researchcomputing.github.io/student-capacity-planning.html#duties-while-on-placement\n",
      "----------------------------------------\n",
      "Title: Skills and Pre-requisites\n",
      "Content: Skills and Pre-requisites Preferred skills: Basic knowledge or willingness to learn, the combining and integrating of data from multiple sources like databases and APIs Ability to learn and understand high-level concepts quickly Ability to work independently and to report to a group and discuss theories and results Good analytical skills Previous experience with, or willingness to learn,  R or Python\n",
      "Topic: capacity planning\n",
      "Keywords: ability, combining, learn, skills, willingness\n",
      "Source: https://wehi-researchcomputing.github.io/student-capacity-planning.html#skills-and-pre-requisites\n",
      "----------------------------------------\n",
      "Title: Benefits for students\n",
      "Content: Benefits for students Benefits for students whilst undertaking the internship include: Each student will get hands on experience in working in a Big Data environment within a highly regarded medical research institute. Practical experience in the maturing stages of a capacity planning project that will be used to help inform high-level decisions. Gain understanding of how real-world information is assessed, developed and how priorities and requirements are established within a research environment. Gain understanding of the importance of maintainable, scalable and extensible code and data. Improving oral and written communication skills in a team environment.\n",
      "Topic: capacity planning\n",
      "Keywords: benefits, data, environment, gain, understanding\n",
      "Source: https://wehi-researchcomputing.github.io/student-capacity-planning.html#benefits-for-students\n",
      "----------------------------------------\n",
      "Title: Introduction\n",
      "Content: Introduction Haemosphere.org is a publicly available database of blood cell gene expression. The haematopoietic research community is a diverse group which contains researchers with various levels of experience in analysing expression data, so we have created this resource to allow easy and fast access to the data for all researchers, and to provide access to the raw data for those who wish to follow up with their own analyses. The main function is that it helps researchers understand which genes are turned on in different blood cell types, by allowing to them to search for their favourite genes, view plots comparing cell types and download data and plots of interest. We would like to improve the use of this site for the research community by improving the user experience and making sure that it is robust and easy to maintain so that it will be available for the community long term.\n",
      "Topic: haemosphere\n",
      "Keywords: cell, community, data, experience, researchers\n",
      "Source: https://wehi-researchcomputing.github.io/student-haemosphere#introduction\n",
      "----------------------------------------\n",
      "Title: Duties while on placement\n",
      "Content: Duties while on placement The Research Software Engineer Intern role will: work closely with researchers to identify their needs around data visualization and analysis Improve the speed of queries to the database Review and improve the maintainability and extensibility of the database Integrate interactive plots to the website There is also a fair amount of flexibility with this project to allow the student to inject their own ideas and introduce new features and functionality.\n",
      "Topic: haemosphere\n",
      "Keywords: allow, database, improve, needs, new\n",
      "Source: https://wehi-researchcomputing.github.io/student-haemosphere#duties-while-on-placement\n",
      "----------------------------------------\n",
      "Title: Skills and Pre-requisites\n",
      "Content: Skills and Pre-requisites Skills and Pre-requisites: Basic knowledge of Python/Javascript/CSS, databases and Linux command-line Ability to learn and understand high-level concepts quickly Ability to work independently and to report to a group and discuss theories and results Good analytical skills Working with git would be an advantage\n",
      "Topic: haemosphere\n",
      "Keywords: ability, pre, requisites, skills, understand\n",
      "Source: https://wehi-researchcomputing.github.io/student-haemosphere#skills-and-pre-requisites\n",
      "----------------------------------------\n",
      "Title: Benefits for students\n",
      "Content: Benefits for students Benefits for students whilst undertaking the internship include: Each student will get hands on experience in working in an emerging research software environment within a highly regarded medical research institute. Gain understanding of how real-world software is assessed, developed and how priorities and requirements are established within a research environment. Gain understanding of the importance of maintainable, scalable and extensible code. Improving oral and written communication skills in a team environment.\n",
      "Topic: haemosphere\n",
      "Keywords: benefits, environment, research, students, understanding\n",
      "Source: https://wehi-researchcomputing.github.io/student-haemosphere#benefits-for-students\n",
      "----------------------------------------\n",
      "Title: Introduction\n",
      "Content: Introduction WEHI is currently developing its Research Data Management requirements and is evaluating products and tools for a hybrid Research Data Management ecosystem. The candidate will develop an understanding of data flow from WEHI microscopes and determine how to automate the processing of microscopy files based off custom scripts provided by the BioImaging team. The key output of the project is to further the current work around making it easier for non-technical people to access High Performance Compute.\n",
      "Topic: imaging\n",
      "Keywords: data, management, microscopes, research, wehi\n",
      "Source: https://wehi-researchcomputing.github.io/student-imaging#introduction\n",
      "----------------------------------------\n",
      "Title: Duties while on placement\n",
      "Content: Duties while on placement The Research Data Engineer Intern role will: review existing semi-automated workflows that are processing of microscopy data, further automate these workflows, including file conversions and transformations of the images, and potentially apply custom imaging processing pipeline to the raw data. There is also flexibility with this project to allow the student to inject their own ideas and introduce new features and functionality.\n",
      "Topic: imaging\n",
      "Keywords: data, introduce, microscopy, processing, workflows\n",
      "Source: https://wehi-researchcomputing.github.io/student-imaging#duties-while-on-placement\n",
      "----------------------------------------\n",
      "Title: Skills and Pre-requisites\n",
      "Content: Skills and Pre-requisites Skills and Pre-requisites: Interest in cutting edge image processing Basic knowledge of Linux command-line Willingness and ability to learn and understand high-level concepts quickly Ability to work independently and to report to a group and discuss theories and results Good analytical skills Previous experience with git would be useful but not necessary\n",
      "Topic: imaging\n",
      "Keywords: ability, pre, requisites, skills, useful\n",
      "Source: https://wehi-researchcomputing.github.io/student-imaging#skills-and-pre-requisites\n",
      "----------------------------------------\n",
      "Title: Benefits for students\n",
      "Content: Benefits for students Benefits for students whilst undertaking the internship include: Working in a High Performance Computing environment or adjacent environment. Practical experience with potential exposure to Bash, Python, C++. Gain understanding of how real-world software is assessed, developed and how priorities and requirements are established within a research environment. Gain understanding of the importance of maintainable, scalable and extensible code. Background information: Imaging Getting Started This video talks about different 3D microscopy modalities. More information but information about hardware can be skipped\n",
      "Topic: imaging\n",
      "Keywords: benefits, environment, information, students, understanding\n",
      "Source: https://wehi-researchcomputing.github.io/student-imaging#benefits-for-students\n",
      "----------------------------------------\n",
      "Title: Introduction\n",
      "Content: Introduction Quantum computers are gaining attention from disciplines outside of physics. We are starting to see algorithms being developed that could be used to solve problems in the future. There are many problems that exist in biology and bioinformatics that could be explored with quantum computing. Structural biology and drug discovery are two such areas that may be able to use quantum computing in the future as quantum computers mature. WEHI is collaborating with the University of Melbourne to create foundational knowledge of quantum computing in biology to ensure that we are prepared for the future. This role is part of that exploration and will help to lay down the foundation of knowledge to allow researchers and research software engineers to accelerate their learning.\n",
      "Topic: quantum\n",
      "Keywords: biology, computing, future, knowledge, quantum\n",
      "Source: https://wehi-researchcomputing.github.io/student-quantum#introduction\n",
      "----------------------------------------\n",
      "Title: Duties while on placement\n",
      "Content: Duties while on placement The Research Data Engineer Intern role will: Generating innovative and beneficial ideas for applying quantum computing to contemporary biological applications, Comprehensive reading and understanding of the latest scholarly work in the relevant field, Identifying knowledge gaps and bridging these, along with periodic presentations reporting on the findings and progress, Work with researchers to understand requirements, Experiment and document how quantum computer simulations can help accelerate learning, Review options for quantum computing in biology, and There is a possibility that experiments on a quantum computer may be done.\n",
      "Topic: quantum\n",
      "Keywords: computer, computing, latest, quantum, work\n",
      "Source: https://wehi-researchcomputing.github.io/student-quantum#duties-while-on-placement\n",
      "----------------------------------------\n",
      "Title: Skills and Pre-requisites:\n",
      "Content: Skills and Pre-requisites: To excel in this internship project, the ideal candidate should have a willingness to research quantum computers, an ability to learn quickly, an enthusiasm for quantum computing, and a willingness to share and communicate information.\n",
      "Topic: quantum\n",
      "Keywords: quantum, requisites, research, share, willingness\n",
      "Source: https://wehi-researchcomputing.github.io/student-quantum#skills-and-pre-requisites\n",
      "----------------------------------------\n",
      "Title: Benefits for students\n",
      "Content: Benefits for students The benefits for students whilst undertaking the internship include: The student will learn Basic awareness and knowledge of quantum computing. Basic awareness and knowledge of the ecosystem that needs to surround quantum computing. Ability to communicate and share complex information to key stakeholders in their language. Experience with researchers and ability to navigate a research environment.\n",
      "Topic: quantum\n",
      "Keywords: ability, computing, knowledge, quantum, students\n",
      "Source: https://wehi-researchcomputing.github.io/student-quantum#benefits-for-students\n",
      "----------------------------------------\n",
      "Title: Further Reading\n",
      "Content: Further Reading Quantum Computing\n",
      "Topic: quantum\n",
      "Keywords: computing, quantum, reading\n",
      "Source: https://wehi-researchcomputing.github.io/student-quantum#further-reading\n",
      "----------------------------------------\n",
      "Title: Introduction\n",
      "Content: Introduction Core sequencing facilities, such as WEHI Genomics, process hundreds of sequencing runs every year. They have to keep track of the how samples are merged (multiplexed) so that they can be uncoupled (demultiplexed) after the sample has been digitised (sequenced) through the sequencing machine. This is a type of metadata. While this allows the sequencing facility to save money by processing samples in bulk, the ability to keep track of these multiplexes is complicated. This is especially significant because there is no resourcing to provide an assistant to be able to check the quality all the metadata at the time of multiplexing. We will propose to do a proof-of-concept to help track multiplexing and other sample transformations as part of the WEHI Genomics facility.\n",
      "Topic: genomics metadata\n",
      "Keywords: metadata, multiplexing, sequencing, track, wehi\n",
      "Source: https://wehi-researchcomputing.github.io/student-genomics-metadata.html#introduction\n",
      "----------------------------------------\n",
      "Title: Duties while on placement\n",
      "Content: Duties while on placement The Research Software Engineer Intern role will: work closely with researchers to identify their needs around genomics metadata multiplexing Review the options available for building a proof-of-concept application based on maintainability and extensibility Implement, build, or trial applications to test fit-for-purpose There is also a fair amount of flexibility with this project to allow the student to inject their own ideas and introduce new features and functionality.\n",
      "Topic: genomics metadata\n",
      "Keywords: allow, introduce, maintainability, metadata, multiplexing\n",
      "Source: https://wehi-researchcomputing.github.io/student-genomics-metadata.html#duties-while-on-placement\n",
      "----------------------------------------\n",
      "Title: Skills and Pre-requisites\n",
      "Content: Skills and Pre-requisites Skills and Pre-requisites: Basic knowledge or ability to learn quickly Java/Javascript/CSS, databases and Linux command-line Ability to learn and understand high-level concepts quickly Ability to work independently and to report to a group and discuss theories and results Good analytical skills Working with git would be an advantage\n",
      "Topic: genomics metadata\n",
      "Keywords: ability, pre, quickly, requisites, skills\n",
      "Source: https://wehi-researchcomputing.github.io/student-genomics-metadata.html#skills-and-pre-requisites\n",
      "----------------------------------------\n",
      "Title: Benefits for students\n",
      "Content: Benefits for students Benefits for students whilst undertaking the internship include: Each student will get hands on experience in working in an emerging research software environment within a highly regarded medical research institute. Gain understanding of how real-world software is assessed, developed and how priorities and requirements are established within a research environment. Gain understanding of the importance of maintainable, scalable and extensible code. Improving oral and written communication skills in a team environment.\n",
      "Topic: genomics metadata\n",
      "Keywords: benefits, environment, research, students, understanding\n",
      "Source: https://wehi-researchcomputing.github.io/student-genomics-metadata.html#benefits-for-students\n",
      "----------------------------------------\n",
      "Title: Further reading\n",
      "Content: Further reading Genomics Metadata Multiplexing\n",
      "Topic: genomics metadata\n",
      "Keywords: genomics, metadata, multiplexing, reading\n",
      "Source: https://wehi-researchcomputing.github.io/student-genomics-metadata.html#further-reading\n",
      "----------------------------------------\n",
      "Title: Introduction\n",
      "Content: Introduction Our cells contain a vast array of interacting organelles (tiny structures within cells that perform specific tasks, similar to the parts of a machine) that determine cellular processes through both health and disease. These structures may be imaged using electron microscopy by bouncing electrons off heavy-metal stained membranes. The resulting images have a resolution of nanometers per voxel (the 3D equivalent of an image pixel) in 3D and each data set may contain millions or billions of voxels per cell. [1] In a paper from 2021 [2] a new method for processing images from the focused ion beam-scanning EM (FIB-SEM) was used to image the cellular ultrastructure of phagophore-ER contacts in three dimensions. As per the paper: FIB-SEM is ideally suited for the acquisition of 3D ultrastructural images from large cellular volumes (Hoffman et al., 2020). However, traditional methods for the reconstruction and analysis of such data require manual image segmentation and classification. The hand-drawn surfaces that are generated during manual segmentation are laborious to produce, low throughput, and subject to human imprecision, making them unsuitable for large-scale morphometric analyses. To overcome these limitations, we developed an approach that delegates the most time-consuming tasks to an artificial intelligence (AI) within a framework that captures the true surface detail of intracellular organelles. Using the machine learning capabilities of Waikato Environment for Knowledge Analysis (WEKA) in combination with ImageJ (Arganda-Carreras et al., 2017; Frank et al., 2004; Schindelin et al., 2012), we trained a random forest computer vision model to faithfully detect all cellular membranes in volumetric FIB-SEM data (Figures 6A and 6B). We have termed this 3D framework AIVE (AI-directed voxel extraction; workflow outlined in Figure S7). The project would involve a series of stages to bring the software infrastructure to a level that will help with development. The initial stage would involve the setup of the workflow along with testing and improving the documentation of the workflow on a local laptop. The potential second stage would be to aim to run the workflow in the WEHI HPC environment known as Milton. The potential third stage would be to add more data to test the workflow to ensure that the test coverage is broader than it is currently. Once this third stage is achieved, there will be an opportunity to work on streamlining the AIVE workflow. References: https://en.wikipedia.org/wiki/Electron_microscope https://www.sciencedirect.com/science/article/pii/S1097276521001696\n",
      "Topic: aive\n",
      "Keywords: 3d, cellular, data, stage, workflow\n",
      "Source: https://wehi-researchcomputing.github.io/student-aive#introduction\n",
      "----------------------------------------\n",
      "Title: Duties while on placement\n",
      "Content: Duties while on placement In this role, you will need to be willing to read and synthesise the original paper with the latest documentation, and work with the Research Software Engineer (RSE) to help streamline all parts of the workflow. The Research Data Engineer Intern role will: review existing semi-automated workflows that are processing FIB-SEM data, test and improve documentation and regression testing for these FIB-SEM data workflows, setup appropriate software development infrastructure to aid in the maintenance and improvement of FIB-SEM workflows, and potentially improve the data workflow with the regression FIB-SEM data available. There is also flexibility with this project to allow the student to inject their own ideas and introduce new features and functionality.\n",
      "Topic: aive\n",
      "Keywords: data, fib, role, sem, workflows\n",
      "Source: https://wehi-researchcomputing.github.io/student-aive#duties-while-on-placement\n",
      "----------------------------------------\n",
      "Title: Skills and Pre-requisites\n",
      "Content: Skills and Pre-requisites Interest in cutting edge image processing and AI Basic knowledge of Linux command-line Willingness and ability to learn and understand high-level concepts quickly Ability to work independently and to report to a group and discuss theories and results Good analytical skills Previous experience with git would be useful but not necessary\n",
      "Topic: aive\n",
      "Keywords: ability, line, linux, necessary, skills\n",
      "Source: https://wehi-researchcomputing.github.io/student-aive#skills-and-pre-requisites\n",
      "----------------------------------------\n",
      "Title: Benefits for students\n",
      "Content: Benefits for students The benefits for students whilst undertaking the internship include: Working in a High Performance Computing environment or adjacent environment. Practical experience with potential exposure to Bash and Java. Gain understanding of how real-world software is assessed, developed and how priorities and requirements are established within a research environment. Gain understanding of the importance of maintainable, scalable and extensible code.\n",
      "Topic: aive\n",
      "Keywords: benefits, environment, gain, students, understanding\n",
      "Source: https://wehi-researchcomputing.github.io/student-aive#benefits-for-students\n",
      "----------------------------------------\n",
      "Title: Further reading\n",
      "Content: Further reading A wiki will be created soon\n",
      "Topic: aive\n",
      "Keywords: created, reading, soon, wiki\n",
      "Source: https://wehi-researchcomputing.github.io/student-aive#further-reading\n",
      "----------------------------------------\n",
      "Title: Introduction\n",
      "Content: Introduction Bioinformatics as a discipline frequently uses many individual software tools, connected in potentially complicated ways, to perform typical analysis. As an example, standard Single Nucleotide Variant (SNV) calling in cancer involves alignment of the sequencing reads to a reference genome, sorting and indexing, variant calling, and subsequent annotation against various databases. Each of these stages comprises of one or more software tools with different input requirements. As a result, reproducibility is difficult to achieve due to the large number of components and the complicated dependency structure inherent in both building the software tools and execution of the workflow. A recently proposed solution to the problem, BioNix[1], leverages the Nix[2] functional package management system to both manage the software and execute the workflow. This has allowed an unprecedented level of reproducibility in the field. In this project, we expose you to Open Source and ask you to become an open source contributor to global open source Nix packages.\n",
      "Topic: bionix\n",
      "Keywords: open, software, source, tools, workflow\n",
      "Source: https://wehi-researchcomputing.github.io/student-bionix#introduction\n",
      "----------------------------------------\n",
      "Title: Duties while on placement\n",
      "Content: Duties while on placement The candidate will be get the opportunity to: Learn about open source norms; Improve the documentation around Nix and BioNix to make it easier and quicker to learn concepts; Wrap underlying bioinformatics software that is required and not currently available in nixpkgs[3] as an open source contributor; Further bonus goals include: writing expressions to execute the tools as individual processing stages; test each stage in isolation to verify functionality and bit-reproducibility; test whole workflows for functionality.\n",
      "Topic: bionix\n",
      "Keywords: functionality, learn, open, source, test\n",
      "Source: https://wehi-researchcomputing.github.io/student-bionix#duties-while-on-placement\n",
      "----------------------------------------\n",
      "Title: Skills and Pre-requisites\n",
      "Content: Skills and Pre-requisites This project would suit a research software engineering candidate who was interested in reproducibility, wants to gain experience with executing bioinformatics workflows efficiently, and enjoys streamlining complex processes. Skills required: knowledge of the use of POSIX systems; understanding of version control systems, experience with git will be helpful; functional programming skills, experience with Nix/NixOS will be helpful.\n",
      "Topic: bionix\n",
      "Keywords: experience, helpful, project, skills, systems\n",
      "Source: https://wehi-researchcomputing.github.io/student-bionix#skills-and-pre-requisites\n",
      "----------------------------------------\n",
      "Title: Benefits for student\n",
      "Content: Benefits for student The benefits for the studnet include: The student will learn the basic awareness and knowledge of data reproducibility. Basic awareness and knowledge of the ecosystem that needs to surround HPC (High Performance Compute). Ability to analyse and identify key knowledge in complex information from key stakeholders. Experience with researchers and ability to navigate a research environment.\n",
      "Topic: bionix\n",
      "Keywords: ability, awareness, basic, knowledge, student\n",
      "Source: https://wehi-researchcomputing.github.io/student-bionix#benefits-for-student\n",
      "----------------------------------------\n",
      "Title: References\n",
      "Content: References BioNix Getting Started https://github.com/PapenfussLab/bionix https://nixos.org/ https://github.com/nixos/nixpkgs https://github.com/WEHI-ResearchComputing/BioNix-qc-pipe https://github.com/WEHI-ResearchComputing/BioNix-Training https://github.com/WEHI-ResearchComputing/BioNix-virusbreakend\n",
      "Topic: bionix\n",
      "Keywords: bionix, com, github, https, researchcomputing\n",
      "Source: https://wehi-researchcomputing.github.io/student-bionix#references\n",
      "----------------------------------------\n",
      "Title: Introduction\n",
      "Content: Introduction WEHI is currently looking at how to take clinical data from databases and create visualisations and dashboards to help administrators and clinicians explore the data.\n",
      "Topic: clinical dashboards\n",
      "Keywords: administrators, clinical, clinicians, create, data\n",
      "Source: https://wehi-researchcomputing.github.io/student-clinical-dashboards#introduction\n",
      "----------------------------------------\n",
      "Title: Duties while on placement\n",
      "Content: Duties while on placement The Research Data Engineer Intern role will: help create or gather synthetic datasets to allow for open collaboration, identify generic and specific visualisations that would help administrators and clinicians explore the data, identify different platforms that could be used to create dashboards and visualisations, and potentially creating exemplar visulisations across more than one platform. There is also flexibility with this project to allow the student to inject their own ideas and introduce new features and functionality.\n",
      "Topic: clinical dashboards\n",
      "Keywords: create, data, help, identify, visualisations\n",
      "Source: https://wehi-researchcomputing.github.io/student-clinical-dashboards#duties-while-on-placement\n",
      "----------------------------------------\n",
      "Title: Skills and Pre-requisites\n",
      "Content: Skills and Pre-requisites Interest in working with clinically-adjacent data Background or willingness to learn visualisation and dashboard tools Willingness and ability to learn and understand high-level concepts quickly Ability to work independently and to report to a group and discuss theories and results Good analytical skills Previous experience with git would be useful but not necessary\n",
      "Topic: clinical dashboards\n",
      "Keywords: ability, learn, skills, visualisation, willingness\n",
      "Source: https://wehi-researchcomputing.github.io/student-clinical-dashboards#skills-and-pre-requisites\n",
      "----------------------------------------\n",
      "Title: Benefits for students\n",
      "Content: Benefits for students Benefits for students whilst undertaking the internship include: Working in a clinical-adjacent environment. Practical experience with potential exposure to Python, R, PowerBI and other visualisation software. Gain understanding of how real-world software is assessed, developed and how priorities and requirements are established within a clinical environment. Gain understanding of the importance of maintainable, scalable and extensible code.\n",
      "Topic: clinical dashboards\n",
      "Keywords: benefits, clinical, environment, students, understanding\n",
      "Source: https://wehi-researchcomputing.github.io/student-clinical-dashboards#benefits-for-students\n",
      "----------------------------------------\n",
      "Title: Further reading\n",
      "Content: Further reading Clinical Informatics Collaborative Github Organisation Clinical Dashboards subproject wiki Extract PDF Background information and project presentations by former students on figshare\n",
      "Topic: clinical dashboards\n",
      "Keywords: background, clinical, project, reading, students\n",
      "Source: https://wehi-researchcomputing.github.io/student-clinical-dashboards#further-reading\n",
      "----------------------------------------\n",
      "Title: How do I know if I am eligible?\n",
      "Content: How do I know if I am eligible? For the enginering students, please contact engit-placements [at] unimelb [dot] edu [dot] au. For the data science and maths students, please contact science-industry-internships[at] unimelb [dot] edu [dot] au.\n",
      "Topic: FAQ\n",
      "Keywords: au, contact, dot, edu, science\n",
      "Source: https://wehi-researchcomputing.github.io/faq#how-do-i-know-if-i-am-eligible\n",
      "----------------------------------------\n",
      "Title: How flexible are the starting dates?\n",
      "Content: How flexible are the starting dates? We are flexible. We aim to keep the same starting dates for everyone to make it easier to put people into the WEHI system, but the actual date you start can be flexible. You could start a week or two later if you need to. We are also flexible if you need to take time off during the internship as well.\n",
      "Topic: FAQ\n",
      "Keywords: dates, flexible, need, start, starting\n",
      "Source: https://wehi-researchcomputing.github.io/faq#how-flexible-are-the-starting-dates\n",
      "----------------------------------------\n",
      "Title: Where are the details I need to fill in my form?\n",
      "Content: Where are the details I need to fill in my form? You can find the information here: These internships are 100% remote. The intake dates and hours per week are here . Supervisor/ Industry Contact details such as the title of the supervisor and phone number should be in the emails sent by your supervisor. An official letter on company letterhead/ An email from the host supervisor with their contact details visible should be the email offer you received from your supervisor.\n",
      "Topic: FAQ\n",
      "Keywords: 100, contact, details, email, supervisor\n",
      "Source: https://wehi-researchcomputing.github.io/faq#where-are-the-details-i-need-to-fill-in-my-form\n",
      "----------------------------------------\n",
      "Title: I know that the internships are usually 100% offsite, but what if I want to go into the office sometimes?\n",
      "Content: I know that the internships are usually 100% offsite, but what if I want to go into the office sometimes? We are open to having some opportunities to go to the office, especially if we can catchup with the other students. It would not be that regular though, but this can be discussed with other students. There are also places to network: There is a monthly onsite lunch with other Research Software Engineers (RSEs) around Parkville . There are also online meetings every month as well. The RSE Asia Australia unconference happens every year in September. This is an online event and we encourage you to attend as there are scholarships available. You can join the RSE Association of Australia and New Zealand via their website. There is a WEHI student symposium usually at the end of the year that we encourage you to attend. This is a link to the 2023 version of the Student Symposium (WEHI access only) . You could proactively reach out to your fellow interns to see if there are others interested in networking.\n",
      "Topic: FAQ\n",
      "Keywords: office, rse, student, students, year\n",
      "Source: https://wehi-researchcomputing.github.io/faq#i-know-that-the-internships-are-usually-100-offsite-but-what-if-i-want-to-go-into-the-office-sometimes\n",
      "----------------------------------------\n",
      "Title: How do I know you won’t get disengaged with the students?\n",
      "Content: How do I know you won’t get disengaged with the students? We are committed to providing guidance, support, and mentorship throughout their internship experience. We recognize the importance of maintaining open lines of communication and being accessible to address their needs. To ensure ongoing engagement, we have weekly check-ins with the student interns to discuss their progress, challenges, and goals. We aim to get them to understand the conceptual parts on these weekly check-ins, so that they can work with the technical side of things at their own pace. There is also a Virtual Computing Drop-in as well as a Thursday  to talk more generally about careers and other skills.\n",
      "Topic: FAQ\n",
      "Keywords: accessible, check, ins, needs, weekly\n",
      "Source: https://wehi-researchcomputing.github.io/faq#how-do-i-know-you-wont-get-disengaged-with-the-students\n",
      "----------------------------------------\n",
      "Title: What is the difference between data engineering, data analysis, and software engineering?\n",
      "Content: What is the difference between data engineering, data analysis, and software engineering? Data engineering is focused on streamlining and cleaning data systematically. Data analysis is focused on cleaning data and analysing it using statistical or machine learning algorithms. Software engineering is focused on systematising analysis or tools that help us make decisions.\n",
      "Topic: FAQ\n",
      "Keywords: analysis, cleaning, data, engineering, focused\n",
      "Source: https://wehi-researchcomputing.github.io/faq#what-is-the-difference-between-data-engineering-data-analysis-and-software-engineering\n",
      "----------------------------------------\n",
      "Title: The Workday email says “On your first day, please arrive at 9.00am unless your manager has advised an alternative time and ask for your manager upon arrival at reception.” - is this accurate?\n",
      "Content: The Workday email says “On your first day, please arrive at 9.00am unless your manager has advised an alternative time and ask for your manager upon arrival at reception.” - is this accurate? No, it is not accurate. This is a 100% remote internship and that part of the Workday email can be safely ignored. On your first day, you will be scheduled some virtual drop-in sessions so you can meet the supervisor and other interns.\n",
      "Topic: FAQ\n",
      "Keywords: accurate, day, email, manager, workday\n",
      "Source: https://wehi-researchcomputing.github.io/faq#the-workday-email-says-on-your-first-day-please-arrive-at-900am-unless-your-manager-has-advised-an-alternative-time-and-ask-for-your-manager-upon-arrival-at-reception---is-this-accurate\n",
      "----------------------------------------\n",
      "Title: I setup my Workday (HR system) through an initial email but now that password doesn’t work or I cannot login to my WEHI email\n",
      "Content: I setup my Workday (HR system) through an initial email but now that password doesn’t work or I cannot login to my WEHI email The links you might have previously used to access Workday before your official start date will no longer allow access.  Email hr [at] wehi [dot] edu [dot] au as this is the contact provided if you encounter any issue in regard to Workday. They will provided you with the new credentials to set up your WEHI email. You may need to go into Incognito mode to get it to work.\n",
      "Topic: FAQ\n",
      "Keywords: email, provided, wehi, work, workday\n",
      "Source: https://wehi-researchcomputing.github.io/faq#i-setup-my-workday-hr-system-through-an-initial-email-but-now-that-password-doesnt-work-or-i-cannot-login-to-my-wehi-email\n",
      "----------------------------------------\n",
      "Title: What courses in Workday do I need to complete?\n",
      "Content: What courses in Workday do I need to complete? These are the key courses you need to do: Law at Work - Privacy for the Private Sector and/or Private Fundamentals at WEHI Law at Work - Sexual Harassment Prevention Law at Work - Workplace Bullying Law at Work - Anti-discrimination and Equal Opportunity Acceptable Workplace Behaviour at WEHI These are the courses you could do if interested: Understanding Risk Management WEHI Child Safe Training Workday basics These are the ones you can ignore as you are 100% remote: Safety Orientation Program - Laboratory Safety Orientation Program - General\n",
      "Topic: FAQ\n",
      "Keywords: courses, law, wehi, work, workplace\n",
      "Source: https://wehi-researchcomputing.github.io/faq#what-courses-in-workday-do-i-need-to-complete\n",
      "----------------------------------------\n",
      "Title: How do I get access to the WEHI-wide student intern group using my WEHI email address?\n",
      "Content: How do I get access to the WEHI-wide student intern group using my WEHI email address? To get access to WEHI-wide student intern group using your WEHI email address. We need to do this as we will be deleting the unimelb email access once everyone has their WEHI email addresses. Go to Teams > go to the teams option > put in the team code - this will be emailed to you on your first day Open it up in Microsoft Teams Client by selecting Open Microsoft Teams Click on Join button in blue It should then say Request Sent Wait for me to approve your access\n",
      "Topic: FAQ\n",
      "Keywords: access, email, teams, using, wehi\n",
      "Source: https://wehi-researchcomputing.github.io/faq#how-do-i-get-access-to-the-wehi-wide-student-intern-group-using-my-wehi-email-address\n",
      "----------------------------------------\n",
      "Title: Given that the internship is remote, am I allowed to complete the internship while on travel?\n",
      "Content: Given that the internship is remote, am I allowed to complete the internship while on travel? Yes, that is correct.\n",
      "Topic: FAQ\n",
      "Keywords: allowed, complete, correct, given, internship\n",
      "Source: https://wehi-researchcomputing.github.io/faq#given-that-the-internship-is-remote-am-i-allowed-to-complete-the-internship-while-on-travel\n",
      "----------------------------------------\n",
      "Title: The description stated that so many hrs per week is expected, but at roughly which times and for how long?\n",
      "Content: The description stated that so many hrs per week is expected, but at roughly which times and for how long? As it is remote, we are very flexible but there are times when we do get together, such as the weekly project meeting. This is explained in the Student Internship Handbook .\n",
      "Topic: FAQ\n",
      "Keywords: description, roughly, stated, student, times\n",
      "Source: https://wehi-researchcomputing.github.io/faq#the-description-stated-that-so-many-hrs-per-week-is-expected-but-at-roughly-which-times-and-for-how-long\n",
      "----------------------------------------\n",
      "Title: I need to use storage and compute. What are my options?\n",
      "Content: I need to use storage and compute. What are my options? We have a few options at WEHI for storage and compute. Some projects have requirements that you can use your own laptop or computer.  For others you can use the following options: If you want to use a High Performance Computer (HPC) to learn more skills, or you have bigger requirements of storage and compute than can fit on your laptop, you can use the Milton HPC To get access to Milton HPC, all WEHI researchers must first submit a request. If you use Milton HPC, you can use the VAST scratch space for your temporary storage . If you want to run a web server or service, then you can use Nectar, the Australian Research Cloud using your WEHI email and password. If you have small data files that your supervisor says is OK to share publicly and you want to share with future students, you can use figshare . If you have small data files that your supervisor says is not OK to share publicly and you want to share with future students, you can use the WEHI-wide student intern group on Sharepoint/Teams. . If you have big data files and you want to share with future students, you can talk to your supervisor about using VAST projects . It would be rare for students to need a VAST project space, so please ask your supervisor first. Research Computing Platform (RCP) also has training courses available for things like Python, Git, Linux, Milton and more . RCP also has a drop-in session that you can go to ask technical questions about high-performance computing (HPC), Slurm usage, cloud computing, general programming, R, Python, package development, code optimisation, data processing, data storage, and data management.\n",
      "Topic: FAQ\n",
      "Keywords: data, hpc, share, use, want\n",
      "Source: https://wehi-researchcomputing.github.io/faq#i-need-to-use-storage-and-compute-what-are-my-options\n",
      "----------------------------------------\n",
      "Title: If I want to use Nectar, what suggestions would you have?\n",
      "Content: If I want to use Nectar, what suggestions would you have? Make sure you use “Any Availability Zone” if you are using Nectar as some of the University of Melbourne hosts are full. It is recommended to use NeCTAR Ubuntu 22.04 LTS (Jammy) amd64 so that students can share documentation between projects and intakes. Make sure you enable 22 SSH access with 0.0.0.0/0 using CIRS. See the Nectar SSH troubleshooting guide . If you want to run a web server, it is recommended to use SSL and therefore you will need to enable 443 HTTPS access with 0.0.0.0/0 using CIRS. See the Nectar SSH troubleshooting guide . If you want to run a flask development server, it is recommended to use SSL and therefore you will need to enable port 5000 access with 0.0.0.0/0 using CIRS. For other non-standard ports you will have to do a similar setup. See the Nectar SSH troubleshooting guide . We should also have a standard to setup a SSL web certificate in the future.\n",
      "Topic: FAQ\n",
      "Keywords: nectar, recommended, ssh, use, using\n",
      "Source: https://wehi-researchcomputing.github.io/faq#if-i-want-to-use-nectar-what-suggestions-would-you-have\n",
      "----------------------------------------\n",
      "Title: Is it OK for me to post on social media?\n",
      "Content: Is it OK for me to post on social media? Yes, but please read the Social Media Policy for student interns .\n",
      "Topic: FAQ\n",
      "Keywords: interns, media, ok, policy, social\n",
      "Source: https://wehi-researchcomputing.github.io/faq#is-it-ok-for-me-to-post-on-social-media\n",
      "----------------------------------------\n",
      "Title: My project is complex and ambiguous - what can I do to deal with this?\n",
      "Content: My project is complex and ambiguous - what can I do to deal with this? All of the projects are complex and ambiguous. This is an explanation on how to deal with a complex and ambiguous project .\n",
      "Topic: FAQ\n",
      "Keywords: ambiguous, complex, deal, explanation, project\n",
      "Source: https://wehi-researchcomputing.github.io/faq#my-project-is-complex-and-ambiguous---what-can-i-do-to-deal-with-this\n",
      "----------------------------------------\n",
      "Title: What is the overall structure of the internship going to look like?\n",
      "Content: What is the overall structure of the internship going to look like? To understand how the overall process of the project please look at the Key milestones and onboarding emails page .\n",
      "Topic: FAQ\n",
      "Keywords: emails, going, internship, look, overall\n",
      "Source: https://wehi-researchcomputing.github.io/faq#what-is-the-overall-structure-of-the-internship-going-to-look-like\n",
      "----------------------------------------\n",
      "Title: You ask us to be as independent as possible. How can we do that?\n",
      "Content: You ask us to be as independent as possible. How can we do that? Rules of thumb for being independent: If you don’t know why at a high level, you won’t be independent. Always take the time to understand high level, so that you can anticipate the client The idea is that you can guess what the client (me) is going to say before I say it And the idea is to ask a question, knowing what the client is going to say, this allows you to test your understanding of the problem If you ask a question, and they say something different, then you need to ask why\n",
      "Topic: FAQ\n",
      "Keywords: ask, client, going, independent, say\n",
      "Source: https://wehi-researchcomputing.github.io/faq#you-ask-us-to-be-as-independent-as-possible-how-can-we-do-that\n",
      "----------------------------------------\n",
      "Title: We are required to interview a number of people to gather insight into their career pathway. How can I arrange this with you?\n",
      "Content: We are required to interview a number of people to gather insight into their career pathway. How can I arrange this with you? You can see more in Ask About Career on page 25 of the RCP Student Onboarding Checklist For those doing the Bachelor of Science or the Master of Data Science course, you will need to ask a series of questions to a supervisor about their career.\n",
      "The questions are as follows: How did you get started in this field, and what do you think has made you successful throughout your career? Are there other ways that people you know entered this field? What are the pros and cons of working in this field? What traits, skills, or experiences do employers in your field look for in candidates? If you were me, what would you do to try to break into this field now? Are there particular publications, professional associations, or events I should explore for additional information on this field? Would you advise me to speak to others about breaking into this field? Can you recommend anyone in particular? There is a video available at Onboarding todo channel > Files > 2021-12-22 Data science internship survey questions. Once you have watched this, if you have further questions, please email me and we can arrange a time to chat about this as a group.\n",
      "Topic: FAQ\n",
      "Keywords: career, field, people, questions, science\n",
      "Source: https://wehi-researchcomputing.github.io/faq#we-are-required-to-interview-a-number-of-people-to-gather-insight-into-their-career-pathway-how-can-i-arrange-this-with-you\n",
      "----------------------------------------\n",
      "Title: We are required to request supervisor signature for the Work Log. How can I arrange this with you?\n",
      "Content: We are required to request supervisor signature for the Work Log. How can I arrange this with you? For those doing the Bachelor of Science or the Master of Data Science course, it is required to complete this supervisor signature work using DocuSign . This ensures that your work log is verified accurately and submitted on time. To arrange this: Sign Up for DocuSign : Use the free 30-day trial of DocuSign. This service allows you to send documents for electronic signature, making the process efficient and convenient for both you and your supervisor. Prepare Your Work Log: Ensure your work log is complete and ready for signature. Send for Signature: Upload your work log to DocuSign, add your supervisor’s email, and send it for their electronic signature. By using DocuSign, you can efficiently obtain your supervisor’s signature and ensure that your work log is ready for submission.\n",
      "Topic: FAQ\n",
      "Keywords: docusign, log, signature, supervisor, work\n",
      "Source: https://wehi-researchcomputing.github.io/faq#we-are-required-to-request-supervisor-signature-for-the-work-log-how-can-i-arrange-this-with-you\n",
      "----------------------------------------\n",
      "Title: What should I put in the public wiki?\n",
      "Content: What should I put in the public wiki? The public wiki is to share information with future students the things you needed to understand at a high level to be able to start working on the technical side of the project. General knowledge to put into the wiki would include (among others): A diagram showing how the high-level parts of the system interact A diagram of how the biology works at a simple level that you need for the project A diagram to show how the overall steps of the workflow and a simple explanation of why each step is done NOTE: Please ensure that anything you put in the public domain is not private. The rule of thumb is that if you found the material on the public internet, you can treat it as public. If you found the material within WEHI or from a WEHI source, you should ask if you can make it public. If you are not sure, please ask your supervisor.\n",
      "Topic: FAQ\n",
      "Keywords: ask, diagram, level, public, wiki\n",
      "Source: https://wehi-researchcomputing.github.io/faq#what-should-i-put-in-the-public-wiki\n",
      "----------------------------------------\n",
      "Title: What should I put in my technical diary?\n",
      "Content: What should I put in my technical diary? Within your project channel in Sharepoint (ie. within the WEHI-wide student intern group in Teams > Files), you should have a Technical notes folder for your intake eg. Semester 2 2023 Technical notes. This is to help future students understand what you did in detail to get your results. This also includes things that should not be made public. So descriptions of where you put data or how you ran a script on Milton should not be made public and should go in Sharepoint. Technical knowledge to put into your technical diary in Sharepoint (among others) would include: commandline commands you used to setup your sofwtware system eg. pip install pandas technical errors you encountered and how you fixed them, or what was the process you found to fix them general technical notes that took you some time to figure out that might help a future student any technical help you received from other students, mentors, or supervisors\n",
      "Topic: FAQ\n",
      "Keywords: future, help, notes, sharepoint, technical\n",
      "Source: https://wehi-researchcomputing.github.io/faq#what-should-i-put-in-my-technical-diary\n",
      "----------------------------------------\n",
      "Title: How should I ask for help to solve a problem?\n",
      "Content: How should I ask for help to solve a problem? There is a way to escalate how to ask for help. This shows you how you can do your proper due diligence before you send your supervsior an email with a question. Before you send that email: Did you search through this FAQ, check the onboarding doc , and the wiki onboarding page via the project pages ? Did you search for a keyword? If it is a broad question, did you do an internet search? Did you ask your project teammates to help you? That is what team mates are for! Did you write down in the email what actions you took in steps #2 and #3 so I know what you have tried? Did you specify exactly what you are having a problem with? ie. “I had trouble with a document” vs “I had trouble accessing ABC.doc in Sharepoint folder X”. Did you cc in your team mates into the email so that they can find out too? Please also make sure you explain the problem in detail, with screenshots and any error messages . These should be saved into your technical diary that should be stored in Sharepoint.\n",
      "Topic: FAQ\n",
      "Keywords: ask, did, email, problem, search\n",
      "Source: https://wehi-researchcomputing.github.io/faq#how-should-i-ask-for-help-to-solve-a-problem\n",
      "----------------------------------------\n",
      "Title: What are the key things to do before the weekly meetings?\n",
      "Content: What are the key things to do before the weekly meetings? Key things to do before for the regular weekly meeting (yes even the first one that is usually in week 2 although it will be mostly empty): Please meet as a team before the meeting without your supervisors to ensure you as a team of students are all on the same page Please send a weekly email update one business day before the meeting (ie. Friday if you have a Monday meeting) with the subject ‘[Project name] week [x] update’ eg. ‘Clinical Dashboards week 3 update’. The email should have: what each student has done, write down any questions you have for the meeting to use as an agenda, provide links to the previous final presentations by previous students, provide a link to the whiteboard session video or image you did (after week 4), provide a summary of the top things you discussed in the whiteboard session (after week 4), provide a link to the wiki and/or the GitHub repository, provide a link to the technical notes in WEHI-wide student intern group in Sharepoint / Files in Teams remember to ask to record the meeting to more easily keep notes if needed, and provide bullet point summary from previous meeting.\n",
      "Topic: FAQ\n",
      "Keywords: link, meeting, provide, things, week\n",
      "Source: https://wehi-researchcomputing.github.io/faq#what-are-the-key-things-to-do-before-the-weekly-meetings\n",
      "----------------------------------------\n",
      "Title: What happens over Christmas / New Year / Easter period?\n",
      "Content: What happens over Christmas / New Year / Easter period? We take a break between Christmas and New Year, as well as the first week of January as well. During the time away there is no need to write and send the weekly update email during the break. We do encourage you to write down questions and what you have done in your technical diary so that you can ask questions when we are back in the second week of January. Remember, we ask you to write up a presentation to say what you think you should do on the project. This helps you become independent. If you do decide to do some work over the holidays, understanding the high level problem will help you make decisions at a technical level without your supervisor’s help. Easter break usually has three public holidays at WEHI Good Friday, Easter Monday and Easter Tuesday. We take a break on those days. You can confirm the breaks via the Public and WEHI holidays on Catalyst .\n",
      "Topic: FAQ\n",
      "Keywords: ask, break, easter, holidays, write\n",
      "Source: https://wehi-researchcomputing.github.io/faq#what-happens-over-christmas--new-year--easter-period\n",
      "----------------------------------------\n",
      "Title: What do I need to do for my final presentation and summary report?\n",
      "Content: What do I need to do for my final presentation and summary report? The final presentation and summary report are due on the last week of the internship. They are usually done at the same time as the regular weekly project meeting. It is important to provide an early draft and a late draft to your supervisors for both the final presentation and the summary report. The early draft is to make sure you are on the right track, and the late draft is to polish things. Please put them into Teams Files / Sharepoint so that they can be commented on directly by your supervisors. We create a single document for all summary reports to be filed together. You will be sent a link to this document when it is ready. The one page project summary audience is for myself and potential researchers who want to understand what you have done from a high level point of view, but can easily click on links to get to the technical detail / reports / visualisations. The one page summary should be handed in before the presentation or before the internship finishes. For your final presentation – please make sure you have an acknowledgement slide and show the slides to your supervisor before your final presentation. A good example of a set of slides is here. The audience for the presentation is for future students and for researchers who might be interested in understanding what you have done from a high level point of view, but can easily look at the wiki to find out more. Maximum time for the presentation is 15 to 20 minutes.\n",
      "Topic: FAQ\n",
      "Keywords: draft, final, presentation, report, summary\n",
      "Source: https://wehi-researchcomputing.github.io/faq#what-do-i-need-to-do-for-my-final-presentation-and-summary-report\n",
      "----------------------------------------\n",
      "Title: Semester 1 2025 now available\n",
      "Content: Semester 1 2025 now available Engineering and IT : start and end dates are from 17th February to 24th of May for around 24 hours per week. Faculty of Science : start and end dates are from 17th February to 24th of May for around 8 hours per week. Final Presentations are yet to be determined. Practice presentations will be done the week before final presentations.\n",
      "Topic: Intake Date\n",
      "Keywords: february, final, hours, presentations, week\n",
      "Source: https://wehi-researchcomputing.github.io/intake_dates#semester-1-2025-now-available\n",
      "----------------------------------------\n",
      "Title: Summer 2024/2025\n",
      "Content: Summer 2024/2025 Engineering and IT : start and end dates are from 25 November to 21 February for around 24 hours per week. Faculty of Science : start and end dates are from 25 November to 21 February for around 8 hours per week. Final Presentations are due week of the 17th of February for all students. Practice presentations will be done the week of the 10th February.\n",
      "Topic: Intake Date\n",
      "Keywords: 21, february, presentations, start, week\n",
      "Source: https://wehi-researchcomputing.github.io/intake_dates#summer-20242025\n",
      "----------------------------------------\n",
      "Title: Semester 2 2024 current\n",
      "Content: Semester 2 2024 current Engineering and IT : start and end dates are from the 22nd July to 23rd October for 24 hours per week. Faculty of Science : start and end dates are from the 22nd July to 11th October for 8 hours per week. Final Presentations are due week of the 7th of October for all students. Practice presentations will be done the week of the 30th September.\n",
      "Topic: Intake Date\n",
      "Keywords: 22nd, october, presentations, start, week\n",
      "Source: https://wehi-researchcomputing.github.io/intake_dates#semester-2-2024-current\n",
      "----------------------------------------\n",
      "Title: Semester 1 2024 intake finalised\n",
      "Content: Semester 1 2024 intake finalised Engineering and IT : start and end dates are from the 26th of February to 31st of May for 24 hours per week. Faculty of Science : start and end dates are from the 26th of February to 17th of May or 31st of May for 8 hours per week. Final Presentations are due week of the 13th of May for all students. Practice presentations will be done the week before.\n",
      "Topic: Intake Date\n",
      "Keywords: end, hours, presentations, start, week\n",
      "Source: https://wehi-researchcomputing.github.io/intake_dates#semester-1-2024-intake-finalised\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from rake_nltk import Rake\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Function to extract text from a PDF\n",
    "def extract_text_from_pdf(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "# Function to generate keywords using TF-IDF\n",
    "def generate_keywords_tfidf(content, top_n=5):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_features=top_n)\n",
    "    X = vectorizer.fit_transform([content])\n",
    "    keywords = vectorizer.get_feature_names_out()\n",
    "    return list(keywords)\n",
    "\n",
    "# Function to scrape a web page\n",
    "def scrape_web_page(url, topic=\"General\"):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch page: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    documents = []\n",
    "\n",
    "    # Find all <h2> tags\n",
    "    titles = soup.find_all('h2')  # Adjust this tag based on the page structure\n",
    "    for title in titles:\n",
    "        question = title.text.strip()\n",
    "        content = question + \" \"  # Initialize content with the question text\n",
    "        sibling = title.find_next_sibling()\n",
    "\n",
    "        # Collect content until the next <h2> or the end of the section\n",
    "        while sibling and sibling.name != 'h2':\n",
    "            if sibling.name in ['p', 'ul', 'ol', 'div']:  # Include other relevant tags as needed\n",
    "                content += sibling.get_text(separator=\" \", strip=True) + \" \"\n",
    "            sibling = sibling.find_next_sibling()\n",
    "\n",
    "        # Generate a relevant part of the URL as the source\n",
    "        section_id = title.get('id')  # Extract the 'id' attribute if available\n",
    "        if section_id:\n",
    "            section_url = f\"{url}#{section_id}\"  # Append the ID as a fragment\n",
    "        else:\n",
    "            section_url = url  # Use the main URL if no ID is found\n",
    "\n",
    "        # Generate keywords using TF-IDF\n",
    "        keywords = generate_keywords_tfidf(content)\n",
    "\n",
    "        documents.append({\n",
    "            \"title\": question,\n",
    "            \"content\": content.strip(),\n",
    "            \"topic\": topic,\n",
    "            \"keywords\": keywords,\n",
    "            \"source\": section_url  # Use the section URL for this title\n",
    "        })\n",
    "\n",
    "    return documents\n",
    "\n",
    "\n",
    "# Extract text from PDFs\n",
    "pdf_paths = [\n",
    "    \"C:/Users/omidm/Downloads/RCP#0032 Intake 10 Student Internship Summary reports (share with all).pdf\",\n",
    "    \"C:/Users/omidm/Downloads/Research Computing Platform Student Internship Handbook.pdf\",\n",
    "    \"C:/Users/omidm/Downloads/RCP0026 Welcome Students Semeter 2 Intake 10.pdf\"\n",
    "]\n",
    "pdf_data = []\n",
    "\n",
    "for pdf_path in pdf_paths:\n",
    "    pdf_text = extract_text_from_pdf(pdf_path)\n",
    "    pdf_keywords = generate_keywords_tfidf(pdf_text)\n",
    "    \n",
    "    # Extract the file name (without extension) from the file path\n",
    "    file_name = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "    \n",
    "    pdf_data.append({\n",
    "        \"title\": f\"Content from {file_name}\",\n",
    "        \"content\": pdf_text,\n",
    "        \"topic\": file_name,  # Use the file name as the topic\n",
    "        \"keywords\": pdf_keywords,\n",
    "        \"source\": None  # Do not save any source for PDFs\n",
    "    })\n",
    "\n",
    "\n",
    "# Scrape web pages\n",
    "links = [\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/students\", \"topic\": \"Unpaid Student Internship Program\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/complex-projects\", \"topic\": \"complex ambiguous projects\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/software_maturity_model\", \"topic\": \"software maturity model\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/explanation_about_ohs\", \"topic\": \"explanation about ohs\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/top-5-mistakes\", \"topic\": \"top 5 mistakes\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/project-wikis\", \"topic\": \"project wikis\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-loxcoder\", \"topic\": \"loxcoder\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-data-commons\", \"topic\": \"student data commons\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-cryoem\", \"topic\": \"cryoem\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-genomics-qc\", \"topic\": \"genomics quantum computing\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-schex\", \"topic\": \"schex\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-mixOmics.html\", \"topic\": \"mixOmics\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-capacity-planning.html\", \"topic\": \"capacity planning\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-haemosphere\", \"topic\": \"haemosphere\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-imaging\", \"topic\": \"imaging\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-quantum\", \"topic\": \"quantum\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-genomics-metadata.html\", \"topic\": \"genomics metadata\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-aive\", \"topic\": \"aive\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-bionix\", \"topic\": \"bionix\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-clinical-dashboards\", \"topic\": \"clinical dashboards\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/email_acknowledgement\", \"topic\": \"email acknowledgement\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/code-of-conduct\", \"topic\": \"code of conduct\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/faq\", \"topic\": \"FAQ\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/intake_dates\", \"topic\": \"Intake Date\"}     \n",
    "\n",
    "\n",
    "]\n",
    "web_data = []\n",
    "for link in links:\n",
    "    data = scrape_web_page(link[\"url\"], topic=link[\"topic\"])\n",
    "    if data:\n",
    "        web_data.extend(data)\n",
    "\n",
    "# Combine PDF data and web-scraped data\n",
    "all_data = pdf_data + web_data\n",
    "\n",
    "# Print and save the aggregated data\n",
    "for doc in all_data:\n",
    "    print(f\"Title: {doc['title']}\")\n",
    "    print(f\"Content: {doc['content']}\")  # Truncate for readability\n",
    "    print(f\"Topic: {doc['topic']}\")\n",
    "    print(f\"Keywords: {', '.join(doc['keywords'])}\")\n",
    "    print(f\"Source: {doc['source']}\")  # Print source if available\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "with open(\"aggregated_data.json\", \"w\") as f:\n",
    "    json.dump(all_data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c8b84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from rake_nltk import Rake\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Function to extract text from a PDF\n",
    "def extract_text_from_pdf(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "# Function to generate keywords using TF-IDF\n",
    "def generate_keywords_tfidf(content, top_n=5):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_features=top_n)\n",
    "    X = vectorizer.fit_transform([content])\n",
    "    keywords = vectorizer.get_feature_names_out()\n",
    "    return list(keywords)\n",
    "\n",
    "def scrape_web_page(url, topic=\"General\"):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch page: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    documents = []\n",
    "\n",
    "    # Find all <h2> tags\n",
    "    titles = soup.find_all('h2')  # Adjust this tag based on the page structure\n",
    "    for title in titles:\n",
    "        question = title.text.strip()\n",
    "        content = question + \" \"  # Initialize content with the question text\n",
    "        sibling = title.find_next_sibling()\n",
    "\n",
    "        # Collect content until the next <h2> or the end of the section\n",
    "        while sibling and sibling.name != 'h2':\n",
    "            if sibling.name in ['p', 'ul', 'ol', 'div']:  # Include other relevant tags as needed\n",
    "                content += sibling.get_text(separator=\" \", strip=True) + \" \"\n",
    "                \n",
    "                # Extract links from anchor tags within this section\n",
    "                for link in sibling.find_all('a'):\n",
    "                    link_text = link.get_text(strip=True)\n",
    "                    link_url = link['href']\n",
    "                    content += f\" [{link_text}]({link_url}) \"  # Add links to content\n",
    "\n",
    "            sibling = sibling.find_next_sibling()\n",
    "\n",
    "        # Generate a relevant part of the URL as the source\n",
    "        section_id = title.get('id')  # Extract the 'id' attribute if available\n",
    "        if section_id:\n",
    "            section_url = f\"{url}#{section_id}\"  # Append the ID as a fragment\n",
    "        else:\n",
    "            section_url = url  # Use the main URL if no ID is found\n",
    "\n",
    "        # Generate keywords using TF-IDF\n",
    "        keywords = generate_keywords_tfidf(content)\n",
    "\n",
    "        documents.append({\n",
    "            \"title\": question,\n",
    "            \"content\": content.strip(),\n",
    "            \"topic\": topic,\n",
    "            \"keywords\": keywords,\n",
    "            \"source\": section_url  # Use the section URL for this title\n",
    "        })\n",
    "\n",
    "    return documents\n",
    "\n",
    "# Extract text from PDFs\n",
    "pdf_paths = [\n",
    "    \"C:/Users/omidm/Downloads/RCP#0032 Intake 10 Student Internship Summary reports (share with all).pdf\",\n",
    "    \"C:/Users/omidm/Downloads/Research Computing Platform Student Internship Handbook.pdf\",\n",
    "    \"C:/Users/omidm/Downloads/RCP0026 Welcome Students Semeter 2 Intake 10.pdf\"\n",
    "]\n",
    "pdf_data = []\n",
    "\n",
    "for pdf_path in pdf_paths:\n",
    "    pdf_text = extract_text_from_pdf(pdf_path)\n",
    "    pdf_keywords = generate_keywords_tfidf(pdf_text)\n",
    "    \n",
    "    # Extract the file name (without extension) from the file path\n",
    "    file_name = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "    \n",
    "    pdf_data.append({\n",
    "        \"title\": f\"Content from {file_name}\",\n",
    "        \"content\": pdf_text,\n",
    "        \"topic\": file_name,  # Use the file name as the topic\n",
    "        \"keywords\": pdf_keywords,\n",
    "        \"source\": None  # Do not save any source for PDFs\n",
    "    })\n",
    "\n",
    "\n",
    "# Scrape web pages\n",
    "links = [\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/students\", \"topic\": \"Unpaid Student Internship Program\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/complex-projects\", \"topic\": \"complex ambiguous projects\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/software_maturity_model\", \"topic\": \"software maturity model\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/explanation_about_ohs\", \"topic\": \"explanation about ohs\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/top-5-mistakes\", \"topic\": \"top 5 mistakes\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/project-wikis\", \"topic\": \"project wikis\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-loxcoder\", \"topic\": \"loxcoder\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-data-commons\", \"topic\": \"student data commons\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-cryoem\", \"topic\": \"cryoem\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-genomics-qc\", \"topic\": \"genomics quantum computing\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-schex\", \"topic\": \"schex\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-mixOmics.html\", \"topic\": \"mixOmics\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-capacity-planning.html\", \"topic\": \"capacity planning\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-haemosphere\", \"topic\": \"haemosphere\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-imaging\", \"topic\": \"imaging\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-quantum\", \"topic\": \"quantum\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-genomics-metadata.html\", \"topic\": \"genomics metadata\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-aive\", \"topic\": \"aive\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-bionix\", \"topic\": \"bionix\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-clinical-dashboards\", \"topic\": \"clinical dashboards\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/email_acknowledgement\", \"topic\": \"email acknowledgement\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/code-of-conduct\", \"topic\": \"code of conduct\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/faq\", \"topic\": \"FAQ\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/intake_dates\", \"topic\": \"Intake Date\"}     \n",
    "\n",
    "\n",
    "]\n",
    "web_data = []\n",
    "for link in links:\n",
    "    data = scrape_web_page(link[\"url\"], topic=link[\"topic\"])\n",
    "    if data:\n",
    "        web_data.extend(data)\n",
    "\n",
    "# Combine PDF data and web-scraped data\n",
    "all_data = pdf_data + web_data\n",
    "\n",
    "# Print and save the aggregated data\n",
    "for doc in all_data:\n",
    "    print(f\"Title: {doc['title']}\")\n",
    "    print(f\"Content: {doc['content']}\")  # Truncate for readability\n",
    "    print(f\"Topic: {doc['topic']}\")\n",
    "    print(f\"Keywords: {', '.join(doc['keywords'])}\")\n",
    "    print(f\"Source: {doc['source']}\")  # Print source if available\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "with open(\"aggregated_data.json\", \"w\") as f:\n",
    "    json.dump(all_data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d955a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [31/Jan/2025 11:33:46] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [31/Jan/2025 11:34:12] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [31/Jan/2025 11:34:36] \"POST /ask HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [31/Jan/2025 11:35:44] \"POST /ask HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [31/Jan/2025 11:36:14] \"POST /ask HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [31/Jan/2025 11:36:43] \"POST /ask HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [31/Jan/2025 11:38:17] \"POST /ask HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [31/Jan/2025 11:40:25] \"POST /ask HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [31/Jan/2025 11:42:06] \"POST /ask HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [31/Jan/2025 11:43:00] \"POST /ask HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, render_template_string\n",
    "import google.generativeai as genai\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "import os\n",
    "\n",
    "# HTML template as a string\n",
    "HTML_TEMPLATE = '''\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Question Answering System</title>\n",
    "    <style>\n",
    "        body {\n",
    "            font-family: Arial, sans-serif;\n",
    "            max-width: 800px;\n",
    "            margin: 0 auto;\n",
    "            padding: 20px;\n",
    "        }\n",
    "        .container {\n",
    "            margin-top: 20px;\n",
    "        }\n",
    "        #question {\n",
    "            width: 100%;\n",
    "            padding: 10px;\n",
    "            margin-bottom: 10px;\n",
    "        }\n",
    "        #response {\n",
    "            margin-top: 20px;\n",
    "            white-space: pre-wrap;\n",
    "        }\n",
    "        .sources {\n",
    "            margin-top: 10px;\n",
    "            font-size: 0.9em;\n",
    "        }\n",
    "        .content-link {\n",
    "            color: blue; /* Set text color to blue */\n",
    "            text-decoration: underline; /* Underline for links */\n",
    "            cursor: pointer; /* Change cursor to pointer for links */\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Ask a Question</h1>\n",
    "    <div class=\"container\">\n",
    "        <textarea id=\"question\" rows=\"4\" placeholder=\"Enter your question here...\"></textarea>\n",
    "        <button onclick=\"askQuestion()\">Submit</button>\n",
    "        <div id=\"response\"></div>\n",
    "        <div id=\"sources\" class=\"sources\"></div>\n",
    "    </div>\n",
    "\n",
    "    <script>\n",
    "        async function askQuestion() {\n",
    "            const question = document.getElementById('question').value;\n",
    "            const responseDiv = document.getElementById('response');\n",
    "            const sourcesDiv = document.getElementById('sources');\n",
    "            \n",
    "            responseDiv.innerHTML = 'Loading...';\n",
    "            sourcesDiv.innerHTML = '';\n",
    "\n",
    "            try {\n",
    "                const response = await fetch('/ask', {\n",
    "                    method: 'POST',\n",
    "                    headers: {\n",
    "                        'Content-Type': 'application/json',\n",
    "                    },\n",
    "                    body: JSON.stringify({ question: question }),\n",
    "                });\n",
    "\n",
    "                const data = await response.json();\n",
    "                responseDiv.innerHTML = data.answer;\n",
    "                \n",
    "                if (data.sources && data.sources.length > 0) {\n",
    "                    sourcesDiv.innerHTML = '<h3>Sources:</h3>' + \n",
    "                        data.sources.map(source => \n",
    "                            `<p><a href=\"${source.url}\" target=\"_blank\" class=\"content-link\">${source.title}</a></p>`\n",
    "                        ).join('');\n",
    "                }\n",
    "            } catch (error) {\n",
    "                responseDiv.innerHTML = 'Error: ' + error.message;\n",
    "            }\n",
    "        }\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "# Configure Gemini directly with API key\n",
    "genai.configure(api_key=\"\")\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "try:\n",
    "    # Load the data\n",
    "    with open('aggregated_data.json', 'r', encoding='utf-8') as f:\n",
    "        knowledge_base = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\"aggregated_data.json not found. Please make sure it exists in the same directory as app.py\")\n",
    "\n",
    "# Prepare documents for TF-IDF\n",
    "documents = [doc['content'] for doc in knowledge_base]\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "def get_relevant_documents(query, top_k=3):\n",
    "    # Transform the query\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    \n",
    "    # Calculate similarity\n",
    "    similarities = cosine_similarity(query_vector, tfidf_matrix)[0]\n",
    "    \n",
    "    # Get top k most similar documents\n",
    "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
    "    \n",
    "    relevant_docs = []\n",
    "    for idx in top_indices:\n",
    "        doc = knowledge_base[idx]\n",
    "        relevant_docs.append({\n",
    "            'content': doc['content'],\n",
    "            'source': doc['source'],\n",
    "            'title': doc['title']\n",
    "        })\n",
    "    \n",
    "    return relevant_docs\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template_string(HTML_TEMPLATE)\n",
    "\n",
    "@app.route('/ask', methods=['POST'])\n",
    "def ask():\n",
    "    try:\n",
    "        data = request.json\n",
    "        question = data['question']\n",
    "        \n",
    "        # Get relevant documents\n",
    "        relevant_docs = get_relevant_documents(question)\n",
    "        \n",
    "        # Prepare context for Gemini\n",
    "        context = \"Based on the following information:\\n\\n\"\n",
    "        for doc in relevant_docs:\n",
    "            # Format content to include clickable links\n",
    "            content_with_links = doc['content'].replace(\"http\", \"<a href='http\").replace(\" \", \"' target='_blank'> </a>\")\n",
    "            context += f\"<div class='content-link'>{content_with_links}</div>\\n\\n\"\n",
    "        \n",
    "        prompt = f\"\"\"{context}\n",
    "        \n",
    "        Question: {question}\n",
    "        \n",
    "        Please provide a clear and concise answer based only on the information provided above. \n",
    "        If the information is not sufficient to answer the question, please say so.\"\"\"\n",
    "        \n",
    "        # Generate response using Gemini\n",
    "        response = model.generate_content(prompt)\n",
    "        \n",
    "        # Prepare sources information\n",
    "        sources = []\n",
    "        for doc in relevant_docs:\n",
    "            if doc['source']:  # Only include if source URL exists\n",
    "                sources.append({\n",
    "                    'url': doc['source'],\n",
    "                    'title': doc['title']\n",
    "                })\n",
    "        \n",
    "        return jsonify({\n",
    "            'answer': response.text,\n",
    "            'sources': sources\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, use_reloader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a4a1c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [30/Jan/2025 12:34:32] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Jan/2025 12:34:44] \"POST /ask HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Jan/2025 12:35:02] \"POST /ask HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, render_template_string\n",
    "import google.generativeai as genai\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "import os\n",
    "\n",
    "# HTML template as a string\n",
    "HTML_TEMPLATE = '''\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Question Answering System</title>\n",
    "    <style>\n",
    "        body {\n",
    "            font-family: Arial, sans-serif;\n",
    "            max-width: 800px;\n",
    "            margin: 0 auto;\n",
    "            padding: 20px;\n",
    "        }\n",
    "        .container {\n",
    "            margin-top: 20px;\n",
    "        }\n",
    "        #question {\n",
    "            width: 100%;\n",
    "            padding: 10px;\n",
    "            margin-bottom: 10px;\n",
    "        }\n",
    "        #response {\n",
    "            margin-top: 20px;\n",
    "            white-space: pre-wrap;\n",
    "        }\n",
    "        .sources {\n",
    "            margin-top: 10px;\n",
    "            font-size: 0.9em;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Ask a Question</h1>\n",
    "    <div class=\"container\">\n",
    "        <textarea id=\"question\" rows=\"4\" placeholder=\"Enter your question here...\"></textarea>\n",
    "        <button onclick=\"askQuestion()\">Submit</button>\n",
    "        <div id=\"response\"></div>\n",
    "        <div id=\"sources\" class=\"sources\"></div>\n",
    "    </div>\n",
    "\n",
    "    <script>\n",
    "        async function askQuestion() {\n",
    "            const question = document.getElementById('question').value;\n",
    "            const responseDiv = document.getElementById('response');\n",
    "            const sourcesDiv = document.getElementById('sources');\n",
    "            \n",
    "            responseDiv.innerHTML = 'Loading...';\n",
    "            sourcesDiv.innerHTML = '';\n",
    "\n",
    "            try {\n",
    "                const response = await fetch('/ask', {\n",
    "                    method: 'POST',\n",
    "                    headers: {\n",
    "                        'Content-Type': 'application/json',\n",
    "                    },\n",
    "                    body: JSON.stringify({ question: question }),\n",
    "                });\n",
    "\n",
    "                const data = await response.json();\n",
    "                responseDiv.innerHTML = data.answer;\n",
    "                \n",
    "                if (data.sources && data.sources.length > 0) {\n",
    "                    sourcesDiv.innerHTML = '<h3>Sources:</h3>' + \n",
    "                        data.sources.map(source => \n",
    "                            `<p><a href=\"${source.url}\" target=\"_blank\">${source.title}</a></p>`\n",
    "                        ).join('');\n",
    "                }\n",
    "            } catch (error) {\n",
    "                responseDiv.innerHTML = 'Error: ' + error.message;\n",
    "            }\n",
    "        }\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "# Configure Gemini directly with API key\n",
    "genai.configure(api_key=\"\")\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "try:\n",
    "    # Load the data\n",
    "    with open('aggregated_data.json', 'r', encoding='utf-8') as f:\n",
    "        knowledge_base = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\"aggregated_data.json not found. Please make sure it exists in the same directory as app.py\")\n",
    "\n",
    "# Prepare documents for TF-IDF\n",
    "documents = [doc['content'] for doc in knowledge_base]\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "def get_relevant_documents(query, top_k=3):\n",
    "    # Transform the query\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    \n",
    "    # Calculate similarity\n",
    "    similarities = cosine_similarity(query_vector, tfidf_matrix)[0]\n",
    "    \n",
    "    # Get top k most similar documents\n",
    "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
    "    \n",
    "    relevant_docs = []\n",
    "    for idx in top_indices:\n",
    "        doc = knowledge_base[idx]\n",
    "        relevant_docs.append({\n",
    "            'content': doc['content'],\n",
    "            'source': doc['source'],\n",
    "            'title': doc['title']\n",
    "        })\n",
    "    \n",
    "    return relevant_docs\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template_string(HTML_TEMPLATE)\n",
    "\n",
    "@app.route('/ask', methods=['POST'])\n",
    "def ask():\n",
    "    try:\n",
    "        data = request.json\n",
    "        question = data['question']\n",
    "        \n",
    "        # Get relevant documents\n",
    "        relevant_docs = get_relevant_documents(question)\n",
    "        \n",
    "        # Prepare context for Gemini\n",
    "        context = \"Based on the following information:\\n\\n\"\n",
    "        for doc in relevant_docs:\n",
    "            context += f\"Document: {doc['content']}\\n\\n\"\n",
    "        \n",
    "        prompt = f\"\"\"{context}\n",
    "        \n",
    "        Question: {question}\n",
    "        \n",
    "        Please provide a clear and concise answer based only on the information provided above. \n",
    "        If the information is not sufficient to answer the question, please say so.\"\"\"\n",
    "        \n",
    "        # Generate response using Gemini\n",
    "        response = model.generate_content(prompt)\n",
    "        \n",
    "        # Prepare sources information\n",
    "        sources = []\n",
    "        for doc in relevant_docs:\n",
    "            if doc['source']:  # Only include if source URL exists\n",
    "                sources.append({\n",
    "                    'url': doc['source'],\n",
    "                    'title': doc['title']\n",
    "                })\n",
    "        \n",
    "        return jsonify({\n",
    "            'answer': response.text,\n",
    "            'sources': sources\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, use_reloader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a02d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "############Improved Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198737ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1e831e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from flask import Flask\n",
    "import google.generativeai as genai\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "\n",
    "# Configure Gemini with API key\n",
    "genai.configure(api_key=\"\")\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "# Flask app for other purposes if needed\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load knowledge base\n",
    "with open('aggregated_data.json', 'r', encoding='utf-8') as f:\n",
    "    knowledge_base = json.load(f)\n",
    "\n",
    "# Prepare documents for TF-IDF\n",
    "documents = [doc['content'] for doc in knowledge_base]\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "def get_relevant_documents(query, top_k=3):\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    similarities = cosine_similarity(query_vector, tfidf_matrix)[0]\n",
    "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
    "    relevant_docs = [knowledge_base[idx] for idx in top_indices]\n",
    "    return relevant_docs\n",
    "\n",
    "def answer_question(question):\n",
    "    # Get relevant documents\n",
    "    relevant_docs = get_relevant_documents(question)\n",
    "    \n",
    "    # Prepare context for Gemini\n",
    "    context = \"Based on the following information:\\n\\n\"\n",
    "    for doc in relevant_docs:\n",
    "        context += f\"Document: {doc['content']}\\n\\n\"\n",
    "    \n",
    "    prompt = f\"\"\"{context}\n",
    "    \n",
    "    Question: {question}\n",
    "    \n",
    "    Please provide a clear and concise answer based only on the information provided above. \n",
    "    If the information is not sufficient to answer the question, please say so.\"\"\"\n",
    "    \n",
    "    # Generate response using Gemini\n",
    "    response = model.generate_content(prompt)\n",
    "    \n",
    "    # Format sources\n",
    "    sources = [\n",
    "        f\"{doc['title']}: {doc['source']}\" \n",
    "        for doc in relevant_docs if 'source' in doc and doc['source']\n",
    "    ]\n",
    "    \n",
    "    return response.text, \"\\n\".join(sources)\n",
    "\n",
    "# Define the Gradio interface\n",
    "def gradio_interface(question):\n",
    "    answer, sources = answer_question(question)\n",
    "    return answer, sources\n",
    "\n",
    "# Create Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=gradio_interface,\n",
    "    inputs=gr.Textbox(label=\"Enter your question\"),\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"Answer\"),\n",
    "        gr.Textbox(label=\"Sources\"),\n",
    "    ],\n",
    "    title=\"Question Answering System\",\n",
    "    description=\"Ask a question, and get answers with references to relevant documents.\"\n",
    ")\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    iface.launch(server_name=\"0.0.0.0\", server_port=7860)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa273ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://38aca9a2014da9a821.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://38aca9a2014da9a821.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* Running on public URL: https://0d453080f2f480e0d1.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://0d453080f2f480e0d1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from flask import Flask, request, jsonify\n",
    "import google.generativeai as genai\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "\n",
    "# Configure Gemini directly with API key\n",
    "genai.configure(api_key=\"\")\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "# Load the data\n",
    "try:\n",
    "    with open('aggregated_data.json', 'r', encoding='utf-8') as f:\n",
    "        knowledge_base = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\"aggregated_data.json not found. Please make sure it exists in the same directory as this script\")\n",
    "\n",
    "# Prepare documents for TF-IDF\n",
    "documents = [doc['content'] for doc in knowledge_base]\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "def get_relevant_documents(query, top_k=3):\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    similarities = cosine_similarity(query_vector, tfidf_matrix)[0]\n",
    "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
    "    relevant_docs = [{'content': knowledge_base[idx]['content'], \n",
    "                      'source': knowledge_base[idx].get('source'), \n",
    "                      'title': knowledge_base[idx].get('title')} \n",
    "                     for idx in top_indices]\n",
    "    return relevant_docs\n",
    "\n",
    "def ask_question(question):\n",
    "    try:\n",
    "        relevant_docs = get_relevant_documents(question)\n",
    "        \n",
    "        context = \"Based on the following information:\\n\\n\"\n",
    "        for doc in relevant_docs:\n",
    "            context += f\"Document: {doc['content']}\\n\\n\"\n",
    "        \n",
    "        prompt = f\"\"\"{context}\n",
    "        \n",
    "        Question: {question}\n",
    "        \n",
    "        Please provide a clear and concise answer based only on the information provided above. \n",
    "        If the information is not sufficient to answer the question, please say so.\"\"\"\n",
    "        \n",
    "        response = model.generate_content(prompt)\n",
    "        \n",
    "        sources = [{'url': doc['source'], 'title': doc['title']} \n",
    "                   for doc in relevant_docs if doc.get('source')]\n",
    "        \n",
    "        return response.text, sources\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\", []\n",
    "\n",
    "# Gradio interface\n",
    "def gradio_interface(question):\n",
    "    answer, sources = ask_question(question)\n",
    "    sources_html = \"<br>\".join([f\"<a href='{src['url']}' target='_blank'>{src['title']}</a>\" for src in sources])\n",
    "    return answer, sources_html\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=gradio_interface,\n",
    "    inputs=gr.Textbox(lines=4, placeholder=\"Enter your question here...\"),\n",
    "    outputs=[gr.Textbox(label=\"Answer\"), gr.HTML(label=\"Sources\")],\n",
    "    live=True\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    interface.launch(share=True)\n",
    "import gradio as gr\n",
    "from flask import Flask, request, jsonify\n",
    "import google.generativeai as genai\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "\n",
    "# Configure Gemini directly with API key\n",
    "genai.configure(api_key=\"\")\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "# Load the data\n",
    "try:\n",
    "    with open('aggregated_data.json', 'r', encoding='utf-8') as f:\n",
    "        knowledge_base = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\"aggregated_data.json not found. Please make sure it exists in the same directory as this script\")\n",
    "\n",
    "# Prepare documents for TF-IDF\n",
    "documents = [doc['content'] for doc in knowledge_base]\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "def get_relevant_documents(query, top_k=3):\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    similarities = cosine_similarity(query_vector, tfidf_matrix)[0]\n",
    "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
    "    relevant_docs = [{'content': knowledge_base[idx]['content'], \n",
    "                      'source': knowledge_base[idx].get('source'), \n",
    "                      'title': knowledge_base[idx].get('title')} \n",
    "                     for idx in top_indices]\n",
    "    return relevant_docs\n",
    "\n",
    "def ask_question(question):\n",
    "    try:\n",
    "        relevant_docs = get_relevant_documents(question)\n",
    "        \n",
    "        context = \"Based on the following information:\\n\\n\"\n",
    "        for doc in relevant_docs:\n",
    "            context += f\"Document: {doc['content']}\\n\\n\"\n",
    "        \n",
    "        prompt = f\"\"\"{context}\n",
    "        \n",
    "        Question: {question}\n",
    "        \n",
    "        Please provide a clear and concise answer based only on the information provided above. \n",
    "        If the information is not sufficient to answer the question, please say so.\"\"\"\n",
    "        \n",
    "        response = model.generate_content(prompt)\n",
    "        \n",
    "        sources = [{'url': doc['source'], 'title': doc['title']} \n",
    "                   for doc in relevant_docs if doc.get('source')]\n",
    "        \n",
    "        return response.text, sources\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\", []\n",
    "\n",
    "# Gradio interface\n",
    "def gradio_interface(question):\n",
    "    answer, sources = ask_question(question)\n",
    "    sources_html = \"<br>\".join([f\"<a href='{src['url']}' target='_blank'>{src['title']}</a>\" for src in sources])\n",
    "    return answer, sources_html\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=gradio_interface,\n",
    "    inputs=gr.Textbox(lines=4, placeholder=\"Enter your question here...\"),\n",
    "    outputs=[gr.Textbox(label=\"Answer\"), gr.HTML(label=\"Sources\")],\n",
    "    live=True\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    interface.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0578bf84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8080\n",
      " * Running on http://192.168.1.129:8080\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import gradio as gr\n",
    "from flask import Flask, request, jsonify\n",
    "import google.generativeai as genai\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Configure Gemini directly with API key\n",
    "genai.configure(api_key=\"\")\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "# Load the data\n",
    "try:\n",
    "    with open('aggregated_data.json', 'r', encoding='utf-8') as f:\n",
    "        knowledge_base = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\"aggregated_data.json not found. Please make sure it exists in the same directory as this script\")\n",
    "\n",
    "# Prepare documents for TF-IDF\n",
    "documents = [doc['content'] for doc in knowledge_base]\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "def get_relevant_documents(query, top_k=3):\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    similarities = cosine_similarity(query_vector, tfidf_matrix)[0]\n",
    "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
    "    relevant_docs = [{'content': knowledge_base[idx]['content'], \n",
    "                      'source': knowledge_base[idx].get('source'), \n",
    "                      'title': knowledge_base[idx].get('title')} \n",
    "                     for idx in top_indices]\n",
    "    return relevant_docs\n",
    "\n",
    "def ask_question(question):\n",
    "    try:\n",
    "        relevant_docs = get_relevant_documents(question)\n",
    "        \n",
    "        context = \"Based on the following information:\\n\\n\"\n",
    "        for doc in relevant_docs:\n",
    "            context += f\"Document: {doc['content']}\\n\\n\"\n",
    "        \n",
    "        prompt = f\"\"\"{context}\n",
    "        \n",
    "        Question: {question}\n",
    "        \n",
    "        Please provide a clear and concise answer based only on the information provided above. \n",
    "        If the information is not sufficient to answer the question, please say so.\"\"\"\n",
    "        \n",
    "        response = model.generate_content(prompt)\n",
    "        \n",
    "        sources = [{'url': doc['source'], 'title': doc['title']} \n",
    "                   for doc in relevant_docs if doc.get('source')]\n",
    "        \n",
    "        return response.text, sources\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\", []\n",
    "\n",
    "# Gradio interface wrapped in Flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/ask', methods=['POST'])\n",
    "def ask():\n",
    "    question = request.json.get('question')\n",
    "    answer, sources = ask_question(question)\n",
    "    return jsonify({'answer': answer, 'sources': sources})\n",
    "\n",
    "# Gradio interface\n",
    "def gradio_interface(question):\n",
    "    answer, sources = ask_question(question)\n",
    "    sources_html = \"<br>\".join([f\"<a href='{src['url']}' target='_blank'>{src['title']}</a>\" for src in sources])\n",
    "    return answer, sources_html\n",
    "\n",
    "# Launch Gradio interface\n",
    "interface = gr.Interface(\n",
    "    fn=gradio_interface,\n",
    "    inputs=gr.Textbox(lines=4, placeholder=\"Enter your question here...\"),\n",
    "    outputs=[gr.Textbox(label=\"Answer\"), gr.HTML(label=\"Sources\")],\n",
    "    live=True\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Use the port specified by Cloud Run\n",
    "    port = int(os.environ.get(\"PORT\", 8080))\n",
    "    app.run(host='0.0.0.0', port=port)\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d98db9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omidm\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8080\n",
      " * Running on http://192.168.1.129:8080\n",
      "Press CTRL+C to quit\n",
      "192.168.1.129 - - [18/Feb/2025 12:51:25] \"GET / HTTP/1.1\" 200 -\n",
      "192.168.1.129 - - [18/Feb/2025 12:51:25] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "192.168.1.129 - - [18/Feb/2025 12:51:40] \"POST /ask HTTP/1.1\" 200 -\n",
      "192.168.1.129 - - [18/Feb/2025 12:52:23] \"POST /ask HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, render_template_string\n",
    "import google.generativeai as genai\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "import os\n",
    "\n",
    "# HTML template as a string\n",
    "HTML_TEMPLATE = '''\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Question Answering System</title>\n",
    "    <style>\n",
    "        body {\n",
    "            font-family: Arial, sans-serif;\n",
    "            max-width: 800px;\n",
    "            margin: 0 auto;\n",
    "            padding: 20px;\n",
    "        }\n",
    "        .container {\n",
    "            margin-top: 20px;\n",
    "        }\n",
    "        #question {\n",
    "            width: 100%;\n",
    "            padding: 10px;\n",
    "            margin-bottom: 10px;\n",
    "        }\n",
    "        #response {\n",
    "            margin-top: 20px;\n",
    "            white-space: pre-wrap;\n",
    "        }\n",
    "        .sources {\n",
    "            margin-top: 10px;\n",
    "            font-size: 0.9em;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Ask a Question</h1>\n",
    "    <div class=\"container\">\n",
    "        <textarea id=\"question\" rows=\"4\" placeholder=\"Enter your question here...\"></textarea>\n",
    "        <button onclick=\"askQuestion()\">Submit</button>\n",
    "        <div id=\"response\"></div>\n",
    "        <div id=\"sources\" class=\"sources\"></div>\n",
    "    </div>\n",
    "\n",
    "    <script>\n",
    "        async function askQuestion() {\n",
    "            const question = document.getElementById('question').value;\n",
    "            const responseDiv = document.getElementById('response');\n",
    "            const sourcesDiv = document.getElementById('sources');\n",
    "            \n",
    "            responseDiv.innerHTML = 'Loading...';\n",
    "            sourcesDiv.innerHTML = '';\n",
    "\n",
    "            try {\n",
    "                const response = await fetch('/ask', {\n",
    "                    method: 'POST',\n",
    "                    headers: {\n",
    "                        'Content-Type': 'application/json',\n",
    "                    },\n",
    "                    body: JSON.stringify({ question: question }),\n",
    "                });\n",
    "\n",
    "                const data = await response.json();\n",
    "                responseDiv.innerHTML = data.answer;\n",
    "                \n",
    "                if (data.sources && data.sources.length > 0) {\n",
    "                    sourcesDiv.innerHTML = '<h3>Sources:</h3>' + \n",
    "                        data.sources.map(source => \n",
    "                            `<p><a href=\"${source.url}\" target=\"_blank\">${source.title}</a></p>`\n",
    "                        ).join('');\n",
    "                }\n",
    "            } catch (error) {\n",
    "                responseDiv.innerHTML = 'Error: ' + error.message;\n",
    "            }\n",
    "        }\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "# Configure Gemini directly with API key\n",
    "genai.configure(api_key=\"\")\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "try:\n",
    "    # Load the data\n",
    "    with open('aggregated_data.json', 'r', encoding='utf-8') as f:\n",
    "        knowledge_base = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\"aggregated_data.json not found. Please make sure it exists in the same directory as app.py\")\n",
    "\n",
    "# Prepare documents for TF-IDF\n",
    "documents = [doc['content'] for doc in knowledge_base]\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "def get_relevant_documents(query, top_k=3):\n",
    "    # Transform the query\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    \n",
    "    # Calculate similarity\n",
    "    similarities = cosine_similarity(query_vector, tfidf_matrix)[0]\n",
    "    \n",
    "    # Get top k most similar documents\n",
    "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
    "    \n",
    "    relevant_docs = []\n",
    "    for idx in top_indices:\n",
    "        doc = knowledge_base[idx]\n",
    "        relevant_docs.append({\n",
    "            'content': doc['content'],\n",
    "            'source': doc['source'],\n",
    "            'title': doc['title']\n",
    "        })\n",
    "    \n",
    "    return relevant_docs\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template_string(HTML_TEMPLATE)\n",
    "\n",
    "@app.route('/ask', methods=['POST'])\n",
    "def ask():\n",
    "    try:\n",
    "        data = request.json\n",
    "        question = data['question']\n",
    "        \n",
    "        # Get relevant documents\n",
    "        relevant_docs = get_relevant_documents(question)\n",
    "        \n",
    "        # Prepare context for Gemini\n",
    "        context = \"Based on the following information:\\n\\n\"\n",
    "        for doc in relevant_docs:\n",
    "            context += f\"Document: {doc['content']}\\n\\n\"\n",
    "        \n",
    "        prompt = f\"\"\"{context}\n",
    "        \n",
    "        Question: {question}\n",
    "        \n",
    "        Please provide a clear and concise answer based only on the information provided above. \n",
    "        If the information is not sufficient to answer the question, please say so.\"\"\"\n",
    "        \n",
    "        # Generate response using Gemini\n",
    "        response = model.generate_content(prompt)\n",
    "        \n",
    "        # Prepare sources information\n",
    "        sources = []\n",
    "        for doc in relevant_docs:\n",
    "            if doc['source']:  # Only include if source URL exists\n",
    "                sources.append({\n",
    "                    'url': doc['source'],\n",
    "                    'title': doc['title']\n",
    "                })\n",
    "        \n",
    "        return jsonify({\n",
    "            'answer': response.text,\n",
    "            'sources': sources\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Use the port specified by Cloud Run\n",
    "    port = int(os.environ.get(\"PORT\", 8080))\n",
    "    app.run(host='0.0.0.0', port=port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928f4fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e14cd5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
