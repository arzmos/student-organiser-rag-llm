{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfe3a2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Content from RCP#0032 Intake 10 Student Internship Summary reports (share with all)\n",
      "Content: RCP#0032\n",
      "Intake\n",
      "10\n",
      "Student \n",
      "Internship\n",
      "Summary\n",
      "reports\n",
      "Table\n",
      "of\n",
      "Contents\n",
      "Link\n",
      "to\n",
      "Intake\n",
      "9\n",
      "Summary\n",
      "Report\n",
      "RCP#0016\n",
      "Intake\n",
      "9\n",
      "Student\n",
      "Internship\n",
      "Summary\n",
      "reports.pdf\n",
      "that\n",
      "can\n",
      "be\n",
      "used\n",
      "as\n",
      "an\n",
      "example.AIVE\n",
      "Student\n",
      "Project\n",
      "Interns:\n",
      "Si\n",
      "Yang\n",
      "(Sean)\n",
      "Chen,\n",
      "Chun-Tung\n",
      "(Chloe)\n",
      "Tsai,\n",
      "Jiawen\n",
      "Deng\n",
      "High-Level\n",
      "Domain\n",
      "work\n",
      "During\n",
      "the\n",
      "first\n",
      "4-5\n",
      "weeks,\n",
      "we\n",
      "learned\n",
      "about\n",
      "and\n",
      "tried\n",
      "to\n",
      "understand\n",
      "the\n",
      "AIVE\n",
      "workflow\n",
      "for\n",
      "converting\n",
      "2D\n",
      "cell\n",
      "image\n",
      "stacks\n",
      "into\n",
      "3D\n",
      "models\n",
      "and\n",
      "familiarised\n",
      "ourselves\n",
      "with\n",
      "software\n",
      "tools\n",
      "used\n",
      "in\n",
      "the\n",
      "...\n",
      "Topic: RCP#0032 Intake 10 Student Internship Summary reports (share with all)\n",
      "Keywords: data, github, project, technical, work\n",
      "----------------------------------------\n",
      "Title: Content from Research Computing Platform Student Internship Handbook\n",
      "Content: Research\n",
      "Computing\n",
      "Platform\n",
      "Student Handbook3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8Introduction\n",
      "Philosophy\n",
      "Benefits for Students\n",
      "Numbers behind the program\n",
      "Code of Conduct\n",
      "Want to know more?Table of ContentsIntroduction\n",
      "The Research Computing Platform (RCP) is a  \n",
      "collaborative, multi-disciplinary lab that\n",
      "supports and advocates for researchers and\n",
      "their computational research needs at WEHI.\n",
      "RCP has established a 100% remote, unpaid\n",
      "student internship program with subjects\n",
      "provided at the University of Melbourne. We\n",
      "did th...\n",
      "Topic: Research Computing Platform Student Internship Handbook\n",
      "Keywords: program, projects, rcp, student, students\n",
      "----------------------------------------\n",
      "Title: Content from RCP0026 Welcome Students Semeter 2 Intake 10\n",
      "Content: Walter and Eliza Hall Institute of Medical ResearchRCP Student Internship Welcome \n",
      "Summer 2024 2025\n",
      "Week of 25th November 2024Acknowledgement of Country\n",
      "I acknowledge the Wurundjeri and Boon Wurrung people, on\n",
      "whose unceded lands some of us live and work here in\n",
      "Naarm (Melbourne). I respectfully acknowledge their Elders,\n",
      "past and present. I also acknowledge all the Traditional\n",
      "Owners of Country throughout the continent of Australia. I\n",
      "pay my respects to their Elders past and present. \n",
      "02Agenda\n",
      "A...\n",
      "Topic: RCP0026 Welcome Students Semeter 2 Intake 10\n",
      "Keywords: email, project, students, team, wehi\n",
      "----------------------------------------\n",
      "Title: Learn real world skills\n",
      "Content: We prepare students for the real-world by teaching them:...\n",
      "Topic: Unpaid Student Internship Program\n",
      "Keywords: learn, prepare, real, skills, world\n",
      "----------------------------------------\n",
      "Title: Types of projects\n",
      "Content: Many of the projects work in the Data Analysis and Research Software Engineering space using High Performance Compute (HPC). We work across diverse projects such as imaging, cryo-EM, genomics, transcriptomics, clinical informatics, and capacity planning....\n",
      "Topic: Unpaid Student Internship Program\n",
      "Keywords: projects, space, transcriptomics, types, work\n",
      "----------------------------------------\n",
      "Title: Open source contributors\n",
      "Content: Sometimes, we are in contact with students who cannot get course credit and are extremely keen to volunteer as an open source software contributor. In these situations, we have to be careful we do not act in an exploitative way. This is why we have written our expectations of potential open source contributors to make the expectations more transparent....\n",
      "Topic: Unpaid Student Internship Program\n",
      "Keywords: act, contributors, expectations, open, source\n",
      "----------------------------------------\n",
      "Title: Hear from previous students\n",
      "Content: You can listen to two students talk about their projects (click image below)....\n",
      "Topic: Unpaid Student Internship Program\n",
      "Keywords: click, hear, image, listen, students\n",
      "----------------------------------------\n",
      "Title: Key Documents to review and FAQ\n",
      "Content: To understand more about the program, you can read:...\n",
      "Topic: Unpaid Student Internship Program\n",
      "Keywords: documents, faq, key, program, read\n",
      "----------------------------------------\n",
      "Title: How to Apply\n",
      "Content: Go to the GitHub repo to change this website...\n",
      "Topic: Unpaid Student Internship Program\n",
      "Keywords: apply, change, github, repo, website\n",
      "----------------------------------------\n",
      "Title: To make changes to this website\n",
      "Content: Go to the GitHub repo to change this website...\n",
      "Topic: Unpaid Student Internship Program\n",
      "Keywords: change, changes, github, make, website\n",
      "----------------------------------------\n",
      "Title: Philosophy\n",
      "Content: Students are encouraged to self-direct during the internship and be as independent as possible, with supervision. Balancing what the student wants to do and benefiting WEHI is a great example of a fantastic project....\n",
      "Topic: explanation about ohs\n",
      "Keywords: balancing, self, student, students, supervision\n",
      "----------------------------------------\n",
      "Title: Allocating Students to Projects\n",
      "Content: The way I allocate students to projects is based on their skills and interests. The process is as follows:...\n",
      "Topic: explanation about ohs\n",
      "Keywords: allocate, allocating, based, projects, students\n",
      "----------------------------------------\n",
      "Title: During the project\n",
      "Content: I ask students to meet a minimum of three times a week. One meeting is to meet as a team with the supervisor to understand the high-level concepts and the architectural or algorithmic limitations, another meeting is a co-working meeting with their fellow project members without the supervisor, and another meeting is a co-working meeting with “sister project” team members to help share information across projects....\n",
      "Topic: explanation about ohs\n",
      "Keywords: meeting, members, project, supervisor, team\n",
      "----------------------------------------\n",
      "Title: Documentation\n",
      "Content: By doing this I teach them that they need to document their new knowledge and technical work for the next set of students, which increases findability, usability and maintenance of the work that they have done. This is also a critical skill for their future careers for project handovers and maintenance work, which many students do not have experience with....\n",
      "Topic: explanation about ohs\n",
      "Keywords: maintenance, students, teach, technical, work\n",
      "----------------------------------------\n",
      "Title: Other Interactions\n",
      "Content: I also have scheduled a voluntary follow-up session / networking session between students on Thursday across the entire student intake but have stopped these due to lack of uptake by the students. By the third week no-one attends, and I am left to myself....\n",
      "Topic: explanation about ohs\n",
      "Keywords: attends, session, students, thursday, uptake\n",
      "----------------------------------------\n",
      "Title: Other Resources\n",
      "Content: Finally, I provide resources to the students that help them in every step of the program, including FAQS that include how I expect meetings to be run, how you can escalate a question, among other things....\n",
      "Topic: explanation about ohs\n",
      "Keywords: escalate, expect, faqs, finally, resources\n",
      "----------------------------------------\n",
      "Title: Feedback\n",
      "Content: We have had 169 students through the program since Semester 2, 2021 who have provided over 18 person years of effort to help us uncover and document complexity early in over 20 projects....\n",
      "Topic: explanation about ohs\n",
      "Keywords: 169, projects, provided, semester, students\n",
      "----------------------------------------\n",
      "Title: Semester 1 2025 Projects\n",
      "Content: The project would involve a series of stages to bring the software infrastructure to a level that will help with development in a complex research environment where currently only 2 people in the world know the software.  For more details see the AIVE project and the AIVE public wiki....\n",
      "Topic: project wikis\n",
      "Keywords: 2025, aive, project, software, stages\n",
      "----------------------------------------\n",
      "Title: Ongoing Projects\n",
      "Content: This project aims to create a proof-of-concept for a Data Lakehouse / Data Commons at WEHI. For more details see Introduction to REDMANE, Data Lakehouse / Data Commons project and the Data Commons Wiki....\n",
      "Topic: project wikis\n",
      "Keywords: aims, commons, data, lakehouse, project\n",
      "----------------------------------------\n",
      "Title: Potential Projects that are dependent on various factors\n",
      "Content: This project helps to setup infrastructure to keep track of what happens to a sample once it reaches the Genomics Facility. For more details see Genomics Metadata Multiplexing project. and the Genomics Metadata Multiplexing Wiki...\n",
      "Topic: project wikis\n",
      "Keywords: genomics, metadata, multiplexing, project, track\n",
      "----------------------------------------\n",
      "Title: Previous projects\n",
      "Content: This projects looks to improve on Haemosphere, which is like a web-based pocket dictionary for visualising and comparing genomic blood datasets. For more details see Haemosphere project and the Haemosphere wiki....\n",
      "Topic: project wikis\n",
      "Keywords: based, haemosphere, project, projects, visualising\n",
      "----------------------------------------\n",
      "Title: Other documentation\n",
      "Content: And a high level Getting started Guides - wiki...\n",
      "Topic: project wikis\n",
      "Keywords: documentation, getting, guides, high, level\n",
      "----------------------------------------\n",
      "Title: Introduction\n",
      "Content: LoxCode is a novel technology developed in the Naik lab at WEHI that allows to create on demand random tags (or barcodes) in the DNA of living cells. These tags are read out via next generation sequencing and help to study important questions in biology like cancer evolution or embryonic development. Given that both the technology and the data it generates are new, no software is currently available that would facilitate the analysis, especially for experimental researchers less familiar with pr...\n",
      "Topic: loxcoder\n",
      "Keywords: available, development, sequencing, technology, use\n",
      "----------------------------------------\n",
      "Title: Duties while on placement\n",
      "Content: The role of the intern is to:...\n",
      "Topic: loxcoder\n",
      "Keywords: duties, intern, placement, role\n",
      "----------------------------------------\n",
      "Title: Skills and Pre-requisites\n",
      "Content: Skills and Pre-requisites:...\n",
      "Topic: loxcoder\n",
      "Keywords: pre, requisites, skills\n",
      "----------------------------------------\n",
      "Title: Benefits for students\n",
      "Content: Benefits for students whilst undertaking the internship include:...\n",
      "Topic: loxcoder\n",
      "Keywords: benefits, include, internship, students, undertaking\n",
      "----------------------------------------\n",
      "Title: Introduction\n",
      "Content: As part of our ongoing efforts to evaluate and implement innovative data management strategies, we are offering an internship opportunity to work on a pre-production project for a data commons called REDMANE. We are seeking a motivated and detail-oriented intern to join our team and contribute to the development of a pre-production data infrastructure....\n",
      "Topic: student data commons\n",
      "Keywords: called, data, pre, production, strategies\n",
      "----------------------------------------\n",
      "Title: Multiple sub-projects within this project\n",
      "Content: This project is made up of the following sub-projects that an intern can apply for:...\n",
      "Topic: student data commons\n",
      "Keywords: apply, following, project, projects, sub\n",
      "----------------------------------------\n",
      "Title: Duties while on placement\n",
      "Content: As a Research Software Engineer Intern, you will play a crucial role in supporting the design and implementation of a pre-production Research Data Management ecosystem called REDMANE. This internship will provide you with valuable hands-on experience in trialling, analysing, and improving different platforms. You will assist in building a scalable data management infrastructure and gain exposure to various aspects of data integration, modeling, and governance....\n",
      "Topic: student data commons\n",
      "Keywords: analysing, data, internship, management, research\n",
      "----------------------------------------\n",
      "Title: Skills and Pre-requisites\n",
      "Content: To excel in this internship project, the ideal candidate should have a willingness to research system administration and development skilsl and processes, an ability to learn quickly, an enthusiasm for research software architecture, and a willingness to share and communicate information. It would be beneficial if the student had an interest in learning Python, Web site development, API development, command-line scripting, System administration, Virtual Machines, OpenStack Cloud, and how to impr...\n",
      "Topic: student data commons\n",
      "Keywords: development, learning, research, student, willingness\n",
      "----------------------------------------\n",
      "Title: Further reading\n",
      "Content: Hosted on GitHub Pages — Theme by orderedlist...\n",
      "Topic: student data commons\n",
      "Keywords: github, hosted, orderedlist, pages, reading\n",
      "----------------------------------------\n",
      "Title: Introduction\n",
      "Content: WEHI is currently focusing on improving its ability to handle big data from the multi-million dollar Cryogenic Electron Microscopy (cryo-EM) instrument. The candidate will develop an understanding of data flow from the cryo-EM facility and determine how data and metadata should be stored to support Findable Accessible Interoperable and Resuable data practices. The key output of the project is a framework for evaluating the suitability of third-party or in-house tools to support complex cryo-EMpr...\n",
      "Topic: cryoem\n",
      "Keywords: ability, cryo, data, em, support\n",
      "----------------------------------------\n",
      "Title: Duties while on placement\n",
      "Content: The Research Data Engineer Intern role will:...\n",
      "Topic: cryoem\n",
      "Keywords: data, duties, engineer, intern, placement\n",
      "----------------------------------------\n",
      "Title: Skills and Pre-requisites\n",
      "Content: Skills and Pre-requisites include:...\n",
      "Topic: cryoem\n",
      "Keywords: include, pre, requisites, skills\n",
      "----------------------------------------\n",
      "Title: Benefits for students\n",
      "Content: Benefits for students whilst undertaking the internship include:...\n",
      "Topic: cryoem\n",
      "Keywords: benefits, include, internship, students, undertaking\n",
      "----------------------------------------\n",
      "Title: Introduction\n",
      "Content: Post-sequencing quality control (QC) is an important step in ensuring that the quality of sequencing data meets expectations. Multiple tools exist to evaluate sequencing quality, such as FastQC[1], Fastq Screen[2] and Qualimap[3]. Core sequencing facilities, such as WEHI Genomics, process hundreds of sequencing runs every year. In order to troubleshoot sequencing issues and provide assurance of data quality to collaborators, sequencing facilities must implement robust data management workflows t...\n",
      "Topic: genomics quantum computing\n",
      "Keywords: data, qc, quality, runs, sequencing\n",
      "----------------------------------------\n",
      "Title: Duties while on placement\n",
      "Content: The Research Software Engineer Intern role will:...\n",
      "Topic: genomics quantum computing\n",
      "Keywords: duties, engineer, intern, placement, research\n",
      "----------------------------------------\n",
      "Title: Skills and Pre-requisites\n",
      "Content: Skills and Pre-requisites:...\n",
      "Topic: genomics quantum computing\n",
      "Keywords: pre, requisites, skills\n",
      "----------------------------------------\n",
      "Title: Benefits for students\n",
      "Content: Benefits for students whilst undertaking the internship include:...\n",
      "Topic: genomics quantum computing\n",
      "Keywords: benefits, include, internship, students, undertaking\n",
      "----------------------------------------\n",
      "Title: Introduction\n",
      "Content: Bioconductor is a pivotal and highly influential initiative in the field of bioinformatics and computational biology. It plays a critical role in helping researchers by providing an extensive and comprehensive ecosystem of software tools, packages, and resources tailored specifically for the analysis and interpretation of high-throughput biological data....\n",
      "Topic: schex\n",
      "Keywords: analysis, role, software, specifically, tailored\n",
      "----------------------------------------\n",
      "Title: Duties while on placement\n",
      "Content: This project would suit a candidate who was interested in maintaining research software, wants to gain experience within an open source software environment like Bioconductor, and enjoys learning about complex processes....\n",
      "Topic: schex\n",
      "Keywords: bioconductor, project, research, software, source\n",
      "----------------------------------------\n",
      "Title: Skills and Pre-requisites\n",
      "Content: To excel in this internship project, the ideal candidate should have a willingness to research and learn about Bioconductor and schex, an ability to learn quickly, an enthusiasm for trying new things, and a willingness to share and communicate information....\n",
      "Topic: schex\n",
      "Keywords: learn, share, skills, things, willingness\n",
      "----------------------------------------\n",
      "Title: Benefits for students\n",
      "Content: The benefits for students whilst undertaking the internship include:...\n",
      "Topic: schex\n",
      "Keywords: benefits, include, internship, students, undertaking\n",
      "----------------------------------------\n",
      "Title: Further reading\n",
      "Content: Hosted on GitHub Pages — Theme by orderedlist...\n",
      "Topic: schex\n",
      "Keywords: github, hosted, orderedlist, pages, reading\n",
      "----------------------------------------\n",
      "Title: Introduction\n",
      "Content: mixOmics is a large R package that provides statistical methods to integrate omics data sets (e.g transcriptomics, proteomics, metabolomics, metagenomics) that simultaneously measure the activity of thousands of biological features (e.g transcripts, proteins, metabolites, bacteria). Data integration enables identification of specific biological relationships between these features (e.g. genes and proteins), to create new insights into molecular processes involved in health and disease. MixOmics ...\n",
      "Topic: mixOmics\n",
      "Keywords: biological, data, integration, methods, mixomics\n",
      "----------------------------------------\n",
      "Title: Duties while on placement\n",
      "Content: As this is a large project, the internship requires complementary skillsets to:...\n",
      "Topic: mixOmics\n",
      "Keywords: complementary, duties, internship, large, placement\n",
      "----------------------------------------\n",
      "Title: Skills and Pre-requisites\n",
      "Content: Skills and Pre-requisites:...\n",
      "Topic: mixOmics\n",
      "Keywords: pre, requisites, skills\n",
      "----------------------------------------\n",
      "Title: Benefits for students\n",
      "Content: Benefits for students whilst undertaking the internship include:...\n",
      "Topic: mixOmics\n",
      "Keywords: benefits, include, internship, students, undertaking\n",
      "----------------------------------------\n",
      "Title: Introduction\n",
      "Content: WEHI is currently reviewing its storage and compute capacity and would like to create models to forecast capacity and create dashboards to demonstrate current usage and help make informed decisions....\n",
      "Topic: capacity planning\n",
      "Keywords: capacity, create, models, reviewing, storage\n",
      "----------------------------------------\n",
      "Title: Duties while on placement\n",
      "Content: The Capacity Planning Data Scientist Intern and Capacity Planning Data Engineering Intern role will:...\n",
      "Topic: capacity planning\n",
      "Keywords: capacity, data, duties, intern, planning\n",
      "----------------------------------------\n",
      "Title: Skills and Pre-requisites\n",
      "Content: Preferred skills:...\n",
      "Topic: capacity planning\n",
      "Keywords: pre, preferred, requisites, skills\n",
      "----------------------------------------\n",
      "Title: Benefits for students\n",
      "Content: Benefits for students whilst undertaking the internship include:...\n",
      "Topic: capacity planning\n",
      "Keywords: benefits, include, internship, students, undertaking\n",
      "----------------------------------------\n",
      "Title: Introduction\n",
      "Content: Haemosphere.org is a publicly available database of blood cell gene expression. The haematopoietic research community is a diverse group which contains researchers with various levels of experience in analysing expression data, so we have created this resource to allow easy and fast access to the data for all researchers, and to provide access to the raw data for those who wish to follow up with their own analyses. The main function is that it helps researchers understand which genes are turned ...\n",
      "Topic: haemosphere\n",
      "Keywords: cell, data, expression, plots, researchers\n",
      "----------------------------------------\n",
      "Title: Duties while on placement\n",
      "Content: The Research Software Engineer Intern role will:...\n",
      "Topic: haemosphere\n",
      "Keywords: duties, engineer, intern, placement, research\n",
      "----------------------------------------\n",
      "Title: Skills and Pre-requisites\n",
      "Content: Skills and Pre-requisites:...\n",
      "Topic: haemosphere\n",
      "Keywords: pre, requisites, skills\n",
      "----------------------------------------\n",
      "Title: Benefits for students\n",
      "Content: Benefits for students whilst undertaking the internship include:...\n",
      "Topic: haemosphere\n",
      "Keywords: benefits, include, internship, students, undertaking\n",
      "----------------------------------------\n",
      "Title: Introduction\n",
      "Content: WEHI is currently developing its Research Data Management requirements and is evaluating products and tools for a hybrid Research Data Management ecosystem. The candidate will develop an understanding of data flow from WEHI microscopes and determine how to automate the processing of microscopy files based off custom scripts provided by the BioImaging team. The key output of the project is to further the current work around making it easier for non-technical people to access High Performance Comp...\n",
      "Topic: imaging\n",
      "Keywords: data, management, microscopes, research, wehi\n",
      "----------------------------------------\n",
      "Title: Duties while on placement\n",
      "Content: The Research Data Engineer Intern role will:...\n",
      "Topic: imaging\n",
      "Keywords: data, duties, engineer, intern, placement\n",
      "----------------------------------------\n",
      "Title: Skills and Pre-requisites\n",
      "Content: Skills and Pre-requisites:...\n",
      "Topic: imaging\n",
      "Keywords: pre, requisites, skills\n",
      "----------------------------------------\n",
      "Title: Benefits for students\n",
      "Content: Benefits for students whilst undertaking the internship include:...\n",
      "Topic: imaging\n",
      "Keywords: benefits, include, internship, students, undertaking\n",
      "----------------------------------------\n",
      "Title: Introduction\n",
      "Content: Quantum computers are gaining attention from disciplines outside of physics. We are starting to see algorithms being developed that could be used to solve problems in the future. There are many problems that exist in biology and bioinformatics that could be explored with quantum computing....\n",
      "Topic: quantum\n",
      "Keywords: algorithms, physics, problems, quantum, solve\n",
      "----------------------------------------\n",
      "Title: Duties while on placement\n",
      "Content: The Research Data Engineer Intern role will:...\n",
      "Topic: quantum\n",
      "Keywords: data, duties, engineer, intern, placement\n",
      "----------------------------------------\n",
      "Title: Skills and Pre-requisites:\n",
      "Content: To excel in this internship project, the ideal candidate should have a willingness to research quantum computers, an ability to learn quickly, an enthusiasm for quantum computing, and a willingness to share and communicate information....\n",
      "Topic: quantum\n",
      "Keywords: quantum, requisites, research, share, willingness\n",
      "----------------------------------------\n",
      "Title: Benefits for students\n",
      "Content: The benefits for students whilst undertaking the internship include:...\n",
      "Topic: quantum\n",
      "Keywords: benefits, include, internship, students, undertaking\n",
      "----------------------------------------\n",
      "Title: Further Reading\n",
      "Content: Hosted on GitHub Pages — Theme by orderedlist...\n",
      "Topic: quantum\n",
      "Keywords: github, hosted, orderedlist, pages, reading\n",
      "----------------------------------------\n",
      "Title: Introduction\n",
      "Content: Core sequencing facilities, such as WEHI Genomics, process hundreds of sequencing runs every year. They have to keep track of the how samples are merged (multiplexed) so that they can be uncoupled (demultiplexed) after the sample has been digitised (sequenced) through the sequencing machine. This is a type of metadata....\n",
      "Topic: genomics metadata\n",
      "Keywords: core, sequencing, track, type, uncoupled\n",
      "----------------------------------------\n",
      "Title: Duties while on placement\n",
      "Content: The Research Software Engineer Intern role will:...\n",
      "Topic: genomics metadata\n",
      "Keywords: duties, engineer, intern, placement, research\n",
      "----------------------------------------\n",
      "Title: Skills and Pre-requisites\n",
      "Content: Skills and Pre-requisites:...\n",
      "Topic: genomics metadata\n",
      "Keywords: pre, requisites, skills\n",
      "----------------------------------------\n",
      "Title: Benefits for students\n",
      "Content: Benefits for students whilst undertaking the internship include:...\n",
      "Topic: genomics metadata\n",
      "Keywords: benefits, include, internship, students, undertaking\n",
      "----------------------------------------\n",
      "Title: Further reading\n",
      "Content: Hosted on GitHub Pages — Theme by orderedlist...\n",
      "Topic: genomics metadata\n",
      "Keywords: github, hosted, orderedlist, pages, reading\n",
      "----------------------------------------\n",
      "Title: Introduction\n",
      "Content: Our cells contain a vast array of interacting organelles (tiny structures within cells that perform specific tasks, similar to the parts of a machine) that determine cellular processes through both health and disease. These structures may be imaged using electron microscopy by bouncing electrons off heavy-metal stained membranes. The resulting images have a resolution of nanometers per voxel (the 3D equivalent of an image pixel) in 3D and each data set may contain millions or billions of voxels ...\n",
      "Topic: aive\n",
      "Keywords: 3d, cells, contain, millions, structures\n",
      "----------------------------------------\n",
      "Title: Duties while on placement\n",
      "Content: In this role, you will need to be willing to read and synthesise the original paper with the latest documentation, and work with the Research Software Engineer (RSE) to help streamline all parts of the workflow....\n",
      "Topic: aive\n",
      "Keywords: documentation, software, streamline, synthesise, willing\n",
      "----------------------------------------\n",
      "Title: Skills and Pre-requisites\n",
      "Content: The benefits for students whilst undertaking the internship include:...\n",
      "Topic: aive\n",
      "Keywords: benefits, include, internship, pre, requisites\n",
      "----------------------------------------\n",
      "Title: Benefits for students\n",
      "Content: The benefits for students whilst undertaking the internship include:...\n",
      "Topic: aive\n",
      "Keywords: benefits, include, internship, students, undertaking\n",
      "----------------------------------------\n",
      "Title: Further reading\n",
      "Content: Hosted on GitHub Pages — Theme by orderedlist...\n",
      "Topic: aive\n",
      "Keywords: github, hosted, orderedlist, pages, reading\n",
      "----------------------------------------\n",
      "Title: Introduction\n",
      "Content: Bioinformatics as a discipline frequently uses many individual software tools, connected in potentially complicated ways, to perform typical analysis. As an example, standard Single Nucleotide Variant (SNV) calling in cancer involves alignment of the sequencing reads to a reference genome, sorting and indexing, variant calling, and subsequent annotation against various databases. Each of these stages comprises of one or more software tools with different input requirements....\n",
      "Topic: bionix\n",
      "Keywords: alignment, calling, software, tools, variant\n",
      "----------------------------------------\n",
      "Title: Duties while on placement\n",
      "Content: The candidate will be get the opportunity to:...\n",
      "Topic: bionix\n",
      "Keywords: candidate, duties, opportunity, placement\n",
      "----------------------------------------\n",
      "Title: Skills and Pre-requisites\n",
      "Content: This project would suit a research software engineering candidate who was interested in reproducibility, wants to gain experience with executing bioinformatics workflows efficiently, and enjoys streamlining complex processes....\n",
      "Topic: bionix\n",
      "Keywords: bioinformatics, skills, software, streamlining, suit\n",
      "----------------------------------------\n",
      "Title: Benefits for student\n",
      "Content: The benefits for the studnet include:...\n",
      "Topic: bionix\n",
      "Keywords: benefits, include, student, studnet\n",
      "----------------------------------------\n",
      "Title: References\n",
      "Content: Hosted on GitHub Pages — Theme by orderedlist...\n",
      "Topic: bionix\n",
      "Keywords: github, hosted, orderedlist, pages, references\n",
      "----------------------------------------\n",
      "Title: Introduction\n",
      "Content: WEHI is currently looking at how to take clinical data from databases and create visualisations and dashboards to help administrators and clinicians explore the data....\n",
      "Topic: clinical dashboards\n",
      "Keywords: administrators, clinical, clinicians, create, data\n",
      "----------------------------------------\n",
      "Title: Duties while on placement\n",
      "Content: The Research Data Engineer Intern role will:...\n",
      "Topic: clinical dashboards\n",
      "Keywords: data, duties, engineer, intern, placement\n",
      "----------------------------------------\n",
      "Title: Skills and Pre-requisites\n",
      "Content: Benefits for students whilst undertaking the internship include:...\n",
      "Topic: clinical dashboards\n",
      "Keywords: benefits, include, internship, pre, requisites\n",
      "----------------------------------------\n",
      "Title: Benefits for students\n",
      "Content: Benefits for students whilst undertaking the internship include:...\n",
      "Topic: clinical dashboards\n",
      "Keywords: benefits, include, internship, students, undertaking\n",
      "----------------------------------------\n",
      "Title: Further reading\n",
      "Content: Hosted on GitHub Pages — Theme by orderedlist...\n",
      "Topic: clinical dashboards\n",
      "Keywords: github, hosted, orderedlist, pages, reading\n",
      "----------------------------------------\n",
      "Title: How do I know if I am eligible?\n",
      "Content: For the enginering students, please contact engit-placements [at] unimelb [dot] edu [dot] au. For the data science and maths students, please contact science-industry-internships[at] unimelb [dot] edu [dot] au....\n",
      "Topic: FAQ\n",
      "Keywords: au, contact, dot, edu, science\n",
      "----------------------------------------\n",
      "Title: How flexible are the starting dates?\n",
      "Content: We are flexible. We aim to keep the same starting dates for everyone to make it easier to put people into the WEHI system, but the actual date you start can be flexible. You could start a week or two later if you need to. We are also flexible if you need to take time off during the internship as well....\n",
      "Topic: FAQ\n",
      "Keywords: dates, flexible, need, start, starting\n",
      "----------------------------------------\n",
      "Title: Where are the details I need to fill in my form?\n",
      "Content: You can find the information here:...\n",
      "Topic: FAQ\n",
      "Keywords: details, form, information, need\n",
      "----------------------------------------\n",
      "Title: I know that the internships are usually 100% offsite, but what if I want to go into the office sometimes?\n",
      "Content: We are open to having some opportunities to go to the office, especially if we can catchup with the other students. It would not be that regular though, but this can be discussed with other students....\n",
      "Topic: FAQ\n",
      "Keywords: 100, catchup, discussed, office, students\n",
      "----------------------------------------\n",
      "Title: How do I know you won’t get disengaged with the students?\n",
      "Content: We are committed to providing guidance, support, and mentorship throughout their internship experience. We recognize the importance of maintaining open lines of communication and being accessible to address their needs....\n",
      "Topic: FAQ\n",
      "Keywords: accessible, open, providing, recognize, students\n",
      "----------------------------------------\n",
      "Title: What is the difference between data engineering, data analysis, and software engineering?\n",
      "Content: Data engineering is focused on streamlining and cleaning data systematically. Data analysis is focused on cleaning data and analysing it using statistical or machine learning algorithms. Software engineering is focused on systematising analysis or tools that help us make decisions....\n",
      "Topic: FAQ\n",
      "Keywords: analysis, cleaning, data, engineering, focused\n",
      "----------------------------------------\n",
      "Title: The Workday email says “On your first day, please arrive at 9.00am unless your manager has advised an alternative time and ask for your manager upon arrival at reception.” - is this accurate?\n",
      "Content: No, it is not accurate. This is a 100% remote internship and that part of the Workday email can be safely ignored. On your first day, you will be scheduled some virtual drop-in sessions so you can meet the supervisor and other interns....\n",
      "Topic: FAQ\n",
      "Keywords: accurate, day, email, manager, workday\n",
      "----------------------------------------\n",
      "Title: I setup my Workday (HR system) through an initial email but now that password doesn’t work or I cannot login to my WEHI email\n",
      "Content: The links you might have previously used to access Workday before your official start date will no longer allow access.  Email hr [at] wehi [dot] edu [dot] au as this is the contact provided if you encounter any issue in regard to Workday. They will provided you with the new credentials to set up your WEHI email. You may need to go into Incognito mode to get it to work....\n",
      "Topic: FAQ\n",
      "Keywords: email, provided, wehi, work, workday\n",
      "----------------------------------------\n",
      "Title: What courses in Workday do I need to complete?\n",
      "Content: These are the key courses you need to do:...\n",
      "Topic: FAQ\n",
      "Keywords: complete, courses, key, need, workday\n",
      "----------------------------------------\n",
      "Title: How do I get access to the WEHI-wide student intern group using my WEHI email address?\n",
      "Content: To get access to WEHI-wide student intern group using your WEHI email address. We need to do this as we will be deleting the unimelb email access once everyone has their WEHI email addresses....\n",
      "Topic: FAQ\n",
      "Keywords: access, address, email, group, wehi\n",
      "----------------------------------------\n",
      "Title: Given that the internship is remote, am I allowed to complete the internship while on travel?\n",
      "Content: Yes, that is correct....\n",
      "Topic: FAQ\n",
      "Keywords: allowed, complete, correct, given, internship\n",
      "----------------------------------------\n",
      "Title: The description stated that so many hrs per week is expected, but at roughly which times and for how long?\n",
      "Content: As it is remote, we are very flexible but there are times when we do get together, such as the weekly project meeting. This is explained in the Student Internship Handbook....\n",
      "Topic: FAQ\n",
      "Keywords: description, roughly, stated, student, times\n",
      "----------------------------------------\n",
      "Title: I need to use storage and compute. What are my options?\n",
      "Content: We have a few options at WEHI for storage and compute....\n",
      "Topic: FAQ\n",
      "Keywords: compute, need, options, storage, use\n",
      "----------------------------------------\n",
      "Title: If I want to use Nectar, what suggestions would you have?\n",
      "Content: Make sure you use “Any Availability Zone” if you are using Nectar as some of the University of Melbourne hosts are full....\n",
      "Topic: FAQ\n",
      "Keywords: availability, hosts, make, nectar, use\n",
      "----------------------------------------\n",
      "Title: Is it OK for me to post on social media?\n",
      "Content: Yes, but please read the Social Media Policy for student interns....\n",
      "Topic: FAQ\n",
      "Keywords: interns, media, ok, policy, social\n",
      "----------------------------------------\n",
      "Title: My project is complex and ambiguous - what can I do to deal with this?\n",
      "Content: All of the projects are complex and ambiguous....\n",
      "Topic: FAQ\n",
      "Keywords: ambiguous, complex, deal, project, projects\n",
      "----------------------------------------\n",
      "Title: What is the overall structure of the internship going to look like?\n",
      "Content: To understand how the overall process of the project please look at the Key milestones and onboarding emails page....\n",
      "Topic: FAQ\n",
      "Keywords: emails, going, internship, look, overall\n",
      "----------------------------------------\n",
      "Title: You ask us to be as independent as possible. How can we do that?\n",
      "Content: Rules of thumb for being independent:...\n",
      "Topic: FAQ\n",
      "Keywords: ask, independent, possible, rules, thumb\n",
      "----------------------------------------\n",
      "Title: We are required to interview a number of people to gather insight into their career pathway. How can I arrange this with you?\n",
      "Content: You can see more in Ask About Career on page 25 of the RCP Student Onboarding Checklist...\n",
      "Topic: FAQ\n",
      "Keywords: 25, arrange, ask, career, checklist\n",
      "----------------------------------------\n",
      "Title: We are required to request supervisor signature for the Work Log. How can I arrange this with you?\n",
      "Content: For those doing the Bachelor of Science or the Master of Data Science course, it is required to complete this supervisor signature work using DocuSign. This ensures that your work log is verified accurately and submitted on time....\n",
      "Topic: FAQ\n",
      "Keywords: required, science, signature, supervisor, work\n",
      "----------------------------------------\n",
      "Title: What should I put in the public wiki?\n",
      "Content: The public wiki is to share information with future students the things you needed to understand at a high level to be able to start working on the technical side of the project....\n",
      "Topic: FAQ\n",
      "Keywords: able, future, high, public, wiki\n",
      "----------------------------------------\n",
      "Title: What should I put in my technical diary?\n",
      "Content: Within your project channel in Sharepoint (ie. within the WEHI-wide student intern group in Teams > Files), you should have a Technical notes folder for your intake eg. Semester 2 2023 Technical notes. This is to help future students understand what you did in detail to get your results. This also includes things that should not be made public. So descriptions of where you put data or how you ran a script on Milton should not be made public and should go in Sharepoint....\n",
      "Topic: FAQ\n",
      "Keywords: notes, public, sharepoint, technical, understand\n",
      "----------------------------------------\n",
      "Title: How should I ask for help to solve a problem?\n",
      "Content: There is a way to escalate how to ask for help. This shows you how you can do your proper due diligence before you send your supervsior an email with a question....\n",
      "Topic: FAQ\n",
      "Keywords: ask, diligence, email, escalate, help\n",
      "----------------------------------------\n",
      "Title: What are the key things to do before the weekly meetings?\n",
      "Content: Key things to do before for the regular weekly meeting (yes even the first one that is usually in week 2 although it will be mostly empty):...\n",
      "Topic: FAQ\n",
      "Keywords: key, meeting, meetings, things, weekly\n",
      "----------------------------------------\n",
      "Title: What happens over Christmas / New Year / Easter period?\n",
      "Content: We take a break between Christmas and New Year, as well as the first week of January as well. During the time away there is no need to write and send the weekly update email during the break. We do encourage you to write down questions and what you have done in your technical diary so that you can ask questions when we are back in the second week of January....\n",
      "Topic: FAQ\n",
      "Keywords: january, new, questions, week, write\n",
      "----------------------------------------\n",
      "Title: What do I need to do for my final presentation and summary report?\n",
      "Content: The final presentation and summary report are due on the last week of the internship. They are usually done at the same time as the regular weekly project meeting. It is important to provide an early draft and a late draft to your supervisors for both the final presentation and the summary report. The early draft is to make sure you are on the right track, and the late draft is to polish things. Please put them into Teams Files / Sharepoint so that they can be commented on directly by your super...\n",
      "Topic: FAQ\n",
      "Keywords: draft, final, presentation, report, summary\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from rake_nltk import Rake\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Function to extract text from a PDF\n",
    "def extract_text_from_pdf(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "# Function to generate keywords using TF-IDF\n",
    "def generate_keywords_tfidf(content, top_n=5):\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_features=top_n)\n",
    "    X = vectorizer.fit_transform([content])\n",
    "    keywords = vectorizer.get_feature_names_out()\n",
    "    return list(keywords)\n",
    "\n",
    "# Function to scrape a web page\n",
    "def scrape_web_page(url, topic=\"General\"):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch page: {response.status_code}\")\n",
    "        return None\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    documents = []\n",
    "    titles = soup.find_all('h2')  # Adjust this tag based on page structure\n",
    "    for title in titles:\n",
    "        question = title.text.strip()\n",
    "        answer = title.find_next('p').text.strip() if title.find_next('p') else \"No answer found\"\n",
    "        content = question + \" \" + answer\n",
    "        keywords = generate_keywords_tfidf(content)\n",
    "        documents.append({\n",
    "            \"title\": question,\n",
    "            \"content\": answer,\n",
    "            \"topic\": topic,\n",
    "            \"keywords\": keywords\n",
    "        })\n",
    "    return documents\n",
    "\n",
    "# Extract text from PDFs\n",
    "pdf_paths = [\n",
    "    \"C:/Users/omidm/Downloads/RCP#0032 Intake 10 Student Internship Summary reports (share with all).pdf\",\n",
    "    \"C:/Users/omidm/Downloads/Research Computing Platform Student Internship Handbook.pdf\",\n",
    "    \"C:/Users/omidm/Downloads/RCP0026 Welcome Students Semeter 2 Intake 10.pdf\"\n",
    "]\n",
    "pdf_data = []\n",
    "\n",
    "for pdf_path in pdf_paths:\n",
    "    pdf_text = extract_text_from_pdf(pdf_path)\n",
    "    pdf_keywords = generate_keywords_tfidf(pdf_text)\n",
    "    \n",
    "    # Extract the file name (without extension) from the file path\n",
    "    file_name = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "    \n",
    "    pdf_data.append({\n",
    "        \"title\": f\"Content from {file_name}\",\n",
    "        \"content\": pdf_text,\n",
    "        \"topic\": file_name,  # Use the file name as the topic\n",
    "        \"keywords\": pdf_keywords\n",
    "    })\n",
    "\n",
    "\n",
    "# Scrape web pages\n",
    "links = [\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/students\", \"topic\": \"Unpaid Student Internship Program\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/complex-projects\", \"topic\": \"complex ambiguous projects\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/software_maturity_model\", \"topic\": \"software maturity model\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/explanation_about_ohs\", \"topic\": \"explanation about ohs\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/top-5-mistakes\", \"topic\": \"top 5 mistakes\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/project-wikis\", \"topic\": \"project wikis\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-loxcoder\", \"topic\": \"loxcoder\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-data-commons\", \"topic\": \"student data commons\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-cryoem\", \"topic\": \"cryoem\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-genomics-qc\", \"topic\": \"genomics quantum computing\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-schex\", \"topic\": \"schex\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-mixOmics.html\", \"topic\": \"mixOmics\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-capacity-planning.html\", \"topic\": \"capacity planning\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-haemosphere\", \"topic\": \"haemosphere\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-imaging\", \"topic\": \"imaging\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-quantum\", \"topic\": \"quantum\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-genomics-metadata.html\", \"topic\": \"genomics metadata\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-aive\", \"topic\": \"aive\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-bionix\", \"topic\": \"bionix\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-clinical-dashboards\", \"topic\": \"clinical dashboards\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/email_acknowledgement\", \"topic\": \"email acknowledgement\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/code-of-conduct\", \"topic\": \"code of conduct\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/faq\", \"topic\": \"FAQ\"}       \n",
    "]\n",
    "web_data = []\n",
    "for link in links:\n",
    "    data = scrape_web_page(link[\"url\"], topic=link[\"topic\"])\n",
    "    if data:\n",
    "        web_data.extend(data)\n",
    "\n",
    "# Combine PDF data and web-scraped data\n",
    "all_data = pdf_data + web_data\n",
    "\n",
    "# Print and save the aggregated data\n",
    "for doc in all_data:\n",
    "    print(f\"Title: {doc['title']}\")\n",
    "    print(f\"Content: {doc['content'][:500]}...\")  # Truncate for readability\n",
    "    print(f\"Topic: {doc['topic']}\")\n",
    "    print(f\"Keywords: {', '.join(doc['keywords'])}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "with open(\"aggregated_data.json\", \"w\") as f:\n",
    "    json.dump(all_data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469cf871",
   "metadata": {},
   "outputs": [],
   "source": [
    "    {\"url\": \"https://www.patreon.com/posts/64545194\", \"topic\": \"Help your students help you teach\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/key-milestones\", \"topic\": \"Key Milestones\"},\n",
    "    {\"url\": \"https://wehi-researchcomputing.github.io/student-project-outlines\", \"topic\": \"Student Project Outlines\"}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89e39bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from rake_nltk import Rake\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Connect to Neo4j\n",
    "driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"12345678\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d35db540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to insert data into Neo4j\n",
    "def insert_into_neo4j(documents):\n",
    "    with driver.session() as session:\n",
    "        for doc in documents:\n",
    "            # Create Document node\n",
    "            session.run(\n",
    "                \"\"\"\n",
    "                MERGE (d:Document {title: $title, content: $content, topic: $topic})\n",
    "                \"\"\",\n",
    "                title=doc['title'], content=doc['content'], topic=doc['topic']\n",
    "            )\n",
    "            \n",
    "            # Create Keyword nodes and relationships\n",
    "            for keyword in doc['keywords']:\n",
    "                session.run(\n",
    "                    \"\"\"\n",
    "                    MERGE (k:Keyword {name: $keyword})\n",
    "                    MERGE (d:Document {title: $title})\n",
    "                    MERGE (d)-[:HAS_KEYWORD]->(k)\n",
    "                    \"\"\",\n",
    "                    keyword=keyword, title=doc['title']\n",
    "                )\n",
    "\n",
    "# Insert data into Neo4j\n",
    "insert_into_neo4j(all_data)\n",
    "\n",
    "# Close the Neo4j\n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b650a320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import os\n",
    "\n",
    "# Set up Neo4j connection\n",
    "class Neo4jQueryTool:\n",
    "    def __init__(self, uri, user, password):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "    def query(self, cypher_query, params=None):\n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(cypher_query, params)\n",
    "            return list(result)\n",
    "\n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "\n",
    "# Initialize Neo4j Tool\n",
    "neo4j_tool = Neo4jQueryTool(\"bolt://localhost:7687\", \"neo4j\", \"12345678\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85774934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd716b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omidm\\anaconda3\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "C:\\Users\\omidm\\anaconda3\\Lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "C:\\Users\\omidm\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, how can I assist you today?\n",
      "\n",
      "I'm sorry, but I'm not sure how to help you.\n",
      "\n",
      "I'm sorry, but I'm not sure how to help you.\n",
      "\n",
      "I'm sorry, but I'm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "text = \"Hello, how can I assist you today?\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs, max_length=50)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f1494fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "from IPython.display import Markdown\n",
    "\n",
    "# Set up Neo4j connection\n",
    "class Neo4jQueryTool:\n",
    "    def __init__(self, uri, user, password):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "    def query(self, cypher_query, params=None):\n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(cypher_query, params)\n",
    "            # Explicitly fetch all records into a list before processing\n",
    "            return list(result)\n",
    "\n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "\n",
    "# Initialize Neo4j Tool\n",
    "neo4j_tool = Neo4jQueryTool(\"bolt://localhost:7687\", \"neo4j\", \"12345678\")\n",
    "\n",
    "# Set up Google Gemini LLM API key\n",
    "os.environ['GOOGLE_API_KEY'] = \"AIzaSyDpTvl6KQLte4DksHn83iYDbhZlARYig8Y\"  # Replace with your actual API key\n",
    "genai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n",
    "\n",
    "# Instantiate the GenerativeModel with the 'gemini-pro' model\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68c21216",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omidm\\AppData\\Local\\Temp\\ipykernel_4008\\3070754831.py:11: DeprecationWarning: Using a driver after it has been closed is deprecated. Future versions of the driver will raise an error.\n",
      "  with self.driver.session() as session:\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: createdAt)} {position: line: 4, column: 24, offset: 113} for query: '\\n            MATCH (d:Document)\\n            RETURN d.title AS title, d.content AS content\\n            ORDER BY d.createdAt DESC\\n            LIMIT $limit\\n        '\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the details of some documents:\n",
      "Title: Content from Research Computing Platform Student Internship Handbook\n",
      "Content: Research\n",
      "Computing\n",
      "Platform\n",
      "Student Handbook3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8Introduction\n",
      "Philosophy\n",
      "Benefits for Students\n",
      "Numbers behind the program\n",
      "Code of Conduct\n",
      "Want to know more?Table of ContentsIntroduction\n",
      "The Research Computing Platform (RCP) is a  \n",
      "collaborative, multi-disciplinary lab that\n",
      "supports and advocates for researchers and\n",
      "their computational research needs at WEHI.\n",
      "RCP has established a 100% remote, unpaid\n",
      "student internship program with subjects\n",
      "provided at the University of Melbourne. We\n",
      "did th\n",
      "Title: Content from RCP0026 Welcome Students Semeter 2 Intake 10\n",
      "Content: Walter and Eliza Hall Institute of Medical ResearchRCP Student Internship Welcome \n",
      "Summer 2024 2025\n",
      "Week of 25th November 2024Acknowledgement of Country\n",
      "I acknowledge the Wurundjeri and Boon Wurrung people, on\n",
      "whose unceded lands some of us live and work here in\n",
      "Naarm (Melbourne). I respectfully acknowledge their Elders,\n",
      "past and present. I also acknowledge all the Traditional\n",
      "Owners of Country throughout the continent of Australia. I\n",
      "pay my respects to their Elders past and present. \n",
      "02Agenda\n",
      "A\n",
      "Title: Learn real world skills\n",
      "Content: We prepare students for the real-world by teaching them:\n",
      "Title: How do I know if I am eligible?\n",
      "Content: For the enginering students, please contact engit-placements [at] unimelb [dot] edu [dot] au. For the data science and maths students, please contact science-industry-internships[at] unimelb [dot] edu [dot] au.\n",
      "Title: How flexible are the starting dates?\n",
      "Content: We are flexible. We aim to keep the same starting dates for everyone to make it easier to put people into the WEHI system, but the actual date you start can be flexible. You could start a week or two later if you need to. We are also flexible if you need to take time off during the internship as well.\n",
      "Title: Content from RCP#0032 Intake 10 Student Internship Summary reports (share with all)\n",
      "Content: RCP#0032\n",
      "Intake\n",
      "10\n",
      "Student \n",
      "Internship\n",
      "Summary\n",
      "reports\n",
      "Table\n",
      "of\n",
      "Contents\n",
      "Link\n",
      "to\n",
      "Intake\n",
      "9\n",
      "Summary\n",
      "Report\n",
      "RCP#0016\n",
      "Intake\n",
      "9\n",
      "Student\n",
      "Internship\n",
      "Summary\n",
      "reports.pdf\n",
      "that\n",
      "can\n",
      "be\n",
      "used\n",
      "as\n",
      "an\n",
      "example.AIVE\n",
      "Student\n",
      "Project\n",
      "Interns:\n",
      "Si\n",
      "Yang\n",
      "(Sean)\n",
      "Chen,\n",
      "Chun-Tung\n",
      "(Chloe)\n",
      "Tsai,\n",
      "Jiawen\n",
      "Deng\n",
      "High-Level\n",
      "Domain\n",
      "work\n",
      "During\n",
      "the\n",
      "first\n",
      "4-5\n",
      "weeks,\n",
      "we\n",
      "learned\n",
      "about\n",
      "and\n",
      "tried\n",
      "to\n",
      "understand\n",
      "the\n",
      "AIVE\n",
      "workflow\n",
      "for\n",
      "converting\n",
      "2D\n",
      "cell\n",
      "image\n",
      "stacks\n",
      "into\n",
      "3D\n",
      "models\n",
      "and\n",
      "familiarised\n",
      "ourselves\n",
      "with\n",
      "software\n",
      "tools\n",
      "used\n",
      "in\n",
      "the\n",
      "\n",
      "Can you summarize the key points and provide advice about these documents? I would love to hear from you. If you have any questions, feel free to e-mail me.\n"
     ]
    }
   ],
   "source": [
    "def fetch_and_generate_content(limit=6, max_input_length=1024, max_new_tokens=200):\n",
    "    try:\n",
    "        # Query Neo4j to retrieve document titles and contents\n",
    "        result = neo4j_tool.query(\"\"\"\n",
    "            MATCH (d:Document)\n",
    "            RETURN d.title AS title, d.content AS content\n",
    "            ORDER BY d.createdAt DESC\n",
    "            LIMIT $limit\n",
    "        \"\"\", {\"limit\": limit})\n",
    "        \n",
    "        # Check if any results were returned\n",
    "        if not result:\n",
    "            return \"No documents were found in the database.\"\n",
    "        \n",
    "        # Format the result into a string suitable for the LLM\n",
    "        document_info = \"\\n\".join(\n",
    "            [f\"Title: {record['title']}\\nContent: {record['content'][:500]}\"  # Truncate content for safety\n",
    "             for record in result]\n",
    "        )\n",
    "        \n",
    "        # Construct the prompt for LLaMA\n",
    "        prompt = (\n",
    "            f\"Here are the details of some documents:\\n{document_info}\\n\"\n",
    "            \"Can you summarize the key points and provide advice about these documents?\"\n",
    "        )\n",
    "        \n",
    "        # Tokenize the input with truncation\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=max_input_length)\n",
    "        \n",
    "        # Validate input_ids length\n",
    "        if inputs.input_ids.shape[1] > max_input_length:\n",
    "            raise ValueError(f\"Input exceeds max_input_length: {inputs.input_ids.shape[1]} tokens\")\n",
    "        \n",
    "        # Generate content using LLaMA\n",
    "        outputs = model.generate(\n",
    "            inputs.input_ids,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            num_beams=4,\n",
    "            no_repeat_ngram_size=2,\n",
    "            early_stopping=True\n",
    "        )\n",
    "        \n",
    "        # Decode the output\n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return response\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\"\n",
    "    finally:\n",
    "        # Ensure the Neo4j connection is closed\n",
    "        neo4j_tool.close()\n",
    "\n",
    "# Example usage: fetch data and generate content\n",
    "response_text = fetch_and_generate_content(limit=6)\n",
    "print(response_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "58633768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Record title='What happens over Christmas / New Year / Easter period?' content='We take a break between Christmas and New Year, as well as the first week of January as well. During the time away there is no need to write and send the weekly update email during the break. We do encourage you to write down questions and what you have done in your technical diary so that you can ask questions when we are back in the second week of January.'>]\n",
      "Document 'What happens over Christmas / New Year / Easter period?':\n",
      "**Summary of Document:**\n",
      "The document outlines that there will be a break from sending weekly update emails between Christmas and New Year, and for the first week of January.\n",
      "\n",
      "**Hypothesis on Significance of Easter:**\n",
      "Despite being mentioned in the title, the document does not provide any details on Easter. However, the inclusion of Easter in the title suggests that it may also be a period where weekly updates are not sent. This hypothesis aligns with the common practice of many organizations observing a break during major holidays, including Easter.\n",
      "\n",
      "Document 'What happens over Christmas / New Year / Easter period?':\n",
      "**Summary of the Document:**\n",
      "\n",
      "The document provides guidelines for students during the upcoming Christmas and New Year break. It encourages students to write down questions and document their technical work in their diaries to facilitate discussions during the first week after the break in January.\n",
      "\n",
      "**Hypothesis on the Significance of Easter:**\n",
      "\n",
      "Although the document's content does not explicitly mention Easter, its inclusion in the title suggests its significance for students. It is possible that Easter may be included in future updates or communications regarding the break period. Alternatively, Easter may be mentioned in the document's broader context, such as in relation to academic schedules or university closures during the Easter holiday.\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase \n",
    "import os\n",
    "import google.generativeai as genai\n",
    "from IPython.display import Markdown\n",
    "\n",
    "# Set up Neo4j connection\n",
    "class Neo4jQueryTool:\n",
    "    def __init__(self, uri, user, password):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "    def query(self, cypher_query, params=None):\n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(cypher_query, params)\n",
    "            return list(result)\n",
    "\n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "\n",
    "# Initialize Neo4j Tool\n",
    "neo4j_tool = Neo4jQueryTool(\"bolt://localhost:7687\", \"neo4j\", \"12345678\")\n",
    "\n",
    "# Set up Google Gemini LLM API key\n",
    "os.environ['GOOGLE_API_KEY'] = \"AIzaSyDpTvl6KQLte4DksHn83iYDbhZlARYig8Y\"  # Replace with your actual API key\n",
    "genai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n",
    "\n",
    "# Instantiate the GenerativeModel with the 'gemini-pro' model\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "# Function to fetch all data and generate content in chunks\n",
    "def fetch_and_generate_all_content(chunk_size=5000):\n",
    "    # Query Neo4j for documents mentioning 'Easter'\n",
    "    result = neo4j_tool.query(\"\"\"\n",
    "        MATCH (d:Document)\n",
    "        WHERE toLower(d.title) CONTAINS 'easter' OR toLower(d.content) CONTAINS 'easter'\n",
    "        RETURN d.title AS title, d.content AS content\n",
    "        \"\"\")\n",
    "    print(result)\n",
    "\n",
    "    if not result:\n",
    "        return \"No documents mentioning Easter found in the database.\"\n",
    "\n",
    "    responses = []\n",
    "    for record in result:\n",
    "        title = record['title']\n",
    "        content = record['content']\n",
    "\n",
    "        # Chunk the document content\n",
    "        chunks = [content[i:i + chunk_size] for i in range(0, len(content), chunk_size)]\n",
    "        for idx, chunk in enumerate(chunks):\n",
    "            prompt = f\"The document titled '{title}' includes 'Easter' in its title but does not mention it in the content. Summarize the document and hypothesize the significance of Easter based on the title and content:\\n{chunk}\"\n",
    "\n",
    "            try:\n",
    "                response = model.generate_content(prompt)\n",
    "                responses.append(f\"Document '{title}':\\n{response.text}\")\n",
    "            except Exception as e:\n",
    "                responses.append(f\"Error in chunk {idx + 1} for document '{title}': {str(e)}\")\n",
    "\n",
    "    return \"\\n\\n\".join(responses)\n",
    "\n",
    "\n",
    "# Example usage: fetch and generate content for all data\n",
    "response_text = fetch_and_generate_all_content(chunk_size=200)  # Adjust chunk size as needed\n",
    "print(response_text)\n",
    "\n",
    "# Close the Neo4j tool after use\n",
    "neo4j_tool.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "836b2b30",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5003\n",
      "Press CTRL+C to quit\n",
      " * Restarting with watchdog (windowsapi)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from neo4j import GraphDatabase\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Flask App\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Set up Neo4j connection\n",
    "class Neo4jQueryTool:\n",
    "    def __init__(self, uri, user, password):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "    def query(self, cypher_query, params=None):\n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(cypher_query, params)\n",
    "            return list(result)\n",
    "\n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "\n",
    "# Initialize Neo4j Tool\n",
    "neo4j_tool = Neo4jQueryTool(\"bolt://localhost:7687\", \"neo4j\", \"12345678\")\n",
    "\n",
    "# Set up Google Gemini LLM API key\n",
    "os.environ['GOOGLE_API_KEY'] = \"YOUR_ACTUAL_GOOGLE_API_KEY\"  # Replace with your actual API key\n",
    "genai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n",
    "\n",
    "# Instantiate the GenerativeModel with the 'gemini-pro' model\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "# Function to handle queries and generate responses\n",
    "def handle_user_question(question, chunk_size=5000):\n",
    "    cypher_query = \"\"\"\n",
    "        MATCH (d:Document)\n",
    "        WHERE toLower(d.title) CONTAINS $keyword OR toLower(d.content) CONTAINS $keyword\n",
    "        RETURN d.title AS title, d.content AS content\n",
    "    \"\"\"\n",
    "    params = {\"keyword\": question.lower()}\n",
    "    result = neo4j_tool.query(cypher_query, params)\n",
    "\n",
    "    if not result:\n",
    "        return f\"No documents mentioning '{question}' found in the database.\"\n",
    "\n",
    "    responses = []\n",
    "    for record in result:\n",
    "        title = record['title']\n",
    "        content = record['content']\n",
    "\n",
    "        # Chunk the document content\n",
    "        chunks = [content[i:i + chunk_size] for i in range(0, len(content), chunk_size)]\n",
    "        for idx, chunk in enumerate(chunks):\n",
    "            prompt = (\n",
    "                f\"The document titled '{title}' is related to your query '{question}'. \"\n",
    "                f\"Summarize its main points and discuss any relevant references:\\n{chunk}\"\n",
    "            )\n",
    "            try:\n",
    "                response = model.generate_content(prompt)\n",
    "                responses.append(f\"Document '{title}':\\n{response.text}\")\n",
    "            except Exception as e:\n",
    "                responses.append(f\"Error in chunk {idx + 1} for document '{title}': {str(e)}\")\n",
    "\n",
    "    return \"\\n\\n\".join(responses)\n",
    "\n",
    "# Flask endpoint for chatbot\n",
    "@app.route(\"/chat\", methods=[\"POST\"])\n",
    "def chat():\n",
    "    user_input = request.json.get(\"question\", \"\")\n",
    "    if not user_input:\n",
    "        return jsonify({\"error\": \"Please provide a valid question.\"}), 400\n",
    "\n",
    "    try:\n",
    "        response_text = handle_user_question(user_input, chunk_size=200)\n",
    "        return jsonify({\"response\": response_text})\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "# Close Neo4j tool gracefully on shutdown\n",
    "@app.teardown_appcontext\n",
    "def close_neo4j_connection(exception):\n",
    "    neo4j_tool.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True, port=5003, use_reloader=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "32789582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-10 17:08:30.489 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-10 17:08:30.489 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-10 17:08:30.489 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-10 17:08:30.489 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-10 17:08:30.489 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-10 17:08:30.489 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-10 17:08:30.495 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-10 17:08:30.495 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from neo4j import GraphDatabase\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Set up Neo4j connection\n",
    "class Neo4jQueryTool:\n",
    "    def __init__(self, uri, user, password):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "    def query(self, cypher_query, params=None):\n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(cypher_query, params)\n",
    "            return list(result)\n",
    "\n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "\n",
    "# Initialize Neo4j Tool\n",
    "neo4j_tool = Neo4jQueryTool(\"bolt://localhost:7687\", \"neo4j\", \"12345678\")\n",
    "\n",
    "# Set up Google Gemini LLM API key\n",
    "os.environ['GOOGLE_API_KEY'] = \"YOUR_ACTUAL_GOOGLE_API_KEY\"  # Replace with your actual API key\n",
    "genai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n",
    "\n",
    "# Instantiate the GenerativeModel with the 'gemini-pro' model\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "# Function to handle queries and generate responses\n",
    "def handle_user_question(question, chunk_size=5000):\n",
    "    cypher_query = \"\"\"\n",
    "        MATCH (d:Document)\n",
    "        WHERE toLower(d.title) CONTAINS $keyword OR toLower(d.content) CONTAINS $keyword\n",
    "        RETURN d.title AS title, d.content AS content\n",
    "    \"\"\"\n",
    "    params = {\"keyword\": question.lower()}\n",
    "    result = neo4j_tool.query(cypher_query, params)\n",
    "\n",
    "    if not result:\n",
    "        return f\"No documents mentioning '{question}' found in the database.\"\n",
    "\n",
    "    responses = []\n",
    "    for record in result:\n",
    "        title = record['title']\n",
    "        content = record['content']\n",
    "\n",
    "        # Chunk the document content\n",
    "        chunks = [content[i:i + chunk_size] for i in range(0, len(content), chunk_size)]\n",
    "        for idx, chunk in enumerate(chunks):\n",
    "            prompt = (\n",
    "                f\"The document titled '{title}' is related to your query '{question}'. \"\n",
    "                f\"Summarize its main points and discuss any relevant references:\\n{chunk}\"\n",
    "            )\n",
    "            try:\n",
    "                response = model.generate_content(prompt)\n",
    "                responses.append(f\"Document '{title}':\\n{response.text}\")\n",
    "            except Exception as e:\n",
    "                responses.append(f\"Error in chunk {idx + 1} for document '{title}': {str(e)}\")\n",
    "\n",
    "    return \"\\n\\n\".join(responses)\n",
    "\n",
    "# Streamlit App\n",
    "st.title(\"Document Query and Chatbot\")\n",
    "\n",
    "# Input field for user question\n",
    "user_input = st.text_input(\"Ask a question about the documents:\", \"\")\n",
    "\n",
    "if user_input:\n",
    "    try:\n",
    "        response_text = handle_user_question(user_input, chunk_size=200)\n",
    "        st.write(\"Response:\")\n",
    "        st.text(response_text)\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5225b0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omidm\\AppData\\Local\\Temp\\ipykernel_4008\\243200390.py:78: DeprecationWarning: \n",
      "        on_event is deprecated, use lifespan event handlers instead.\n",
      "\n",
      "        Read more about it in the\n",
      "        [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).\n",
      "        \n",
      "  @app.on_event(\"shutdown\")\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI, HTTPException\n",
    "from neo4j import GraphDatabase\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "# FastAPI App\n",
    "app = FastAPI()\n",
    "\n",
    "# Set up Neo4j connection\n",
    "class Neo4jQueryTool:\n",
    "    def __init__(self, uri, user, password):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "    def query(self, cypher_query, params=None):\n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(cypher_query, params)\n",
    "            return list(result)\n",
    "\n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "\n",
    "# Initialize Neo4j Tool\n",
    "neo4j_tool = Neo4jQueryTool(\"bolt://localhost:7687\", \"neo4j\", \"12345678\")\n",
    "\n",
    "# Set up Google Gemini LLM API key\n",
    "os.environ['GOOGLE_API_KEY'] = \"YOUR_ACTUAL_GOOGLE_API_KEY\"  # Replace with your actual API key\n",
    "genai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n",
    "\n",
    "# Instantiate the GenerativeModel with the 'gemini-pro' model\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "# Function to handle queries and generate responses\n",
    "def handle_user_question(question, chunk_size=5000):\n",
    "    cypher_query = \"\"\"\n",
    "        MATCH (d:Document)\n",
    "        WHERE toLower(d.title) CONTAINS $keyword OR toLower(d.content) CONTAINS $keyword\n",
    "        RETURN d.title AS title, d.content AS content\n",
    "    \"\"\"\n",
    "    params = {\"keyword\": question.lower()}\n",
    "    result = neo4j_tool.query(cypher_query, params)\n",
    "\n",
    "    if not result:\n",
    "        return f\"No documents mentioning '{question}' found in the database.\"\n",
    "\n",
    "    responses = []\n",
    "    for record in result:\n",
    "        title = record['title']\n",
    "        content = record['content']\n",
    "\n",
    "        # Chunk the document content\n",
    "        chunks = [content[i:i + chunk_size] for i in range(0, len(content), chunk_size)]\n",
    "        for idx, chunk in enumerate(chunks):\n",
    "            prompt = (\n",
    "                f\"The document titled '{title}' is related to your query '{question}'. \"\n",
    "                f\"Summarize its main points and discuss any relevant references:\\n{chunk}\"\n",
    "            )\n",
    "            try:\n",
    "                response = model.generate_content(prompt)\n",
    "                responses.append(f\"Document '{title}':\\n{response.text}\")\n",
    "            except Exception as e:\n",
    "                responses.append(f\"Error in chunk {idx + 1} for document '{title}': {str(e)}\")\n",
    "\n",
    "    return \"\\n\\n\".join(responses)\n",
    "\n",
    "# FastAPI endpoint for chatbot\n",
    "@app.post(\"/chat\")\n",
    "async def chat(user_input: str):\n",
    "    if not user_input:\n",
    "        raise HTTPException(status_code=400, detail=\"Please provide a valid question.\")\n",
    "    \n",
    "    try:\n",
    "        response_text = handle_user_question(user_input, chunk_size=200)\n",
    "        return {\"response\": response_text}\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "# Close Neo4j tool gracefully on shutdown\n",
    "@app.on_event(\"shutdown\")\n",
    "def close_neo4j_connection():\n",
    "    neo4j_tool.close()\n",
    "\n",
    "# To run this, use `uvicorn main:app --reload` in the terminal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7c6387aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!uvicorn app:app --reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2791499c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uvicorn app:app --reload --host 0.0.0.0 --port 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2611fda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
